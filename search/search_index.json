{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"appendix/docker-cheat-sheet/","title":"Docker Commands","text":""},{"location":"appendix/docker-cheat-sheet/#introduction","title":"Introduction","text":"<p>In this article, I am going to present a comprehensive cheat sheet of commonly used <code>Docker</code> commands</p>"},{"location":"appendix/docker-cheat-sheet/#installing-docker","title":"Installing Docker","text":"<p>Here are the commands to install Docker on different operating systems:</p> <pre><code># Ubuntu/Debian:\nsudo apt-get update\nsudo apt-get install docker.io\n\n\n# MacOS (using Homebrew):\nbrew install docker\n\n# Windows OS (using choco)\nchoco install docker-desktop\n</code></pre>"},{"location":"appendix/docker-cheat-sheet/#docker-install-verify","title":"Docker Install verify","text":"<p>To know docker is installed or not</p> <pre><code>which docker\n\n# output\n/usr/bin/docker\n</code></pre> <p>What is the version installed on your machine</p> <pre><code>docker -version\n</code></pre>"},{"location":"appendix/docker-cheat-sheet/#general-commands","title":"General Commands","text":"<p>Start the docker daemon</p> <pre><code>docker -d\n</code></pre> <p>Get help with Docker. Can also use \u2013help on all subcommands</p> <pre><code>docker --help\n</code></pre> <p>Display system-wide information</p> <pre><code>docker info\n</code></pre>"},{"location":"appendix/docker-cheat-sheet/#docker-image","title":"Docker Image","text":"<p>Docker image is a lightweight, standalone, and executable package that contains everything needed to run a piece of software, including the code, runtime, system tools, libraries, and dependencies. </p> <pre><code># List local images\ndocker images\n\n# Delete an Image\ndocker rmi &lt;image_name&gt;\n\n# Remove all unused images\ndocker image prune\n</code></pre>"},{"location":"appendix/docker-cheat-sheet/#docker-build","title":"Docker Build","text":"<p>Build an image from a Dockerfile</p> <pre><code># Build an image from a Dockerfile and tag it with a specified name.\ndocker build -t &lt;image_name&gt;\n\n# build an image and tag with naming conventions\ndocker build -t projectname/domainname/appname:yyyymmdd.sequence .\n# Example\ndocker build -t sample/aspnet-api:20230226.1 .\n\n# Build an image from a Dockerfile without the cache\ndocker build -t &lt;image_name&gt; . \u2013no-cache\n</code></pre>"},{"location":"appendix/docker-cheat-sheet/#docker-run","title":"Docker Run","text":"<pre><code># Create and run a container from an image, with a custom name:\ndocker run --name &lt;container_name&gt; &lt;image_name&gt;\n\n# Run a container with and publish a container\u2019s port(s) to the host.\ndocker run -p &lt;host_port&gt;:&lt;container_port&gt; &lt;image_name&gt;\n\n# Run a container in the background\ndocker run -d &lt;image_name&gt;\n\n# Remove a stopped container:\ndocker rm &lt;container_name&gt;\n\n# Example: \ndocker run --rm -p 8080:80 project1/domain1/app1:20230226.1\n</code></pre> <ul> <li>--rm: This option automatically removes the container when it exits. It ensures that the container is cleaned up after it finishes running. This is useful for temporary or disposable containers.</li> <li>-p 8080:80: This option maps the host machine's port 8080 to the container's port 80. It establishes a network connection between the host and the container, allowing access to the containerized application via port 8080 on the host.</li> </ul> <p>Exit the container</p> <pre><code>exit\n</code></pre>"},{"location":"appendix/docker-cheat-sheet/#docker-push","title":"Docker Push","text":"<pre><code># Publish an image to Docker Hub\ndocker push &lt;username&gt;/&lt;image_name&gt;\n</code></pre>"},{"location":"appendix/docker-cheat-sheet/#docker-container","title":"Docker container","text":"<p>A Docker container is a lightweight, standalone, and executable runtime instance of a Docker image. It represents a running process that is isolated from the host system and other containers. Docker container providing a consistent and reproducible environment for running applications. Containers are highly portable and can be easily moved and deployed across different environments, such as development, testing, staging, and production. </p>"},{"location":"appendix/docker-cheat-sheet/#docker-hub","title":"Docker Hub","text":"<p>Docker Hub is a cloud-based registry service provided by Docker that allows developers to store and share container images. It serves as a centralized repository for Docker images,</p> <pre><code># Login into Docker\ndocker login -u &lt;username&gt;\n\n# Publish an image to Docker Hub\ndocker push &lt;username&gt;/&lt;image_name&gt;\n\n# Search Hub for an image\ndocker search &lt;image_name&gt;\n\n# Pull an image from a Docker Hub\ndocker pull &lt;image_name&gt;\n</code></pre>"},{"location":"appendix/docker-cheat-sheet/#docker-network","title":"Docker network","text":"<p>This command creates a new bridge network named \"network1\" that containers can connect to for networked communication.</p> <pre><code>docker network create -d bridge network1\n</code></pre>"},{"location":"appendix/docker-cheat-sheet/#clean-up-resources","title":"Clean up resources","text":"<p>you can use the <code>docker system prune</code> command to clean up all dangling or unused resources, including images, containers, volumes, and networks that are not tagged or connected to a running container. This command is helpful for freeing up disk space and removing unnecessary resources.</p> <pre><code># before cleaning up Docker, first check all the available resources using the following commands:\n\ndocker  container ls\ndocker  image ls\ndocker  volume ls\ndocker  network ls\ndocker  info\n\ndocker system prune\n# or\ndocker system prune -a\n</code></pre> <p>If you need to clean up all containers and images locally in Docker Desktop, you can use the following commands:</p> <pre><code># To delete all containers including its volumes use,\ndocker rm -vf $(docker ps -aq)\n\n# To delete all volumes use,\ndocker volume rm $(docker volume ls -q)\n\n# To delete all the images,\ndocker rmi -f $(docker images -aq)\n</code></pre>"},{"location":"appendix/docker-cheat-sheet/#docker-compose-commands","title":"Docker Compose Commands","text":"<p>Below are some commonly used Docker Compose commands:</p>"},{"location":"appendix/docker-cheat-sheet/#starts-services","title":"Starts services","text":"<pre><code>docker-compose up\n</code></pre> <p>Starts the services defined in your <code>docker-compose.yml</code> file. It creates and starts containers as specified in the configuration.</p> <pre><code>docker-compose up -d\n</code></pre> <p>Starts the services in the background (detached mode).</p>"},{"location":"appendix/docker-cheat-sheet/#stops-services","title":"Stops services","text":"<p><pre><code>docker-compose down\n</code></pre> Stops and removes containers, networks, volumes, and other services defined in your <code>docker-compose.yml</code> file.</p> <p><pre><code>docker-compose down -v\n</code></pre> Stops and removes containers, networks, volumes, and other services while also removing volumes.</p> <p><pre><code>docker-compose down --volumes --rmi all\n</code></pre> Stops and removes containers, networks, volumes, and other services, while also removing volumes and images.    </p> <pre><code>docker-compose stop\n</code></pre> <p>Stops the services defined in your <code>docker-compose.yml</code> file without removing them.</p>"},{"location":"appendix/docker-cheat-sheet/#lists-the-containers","title":"Lists the containers","text":"<pre><code>docker-compose ps\n</code></pre> <p>Lists the containers that are part of your Docker Compose setup, showing their status.</p> <p><pre><code>docker-compose ps -a\n</code></pre> Lists all containers, including stopped ones, that are part of your Docker Compose setup.</p>"},{"location":"appendix/docker-cheat-sheet/#displays-log","title":"Displays log","text":"<p><pre><code>docker-compose logs\n</code></pre> Displays log output from services. You can use the <code>-f</code> option to follow the logs in real-time.</p> <pre><code>docker-compose logs webserver\n</code></pre> <p>Displays logs for a specific service.</p>"},{"location":"appendix/docker-cheat-sheet/#executes-a-command","title":"Executes a command","text":"<p><pre><code>docker-compose exec webserver ls -l\n</code></pre> Executes a command in a running service container.</p>"},{"location":"appendix/docker-cheat-sheet/#builds-services","title":"Builds services","text":"<p><pre><code>docker-compose build\n</code></pre> Builds or rebuilds services defined in your <code>docker-compose.yml</code> file.</p>"},{"location":"appendix/docker-cheat-sheet/#restarts-services","title":"Restarts services","text":"<p><pre><code>docker-compose restart\n</code></pre> Restarts services.</p>"},{"location":"appendix/docker-cheat-sheet/#displays-configuration","title":"Displays configuration","text":"<p><pre><code>docker-compose config\n</code></pre> Validates and displays the configuration of your <code>docker-compose.yml</code> file.</p>"},{"location":"appendix/docker-cheat-sheet/#pauses-services","title":"Pauses services","text":"<p><pre><code>docker-compose pause\n</code></pre> Pauses all services. Containers remain running, but they stop processing requests.</p> <p><pre><code>docker-compose unpause\n</code></pre> Unpauses services after they have been paused.</p> <p><pre><code>docker-compose top\n</code></pre> Displays the running processes of a service.</p>"},{"location":"appendix/docker-cheat-sheet/#scales-service","title":"Scales service","text":"<p><pre><code>docker-compose scale webserver=3\n</code></pre> Scales a service to the specified number of instances.</p>"},{"location":"appendix/docker-cheat-sheet/#display-events","title":"Display events","text":"<pre><code>docker-compose events\n</code></pre>"},{"location":"appendix/docker-cheat-sheet/#docker-compose-config","title":"docker compose config","text":"<p>Parse, resolve and render compose file in canonical forma</p> <pre><code>docker-compose config\n</code></pre> <p>Streams real-time events from your services.</p>"},{"location":"appendix/docker-cheat-sheet/#docker-commands-summary","title":"Docker commands Summary","text":""},{"location":"appendix/docker-cheat-sheet/#basic-commands","title":"Basic Commands","text":"<ul> <li><code>docker run [image]</code>: Start a new container from an image</li> <li><code>docker ps</code>: List all running containers</li> <li><code>docker stop [container]</code>: Stop a running container</li> <li><code>docker rm [container]</code>: Remove a container</li> <li><code>docker images</code>: List all available images</li> <li><code>docker pull [image]</code>: Download an image from a registry</li> <li><code>docker push [image]</code>: Upload an image to a registry</li> <li><code>docker build [options] [path]</code>: Build an image from a Dockerfile</li> </ul>"},{"location":"appendix/docker-cheat-sheet/#advanced-commands","title":"Advanced Commands","text":"<ul> <li><code>docker exec [container] [command]</code>: Run a command inside a running container</li> <li><code>docker-compose up</code>: Start a Docker Compose application</li> <li><code>docker network [subcommand]</code>: Manage Docker networks</li> <li><code>docker volume [subcommand]</code>: Manage Docker volumes</li> <li><code>docker logs [container]</code>: View the logs of a container</li> <li><code>docker inspect [container]</code>: Inspect a container</li> <li><code>docker diff [container]</code>: Show changes to the filesystem of a container</li> <li><code>docker commit [container] [image]</code>: Create a new image from a container's changes</li> <li><code>docker save [image]</code>: Save an image to a tar archive</li> <li><code>docker load</code>: Load an image from a tar archive</li> </ul>"},{"location":"appendix/docker-cheat-sheet/#references","title":"References","text":"<ul> <li>Overview of docker compose CLI</li> </ul>"},{"location":"appendix/dockerfile-cheat-sheet/","title":"Dockerfile Commands","text":""},{"location":"appendix/dockerfile-cheat-sheet/#introduction","title":"Introduction","text":"<p>In this article, I am going to present a comprehensive cheat sheet of commonly used <code>Dockerfile</code> commands</p>"},{"location":"appendix/dockerfile-cheat-sheet/#dockerfile","title":"Dockerfile","text":"<p>A Dockerfile is a text document that contains instructions for building a Docker image. Docker can automatically build images by interpreting instructions from a Dockerfile. This page outlines the commands available for use within a Dockerfile.\"</p>"},{"location":"appendix/dockerfile-cheat-sheet/#1-from","title":"1. FROM","text":"<p>Specifies the base image for your Docker image. <pre><code>FROM &lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;]\n</code></pre> Example: <pre><code>FROM mcr.microsoft.com/dotnet/sdk:5.0 AS build\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#2-run","title":"2. RUN","text":"<p>Executes commands in the shell of the container. <pre><code>RUN &lt;command&gt;\n</code></pre> Example: <pre><code>RUN apt-get update &amp;&amp; apt-get install -y \\\n    git\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#3-copy","title":"3. COPY","text":"<p>Copies files or directories from the build context to the container's filesystem. <pre><code>COPY &lt;src&gt; &lt;dest&gt;\n</code></pre> Example: <pre><code>COPY . /app\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#4-workdir","title":"4. WORKDIR","text":"<p>Sets the working directory for any RUN, CMD, ENTRYPOINT, COPY, and ADD instructions that follow it. <pre><code>WORKDIR /path/to/directory\n</code></pre> Example: <pre><code>WORKDIR /app\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#5-cmd","title":"5. CMD","text":"<p>Specifies the default command to run when the container starts. <pre><code>CMD [\"executable\", \"param1\", \"param2\"]\n</code></pre> Example: <pre><code>CMD [\"dotnet\", \"MyApi.dll\"]\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#6-entrypoint","title":"6. ENTRYPOINT","text":"<p>Specifies the command to run when the container starts, allowing arguments to be passed. <pre><code>ENTRYPOINT [\"executable\", \"param1\", \"param2\"]\n</code></pre> Example: <pre><code>ENTRYPOINT [\"dotnet\", \"MyApi.dll\"]\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#7-expose","title":"7. EXPOSE","text":"<p>Informs Docker that the container listens on specific network ports at runtime. <pre><code>EXPOSE &lt;port&gt; [&lt;port&gt;/&lt;protocol&gt;...]\n</code></pre> Example: <pre><code>EXPOSE 80\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#8-env","title":"8. ENV","text":"<p>Sets environment variables. <pre><code>ENV &lt;key&gt; &lt;value&gt;\n</code></pre> Example: <pre><code>ENV ASPNETCORE_ENVIRONMENT=Production\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#9-arg","title":"9. ARG","text":"<p>Defines build-time variables. <pre><code>ARG &lt;name&gt;[=&lt;default value&gt;]\n</code></pre> Example: <pre><code>ARG CONNECTION_STRING\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#10-volume","title":"10. VOLUME","text":"<p>Creates a mount point and marks it as holding externally mounted volumes from native host or other containers. <pre><code>VOLUME /path/to/volume\n</code></pre> Example: <pre><code>VOLUME /var/log/app\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#11-label","title":"11. LABEL","text":"<p>Adds metadata to an image. <pre><code>LABEL &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; ...\n</code></pre> Example: <pre><code>LABEL maintainer=\"John Doe &lt;john@example.com&gt;\"\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#12-user","title":"12. USER","text":"<p>Sets the user or UID to use when running the image. <pre><code>USER &lt;username | UID&gt;\n</code></pre> Example: <pre><code>USER appuser\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#13-healthcheck","title":"13. HEALTHCHECK","text":"<p>Defines a command to periodically check the container's health. <pre><code>HEALTHCHECK [OPTIONS] CMD &lt;command&gt;\n</code></pre> Example: <pre><code>HEALTHCHECK --interval=30s --timeout=3s \\\n  CMD curl -f http://localhost/health || exit 1\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#14-onbuild","title":"14. ONBUILD","text":"<p>Adds a trigger instruction when the image is used as the base for another build. <pre><code>ONBUILD &lt;INSTRUCTION&gt;\n</code></pre> Example: <pre><code>ONBUILD COPY . /app\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#15-stopsignal","title":"15. STOPSIGNAL","text":"<p>Sets the system call signal that will be sent to the container to exit. <pre><code>STOPSIGNAL signal\n</code></pre> Example: <pre><code>STOPSIGNAL SIGTERM\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#16-shell","title":"16. SHELL","text":"<p>Overrides the default shell used for the shell form of commands. <pre><code>SHELL [\"executable\", \"parameters\"]\n</code></pre> Example: <pre><code>SHELL [\"/bin/bash\", \"-c\"]\n</code></pre></p>"},{"location":"appendix/dockerfile-cheat-sheet/#cmd-vs-entrypoint","title":"CMD vs ENTRYPOINT","text":"<p>CMD and ENTRYPOINT are used to specify the default command to run when a container is started. However, they have different behaviors and can be used together in different ways depending on the requirements of your Docker image.</p> <ul> <li> <p>CMD:</p> </li> <li> <p>Sets default command and/or parameters.</p> </li> <li>Can be overridden from the command line.</li> <li> <p>Last <code>CMD</code> instruction takes effect if multiple are present.</p> </li> <li> <p>ENTRYPOINT:</p> </li> <li> <p>Specifies main executable to run.</p> </li> <li>Allows arguments to be passed.</li> <li>Arguments passed to <code>docker run</code> are appended to the <code>ENTRYPOINT</code> command.</li> <li>Last <code>ENTRYPOINT</code> instruction takes effect if multiple are present.</li> </ul> <p>Best Practices:</p> <ul> <li>Use CMD for default command and parameters.</li> <li>Use ENTRYPOINT for main executable, allowing additional arguments.</li> </ul> <p>Example:</p> <pre><code>ENTRYPOINT [\"dotnet\", \"MyApi.dll\"]\n</code></pre> <p>In this example, <code>dotnet MyApi.dll</code> is the main executable, with any additional arguments passed when running the container.</p>"},{"location":"appendix/dockerfile-cheat-sheet/#copy-vs-add","title":"COPY vs ADD","text":"<p>COPY and ADD are used to copy files and directories from the host machine into the container's filesystem. While they have similar functionalities, there are some differences between them.</p> <p>COPY Instruction:</p> <p>The COPY instruction copies files or directories from the build context (i.e., the directory containing the Dockerfile) into the container's filesystem. It can copy local files/directories as well as files/directories from URLs. However, it does not support extracting files from compressed archives (e.g., .tar.gz).</p> <p>ADD Instruction:</p> <p>The ADD instruction has the same functionality as COPY, but it also supports additional features such as extracting compressed archives (e.g., .tar.gz) and copying files from URLs. However, because of these additional features, it's considered less predictable and is recommended to use COPY instead unless the extra functionality of ADD is specifically required.</p> Feature COPY ADD Functionality Copies files/directories from build context Same as COPY, plus supports additional features like extracting compressed archives and copying files from URLs Predictability More predictable and straightforward Provides additional functionality but less predictable Best Practice Preferred for basic file copying tasks Use sparingly, only when additional features are needed <p>In summary, <code>COPY</code> is preferred for basic file copying tasks due to its predictability, while <code>ADD</code> offers additional functionality but should be used with caution.</p>"},{"location":"appendix/dockerfile-cheat-sheet/#references","title":"References","text":"<ul> <li>Dockerfile reference</li> </ul>"},{"location":"appendix/git-cheat-sheet/","title":"Git Commands","text":"<p>In this article, I am going to present a comprehensive cheat sheet of commonly used Git commands with examples. </p>"},{"location":"appendix/git-cheat-sheet/#installing-git","title":"Installing git","text":"<p>Here are the commands to install Git on different operating systems:</p> <pre><code># Ubuntu/Debian:\nsudo apt-get install git\n\n# MacOS (using Homebrew):\nbrew install git\n\n# Windows OS (using choco)\nchoco install git\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#setting-up-git-configuration","title":"Setting up git configuration:","text":"<p>To begin, it's important to configure your Git settings, associating your name and email with your commits. Use the following commands to set your name and email respectively:</p> <pre><code>git config --global user.name \"anji.keesari\"\ngit config --global user.email \"anjkeesari@gmail.com\"\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#caching-credentials","title":"Caching credentials:","text":"<p>Typing in login credentials repeatedly can be time consuming. To streamline this process, you can store your credentials in the cache using the command:</p> <pre><code>git config --global credential.helper cache\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#enable-automatic-coloring-of-git-output","title":"Enable automatic coloring of Git output","text":"<p>This command is used to enable automatic coloring of Git output in the command line interface. Enabling this option enhances the readability of Git's output by applying different colors to various elements.</p> <pre><code>git config --global color.ui auto\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#checking-git-configuration","title":"Checking git configuration:","text":"<p>To verify your Git configuration, including your username and email, use the following command:</p> <pre><code>git config -l\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#initializing-git","title":"Initializing git","text":"<p>Before diving into Git commands, you need to initialize a new Git repository locally in your project's root directory. Execute the command:</p> <pre><code>git init\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#git-clone","title":"Git clone","text":"<p>To work on an existing Git repository, you can clone it using the command</p> <pre><code>git clone &lt;repository-url&gt;\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#adding-files-to-the-staging-area","title":"Adding files to the staging area:","text":"<p>To stage changes and prepare them for commit, use the git add command. You can add specific files or entire directories to the staging area using the following commands:</p> <pre><code>git add &lt;file-name&gt;             # Add a specific file\ngit add .                       # Add all changes in the current directory (excluding deletions)\ngit add test*                   # Add all files starting with 'test' in the current directory\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#committing-changes","title":"Committing changes:","text":"<p>Committing changes captures a snapshot of your code at a specific point in time. Use the following commands to commit your changes:</p> <pre><code>git commit -m \"(message)\"       # Commits the changes with a custom message\ngit commit -am \"(message)\"      # Adds all changes to staging and commits them with a custom message\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#git-log","title":"Git log","text":"<p>To view the commit history of a repository, use the <code>git log</code> command. It provides you with an overview of past commits and their respective details. Additionally, you can use <code>git log -p</code> to see the commit history along with the changes made to each file.</p> <pre><code>#  shows the commit history for the current repository:\ngit log\n# commit's history including all files and their changes:\ngit log -p\n\npress q any time to quit\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#commit-details","title":"Commit details","text":"<p>Use this command to see a specific commit in details</p> <p><pre><code>git show commit-id\n</code></pre> Note: replace <code>commit-id</code> with the id of the commit that you can find in the git log</p>"},{"location":"appendix/git-cheat-sheet/#git-status","title":"Git status","text":"<p>This command will show the status of the current repository including staged, unstaged, and untracked files.</p> <pre><code>git status\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#undoing-changes","title":"Undoing changes:","text":"<p>If you have already pushed a commit to a remote repository and want to undo it, you need to create a new commit that undoes the changes. The following command will create a new commit that undoes the changes introduced by the specified commit:</p> <p><pre><code>git revert &lt;commit-id&gt;\n</code></pre> Replace  with the ID of the commit you want to undo. <p>If you have already committed changes and want to undo the most recent commit, you have a few options depending on your desired outcome: - Undo the commit and keep the changes as unstaged modifications: <pre><code>git reset HEAD^\n</code></pre> Undo the commit and completely discard the changes: <pre><code>git reset --hard HEAD^\n</code></pre></p>"},{"location":"appendix/git-cheat-sheet/#viewing-differences","title":"Viewing differences","text":"<p>To compare the differences between versions, you can use the git diff command. It displays the changes made to files since the last commit. </p> <pre><code>git diff\n</code></pre> <p>This will show the line-by-line differences between the current state of the files and the last committed version.</p>"},{"location":"appendix/git-cheat-sheet/#pushing-changes","title":"Pushing changes","text":"<p>To push your local commits to a remote repository, you need to use following command.</p> <pre><code>git push origin &lt;branch-name&gt;\n\n# if you haven't set the upstream branch yet, you can use this\n\ngit push --set-upstream origin aspnet-api\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#pulling-changes","title":"Pulling changes","text":"<p>Use this command to incorporate the latest changes from a remote repository into your local repository.</p> <pre><code>git pull origin &lt;branch-name&gt;\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#git-fetch","title":"Git fetch","text":"<p>To fetch the latest changes from the remote repository without merging them into your local branches.</p> <pre><code>git fetch\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#creating-a-new-branch","title":"Creating a new branch:","text":"<p>To create a new branch in Git, you can use the git branch command followed by the name of the branch you want to create. </p> <pre><code>git branch &lt;branch-name&gt;\n\n# Creates a new branch, `aspnet-api` is name of the branch here\ngit branch aspnet-api\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#switching-branch","title":"Switching branch:","text":"<p>To switch to a different branch in your Git repository, you can utilize the <code>git checkout</code> command followed by the name of the branch you want to switch to. </p> <pre><code>git checkout &lt;branch-name&gt;\n\n# Switched to branch 'aspnet-api'\ngit checkout aspnet-api\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#list-branches","title":"List branches","text":"<p>It will show a list of all branches and mark the current branch with an asterisk and highlight it in green.</p> <pre><code># Shows the list of all branches.\ngit branch  \n# List all local branches in repository. With -a: show all branches (with remote).\ngit branch -a \n\n# press q to quit\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#get-remote-urls","title":"Get remote URLs","text":"<p>You can see all remote repositories for your local repository with this command:</p> <pre><code>git remote -v\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#more-info-about-a-remote-repo","title":"More info about a remote repo","text":"<p>How to get more info about a remote repo in Git:</p> <pre><code>git remote show origin\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#merging-branches","title":"Merging branches","text":"<p>In Git, merging allows you to combine the changes from one branch into another. To merge a branch into another branch, you can use the git merge command followed by the name of the branch you want to merge. Here's an example:</p> <pre><code>git merge &lt;branch-name&gt;\n\n# For instance, if you want to merge the changes from the develop branch into the main branch\n# cd to the folder\ngit checkout main\ngit merge develop\n</code></pre> <p>After performing the merge, it's a good practice to check the status of your repository using git status to ensure that the merge was successful and there are no conflicts to resolve. Additionally, you can view the commit history using git log to see the merged commits and their details.</p> <pre><code>git status\ngit logs\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#delete-branch","title":"Delete branch","text":"<p>To delete a branch in Git, you can use either of the following commands:</p> <pre><code>git branch --delete &lt;branch-name&gt;\ngit branch -d &lt;branch-name&gt;\n\nexample\n# git branch to see list of branches before delete\ngit branch\n# delete the branch\ngit branch --delete &lt;branch-name&gt;\n# git branch again to see list of branches after delete\ngit branch\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#branch-from-a-previous-commit","title":"Branch from a previous commit","text":"<p>To create a new branch in Git using a specific commit hash, you can use the git branch command followed by the name of the branch and the commit hash</p> <pre><code>git branch branch_name &lt;commit-hash&gt;\n# Step 1: Create the branch from the commit hash\n\ngit branch new_branch 07615d50afde24d21e2180b90d3a0a58ec131980\n\n# this will create the local branch\n\n# Step 2: Switch to the new branch &amp; commit\n\ngit commit -am \u201c(message)\u201d \n</code></pre>"},{"location":"appendix/git-cheat-sheet/#rollback-an-old-commit","title":"Rollback an old commit","text":"<p>You can revert an old commit using its commit id. </p> <pre><code>git revert comit_id\n</code></pre>"},{"location":"appendix/git-cheat-sheet/#how-to-resolve-merge-conflicts-using-git-commands","title":"How to resolve merge conflicts using git commands","text":"<p>Resolving merge conflicts in Git involves editing the conflicted files to choose which changes to keep and which to discard, and then committing the resolved changes. Here's a step-by-step guide:</p> <ol> <li> <p>Check the status of your repository to see if there are any merge conflicts:</p> <p><pre><code>git status\n</code></pre> If there are merge conflicts, you will see a message indicating which files have conflicts.</p> </li> <li> <p>Open the conflicted files in a text editor and look for the conflict markers. The markers will look something like this:</p> <p><pre><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nThis is the content from the current branch.\n=======\nThis is the content from the branch you are merging.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; &lt;branch-name&gt;\n</code></pre> 1. Decide what changes you want to keep and remove the conflict markers and any unnecessary content. The final content should only include the changes you want to keep.</p> </li> <li> <p>Stage the changes using git add:     <pre><code>git add &lt;file-name&gt;\n</code></pre></p> </li> <li>Commit the changes to the repository:     <pre><code>git commit -m \"Resolved merge conflicts\"\n</code></pre></li> <li>Push the changes to the remote repository if necessary:     <pre><code>git push origin &lt;branch-name&gt;\n</code></pre></li> </ol>"},{"location":"appendix/git-cheat-sheet/#temporary-commits","title":"Temporary commits","text":"<p>In Git, you can use temporary commits to store modified, tracked files temporarily, allowing you to switch branches without losing your changes. This is a useful technique when you want to work on a different branch but are not ready to commit your changes yet.</p> <ul> <li>Stash your changes:  This will create a temporary commit that stores your modifications, allowing you to switch branches. <pre><code>git stash\n</code></pre></li> <li>Git stash list Running this command will show you the stash ID, along with a description that includes the branch name and commit message. <pre><code>git stash list\n</code></pre></li> <li>Git stash pop: his command is used to apply the changes from the top of the stash stack and remove that stash from the stack. <pre><code>git stash pop:\n</code></pre></li> <li>Git stash drop:  This command allows you to discard a stash from the stash stack. It permanently removes a stash and its changes, freeing up space in the stack. <pre><code>git stash drop: \n</code></pre></li> </ul>"},{"location":"introduction/about-author/","title":"About the Author","text":"<p>Anji Keesari is a software engineer and cloud architect with over 20 years of experience in the technology industry. He has been involved in numerous projects related to cloud computing, microservices architecture, and technologies such as Kubernetes, Terraform, and containers.</p> <p>Anji has hands-on experience deploying and managing Kubernetes clusters in production environments. He is also proficient in tools like ArgoCD and Helm, utilizing them to deploy microservices applications on Kubernetes. Anji also has extensive knowledge of containers and containerization technologies, including Docker and container orchestration tools such as Kubernetes.</p> <p>Apart from his expertise in Kubernetes and related tools, Anji has a strong background in Terraform, utilizing it to deploy infrastructure on various cloud platforms, including Azure and AWS.</p> <p>Anji has a passion for teaching and sharing his knowledge with others. He has written numerous articles and tutorials on Kubernetes, ArgoCD, and Helm, and published in Medium website.</p> <p>With his extensive knowledge and experience in Kubernetes, ArgoCD, and Helm, Anji is the perfect author for following two books:</p> <ul> <li>Building Microservices with Containers (A Practical Guide)</li> <li>Building Scalable Kubernetes Infrastructure for Microservices (A Practical Guide)</li> </ul> <p>Throughout his career, Anji have worked with various companies in diverse domains such as Banking, Healthcare, and Finance, across countries such as India, UK, and US. He is dedicated to making a significant impact in his workplace and helping others along the way.</p> <p>During his free time, Anji finds joy in various activities such as playing soccer, going hiking, exploring new places, and most importantly, spending quality time with his loved ones.</p> <p>For any questions, suggestions, or topic requests, feel free to drop him a message, and he'll get in touch when his schedule permits.</p> <p>Contact Information:</p> <ul> <li>Email: anjkeesari@gmail.com</li> <li>Website: https://anjikeesari.com</li> </ul>"},{"location":"introduction/acknowledgments/","title":"Acknowledgments","text":"<p>Writing a book is a collaborative effort, and I could not have done it without the help and support of many people.</p> <p>First and foremost, I would like to thank my family for their patience, understanding, and encouragement throughout this project, they scarified lot of (long) weekends. Their love and support kept me going during the long hours of writing and editing.</p> <p>During this book writing I had to refer lot of online materials, I would also like to thank the many individuals and organizations who have contributed to the development of Kubernetes, ArgoCD, Helm, Terraform, and containerization technologies. Without their hard work and dedication, this book would not be possible.</p> <p>Finally, I would like to thank the readers of this book for their interest and support. I hope that this book will be a valuable resource for anyone who wants to learn how to build and deploy microservices applications on a Kubernetes using ArgoCD and Helm.</p> <p>Thank you all for your contributions and support.</p> <p>Warm regards,</p> <p>Anji Keesari</p>"},{"location":"introduction/introduction/","title":"Introduction","text":"<p>Welcome to <code>Building Microservices with Containers: A Practical Guide</code>. In today's rapidly growing technological landscape, the demand for scalable, flexible, and resilient software solutions is necessary. In response to this demand, the architecture of choice for many modern applications is microservices. Microservices enables the development of complex systems as a set of small, independently deployable services.</p> <p>This book is your detailed guide to understanding and implementing microservices architecture using containerization technology, specifically Docker. Whether you're a regular application developer looking to adopt microservices or a new to the technology, this book will provide you with the knowledge and hands-on experience necessary to succeed in building scalable and maintainable applications.</p>"},{"location":"introduction/introduction/#why-microservices","title":"Why Microservices?","text":"<p>Before looking into the technical details, let's briefly explore why microservices have become the architecture of choice for many organizations. Microservices offer several advantages over traditional monolithic architectures, including:</p> <ul> <li>Scalability: Microservices allow individual components of an application to scale independently, enabling better resource utilization and improved performance.</li> <li>Flexibility: With microservices, teams can choose the most appropriate technology stack for each service, leading to greater flexibility and innovation.</li> <li>Resilience: Isolating services from each other reduces the impact of failures, making the overall system more resilient.</li> <li>Continuous Delivery: Microservices facilitate continuous delivery and deployment practices, enabling teams to release updates quickly and frequently.</li> </ul>"},{"location":"introduction/introduction/#why-containers","title":"Why Containers?","text":"<p>While microservices offer numerous benefits, managing a large number of services can be challenging. This is where containerization comes into play. Containers provide lightweight, portable, and isolated environments for running applications, making it easier to package, deploy, and manage microservices at scale. Docker, one of the most popular containerization platforms, has revolutionized the way developers build, ship, and run applications.</p>"},{"location":"introduction/introduction/#what-youll-learn","title":"What You'll Learn","text":"<p>In this book, we'll start by covering the fundamentals of microservices architecture and Docker containerization. We'll then guide you through the process of building and deploying microservices using a variety of technologies, including .NET Core, Node.js, React.js, and SQL databases. Along the way, you'll learn how to:</p> <ul> <li>Containerize microservices using Docker.</li> <li>Orchestrate containers with Docker Compose.</li> <li>Implement authentication and authorization using Keycloak.</li> <li>Build web applications with popular frameworks like .NET Core MVC and React.js.</li> <li>Set up and manage databases within containers using SQL Server and PostgreSQL.</li> <li>Deploy and scale microservices in a production environment.</li> </ul> <p>Each chapter includes practical, hands-on tutorials and real-world examples to help reinforce your understanding of the concepts covered. By the end of this book, you'll have the knowledge and skills to design, build, and deploy microservices-based applications with confidence.</p>"},{"location":"introduction/introduction/#who-this-book-is-for","title":"Who This Book Is For","text":"<p>This book is designed for developers, architects, and DevOps engineers who are interested in adopting microservices architecture using containerization technology. Whether you're new to microservices or looking to expand your knowledge, this book will provide you with the essential tools and techniques to succeed in today's growing software development landscape.</p> <p>Developers:</p> <ul> <li>If you're a developer looking to moving from traditional monolithic architectures to microservices, this book will provide you with the necessary knowledge and practical skills to design, develop, and deploy microservices-based applications using containerization technology.</li> <li>Whether you specialize in a specific programming language or framework, the hands-on tutorials and real-world examples in this book will help you gain a deeper understanding of how to implement microservices using a variety of technologies, including .NET Core, Node.js, React.js, SQL databases, and more.</li> </ul> <p>Architects:</p> <ul> <li>For architects responsible for designing and planning the architecture of modern applications, this book will serve as a comprehensive guide to understanding the principles, patterns, and best practices of microservices architecture.</li> <li>You'll learn how to design scalable, resilient, and maintainable systems using microservices and containerization technology, and how to address common challenges such as service discovery, communication, and data management in distributed environments.</li> </ul> <p>DevOps Engineers:</p> <ul> <li>If you're a DevOps engineer tasked with managing the deployment, scaling, and monitoring of microservices-based applications, this book will help you with the necessary skills to leverage containerization tools like Docker and orchestration platforms like Kubernetes.</li> <li>You'll learn how to automate the deployment process, implement continuous integration and continuous delivery (CI/CD) pipelines, and ensure the reliability and performance of microservices in production environments.</li> </ul> <p>Students and Researchers:</p> <ul> <li>This book can also be valuable for students and researchers studying software engineering,  and cloud computing. It provides a practical, hands-on approach to learning about microservices architecture and containerization technology, with real-world examples and case studies to illustrate key concepts.</li> </ul>"},{"location":"introduction/introduction/#key-benefits-of-reading-this-book","title":"Key Benefits of Reading This Book:","text":"<p><code>Building Microservices with Containers: A Practical Guide</code> offers a lot of benefits to readers at various stages of their application development journey in understanding and implementing microservices architecture with containerization technology. Here are some key benefits you can expect from reading this book:</p> <p>Hands-On Tutorials:</p> <ul> <li>Benefit from step-by-step tutorials and real-world examples that guide you through the process of building and deploying microservices using Docker containers.</li> <li>Gain practical experience by working on hands-on exercises and projects designed to reinforce your learning and enhance your skills.</li> </ul> <p>Diverse Technology Stack:</p> <ul> <li>Explore a diverse range of technologies and frameworks, including .NET Core, Node.js, React.js, SQL databases, Docker, and Kubernetes.</li> <li>Learn how to choose the right tools and technologies for your specific use case, and how to integrate them effectively to build scalable and resilient applications.</li> </ul> <p>Transition from Monolithic to Microservices:</p> <ul> <li>Understand the benefits and challenges of transitioning from monolithic architectures to microservices, and how to plan and execute a successful migration strategy.</li> <li>Learn how to decompose monolithic applications into smaller, loosely-coupled services, and how to leverage containerization to improve scalability, flexibility, and resilience.</li> </ul> <p>Whether you're a developer, architect, DevOps engineer, student, or researcher, <code>Building Microservices with Containers: A Practical Guide</code> offers valuable insights, practical skills, and career advancement opportunities that will empower you to succeed in today's dynamic and fast-paced software development landscape.</p>"},{"location":"introduction/introduction/#hands-on-labs","title":"Hands-On Labs","text":"<p>Here is the high-level list of labs we will cover in this chapter:</p> <p>Lab-1: Getting Started with Microservices - In this lab, we'll introduce you to the concept of microservices and explain their importance in modern application development. You'll gain a high-level understanding of microservices architecture and its benefits.</p> <p>Lab-2: Getting Started with Docker - Here, we'll look into Docker, the modern containerization technology. You'll learn how to install docker, run your first container, and explore basic docker commands.</p> <p>Lab-3: Create your First Containerized Microservice with .NET Core - This lab guides you through creating a microservice using .NET Core and containerizing it with Docker. You'll learn how to write Dockerfiles and build container images for .NET Core microservices.</p> <p>Lab-5: Create your Second Containerized Microservice with Node.js - In this lab, we switch gears to Node.js and create another microservice. You'll containerize a Node.js-based microservice and understand the differences compared to .NET Core.</p> <p>Lab-6: Create your First Containerized Website using ASP.NET Core MVC - Now, it's time to create a containerized website using ASP.NET Core MVC. You'll build a web application, package it as a Docker image, and run it as a container.</p> <p>Lab-7: Create your Second Containerized Website using React JS - In this lab, we'll focus on front-end development by creating a React.js-based website. You'll containerize a React application and understand how to work with front-end containers.</p> <p>Lab-8: Create your First Database with SQL Server - Databases are an essential part of microservices. In this lab, we'll set up a SQL Server database within a container. You'll learn how to create and connect to containerized databases.</p> <p>Lab-9: Create your Second Database with PostgreSQL - PostgreSQL is another popular database choice. This lab guides you through running PostgreSQL in a docker container and executing scripts. You'll understand how to work with different database engines within containers.</p> <p>Lab-10: Running Keycloak application in a Docker Container - External services play a important role in microservices. In this lab, we'll run Keycloak application, an identity and access management system, in a Docker container. You'll configure and interact with Keycloak within the containerized environment.</p> <p>Lab-11: Running Drupal website in a Docker Container - Continuing with external services, we'll set up Drupal website, a content management system, in a Docker container. You'll explore how to work with content management systems within containers.</p> <p>These hands-on labs provide a practical foundation for building and containerizing microservices. By the end of these labs, you'll have hands-on experience with various technologies and a clear understanding of how to create and run microservices and external services in containers. This knowledge will be invaluable as we progress through the chapters and explore more advanced microservices concepts and deployment strategies.</p>"},{"location":"introduction/introduction/#categories-of-labs","title":"Categories of Labs:","text":"<p>Labs in this Chapter are categorized into four areas, these categories provide a structured approach to learning containerization across different aspects of web development, from APIs and websites to databases and external services. By completing labs in each category, participants will gain comprehensive knowledge and skills essential for modern application development  practices. </p> <ul> <li>Creating Containerized APIs (API Development)</li> <li>Creating Containerized Websites (Website Development)</li> <li>Setting Up Databases in Containers (Database Containers)</li> <li>Running External Services in Docker Containers (External Services)</li> </ul>"},{"location":"introduction/introduction/#creating-containerized-apis","title":"Creating Containerized APIs","text":"<p>Labs created within this category, you'll learn how to create containerized APIs using technologies like .NET Core Web API, Node.js.</p> <p>.NET Core Web API:</p> <ol> <li> <p>Introduction to .NET Core Web API: We'll start by introducing you to .NET Core Web API, a cross-platform framework for building Restful services.</p> </li> <li> <p>Setting Up an .NET Core Web API Project: We'll guide you through setting up a new .NET Core Web API project.</p> </li> <li> <p>Containerization with Docker: You'll learn how to package your .NET Core Web API as a Docker container. We'll provide guidance on creating a Dockerfile for your web application.</p> </li> <li> <p>Running the Containerized .NET Core Web API: You'll see how to run your containerized .NET Core Web API locally and understand how containers simplify deployment.</p> </li> </ol> <p>Node.js APIs:</p> <ol> <li> <p>Introduction to Node.js: Node.js is a popular JavaScript library for building Restful services. We'll introduce you to Node.js and explain its role in modern Rest APIs development.</p> </li> <li> <p>Creating a Node.js Rest API: You'll learn how to create a Node.js API from scratch. </p> </li> <li> <p>Containerization with Docker: Similar to .NET Core Web API, we'll guide you through containerizing your Node.js API. You'll create a Dockerfile for your Restful service.</p> </li> <li> <p>Running the Containerized Node.js API: You'll see how to run your containerized Node.js API locally. </p> </li> </ol> <p>By the end of these labs, you'll have hands-on experience with .NET Core Web API and Node.js along with the knowledge of how to containerize web applications. These skills are essential as we move forward to deploy these containerized websites alongside microservices in later chapters. </p>"},{"location":"introduction/introduction/#creating-containerized-websites","title":"Creating Containerized Websites","text":"<p>Labs created within this category, you'll learn how to create containerized websites using technologies like ASP.NET Core, MVC and React.js.</p> <p>ASP.NET Core MVC:</p> <ol> <li> <p>Introduction to ASP.NET Core MVC: We'll start by introducing you to ASP.NET Core MVC, a cross-platform framework for building web applications. You'll understand its role in creating dynamic web content.</p> </li> <li> <p>Setting Up an ASP.NET Core MVC Project: We'll guide you through setting up a new ASP.NET Core MVC project.</p> </li> <li> <p>Containerization with Docker: You'll learn how to package your ASP.NET Core MVC application as a Docker container. We'll provide guidance on creating a Dockerfile for your web application.</p> </li> <li> <p>Running the Containerized ASP.NET Core MVC Application: You'll see how to run your containerized ASP.NET Core MVC application locally and understand how containers simplify deployment.</p> </li> </ol> <p>React.js:</p> <ol> <li> <p>Introduction to React.js: React.js is a popular JavaScript library for building user interfaces. We'll introduce you to React.js and explain its role in modern web development.</p> </li> <li> <p>Creating a React.js Application: You'll learn how to create a React.js application from scratch. </p> </li> <li> <p>Containerization with Docker: Similar to ASP.NET Core MVC, we'll guide you through containerizing your React.js application. You'll create a Dockerfile for your web app.</p> </li> <li> <p>Running the Containerized React.js Application: You'll see how to run your containerized React.js application locally. </p> </li> </ol> <p>By the end of these labs, you'll have hands-on experience with ASP.NET Core MVC and React.js, along with the knowledge of how to containerize web applications. These skills are essential as we move forward to deploy these containerized websites alongside microservices in later chapters. </p>"},{"location":"introduction/introduction/#setting-up-databases-in-containers","title":"Setting Up Databases in Containers","text":"<p>Labs created within this category, we'll learn setting up databases within containers for microservices data storage. You'll learn how to create containerized database instances using SQL Server and PostgreSQL.</p> <p>Microservices often rely on databases to store and manage data. Containerizing databases offers numerous advantages, such as isolation, portability, and versioning. In this section, we'll focus on two popular database systems: SQL Server and PostgreSQL.</p> <p>SQL Server:</p> <ol> <li> <p>Introduction to SQL Server: We'll introduce you to SQL Server, a robust relational database management system (RDBMS) developed by Microsoft.</p> </li> <li> <p>Containerization with Docker: You'll learn how to containerize SQL Server by pulling an official SQL Server Docker image from the Azure Container registry or Docker Hub.</p> </li> <li> <p>Running SQL Server in a Docker Container: We'll guide you through running a SQL Server container, configuring database settings, and connecting to the containerized SQL Server instance.</p> </li> <li> <p>Data Management: You'll explore data management tasks within a containerized SQL Server, such as creating databases, tables, and performing CRUD (Create, Read, Update, Delete) operations.</p> </li> <li> <p>Connecting to database locally: Finally you'll explore different tools like SQL Server Management Studio (SSMS) and Azure data studio for connecting to containerized SQL Server database.</p> </li> </ol> <p>PostgreSQL:</p> <ol> <li> <p>Introduction to PostgreSQL: We'll introduce you to PostgreSQL, a powerful open-source relational database system known for its scalability and extensibility.</p> </li> <li> <p>Containerization with Docker: You'll learn how to containerize PostgreSQL by pulling an official PostgreSQL Docker image from the Docker Hub.</p> </li> <li> <p>Running PostgreSQL in a Docker Container: We'll guide you through running a PostgreSQL container, configuring database settings, and connecting to the containerized PostgreSQL instance.</p> </li> <li> <p>Data Management: You'll explore data management tasks within a containerized PostgreSQL database, including creating databases, tables, and executing SQL queries.</p> </li> <li> <p>Connecting to database locally: Finally you'll explore different tools like <code>PSQL</code> and Pgadmin4 for connecting to containerized PostgreSQL database.</p> </li> </ol> <p>By the end of these labs, you'll have hands-on experience with containerized SQL Server and PostgreSQL databases, understanding their role in microservices data storage. These skills are important as you proceed through the chapters, where microservices will interact with these containerized databases to retrieve and store data. </p>"},{"location":"introduction/introduction/#running-external-services-in-containers","title":"Running External Services in Containers","text":"<p>Labs created within this category, we'll learn integration of external services into your microservices architecture. You'll learn how to run external services like Keycloak and Drupal in Docker containers, enhancing the capabilities of your microservices.</p> <p>External services play a importent role in microservices architecture, providing essential functionalities such as authentication and content management. Containerizing these external services offers several advantages, including consistency and simplified deployment. In this section, we'll focus on two prominent external services: Keycloak and Drupal.</p> <p>Keycloak:</p> <ol> <li> <p>Introduction to Keycloak: Keycloak is an open-source identity and access management system. We'll introduce you to Keycloak and explain its significance in microservices authentication.</p> </li> <li> <p>Containerization with Docker: You'll learn how to containerize Keycloak by pulling an official Keycloak Docker image from the Docker Hub.</p> </li> <li> <p>Running Keycloak in a Docker Container: We'll guide you through running a Keycloak container, configuring realms, users, and roles within the containerized Keycloak instance.</p> </li> <li> <p>Testing the Keycloak Application Locally: Finally you'll see how to browse your containerized Keycloak application locally and login into admin portal and intacting with Keycloak application. </p> </li> </ol> <p>Drupal:</p> <ol> <li> <p>Introduction to Drupal: Drupal is a popular open-source content management system (CMS). We'll introduce you to Drupal and its role in managing content for microservices.</p> </li> <li> <p>Containerization with Docker: You'll learn how to containerize Drupal by pulling an official Drupal Docker image from the Docker Hub.</p> </li> <li> <p>Running Drupal in a Docker Container: We'll guide you through running a Drupal container, setting up a website, and managing content within the containerized Drupal instance.</p> </li> <li> <p>Testing the Drupal Website Locally: Finally you'll see how to browse your containerized Drupal Website locally and login into drupal portal and intacting with drupal website.</p> </li> </ol> <p>By the end of these labs, you'll have hands-on experience with containerized Keycloak and Drupal instances, understanding how to integrate them seamlessly into your microservices ecosystem. These skills are essential as you proceed through the chapters, where microservices will rely on these external services for authentication, authorization, and content management.</p>"},{"location":"introduction/toc/","title":"Table of Contents","text":"<ul> <li>About the Author</li> <li>Acknowledgments</li> <li>Introduction</li> </ul> <ul> <li>Chapter-1: Getting Started with Microservices<ul> <li>What are Microservices?</li> <li>Microservices vs Monolithic Architectures</li> <li>Advantages of Microservices</li> <li>Challenges and Considerations</li> <li>Key Technologies and Tools</li> <li>Microservices Communication</li> <li>Domain-Driven Design (DDD)</li> <li>Task-1: Identify Microservices for the book</li> <li>Task-2: Identify the List of Git Repositories Needed</li> <li>Task-3: Create new Azure DevOps Organization</li> <li>Task-4: Create new Azure DevOps Project</li> </ul> </li> <li>Chapter-2: Docker Fundamentals<ul> <li>Overview</li> <li>What is Docker?</li> <li>Why use Docker?</li> <li>Docker concepts</li> <li>Container orchestration</li> <li>Docker Desktop</li> <li>Install Docker</li> <li>Docker Commands</li> </ul> </li> <li>Chapter-3: Getting Started with Docker<ul> <li>Step 1: Get the Sample Application</li> <li>Step 2: Create Docker Image</li> <li>Step 3: Create Docker Container</li> <li>Step 4: Port Binding</li> <li>Step 5: Browse the Frontend Application</li> <li>Step 6: View Docker Logs</li> <li>Step 7: Docker Commands</li> </ul> </li> <li>Chapter-4: Create Your First Microservice with .NET Core Web API<ul> <li>Step-1: Create a new repo in azure DevOps</li> <li>Step-2: Clone the repo from azure DevOps</li> <li>Step-3: Create a new .NET Core Web API project</li> <li>Step-4: Test the new .NET core Web API project</li> <li>Step-5: Add Dockerfiles to the API project</li> <li>Step-6: Docker Build &amp; Run</li> <li>Step-7: Push docker container to ACR</li> <li>Step-8: Pull docker container from ACR</li> </ul> </li> <li>Chapter-5: Create Your Second Microservice with Node.js<ul> <li>Step-1: Setup repository in Azure DevOps.</li> <li>Step-2: Create a new Node JS API project</li> <li>Step-3: Test the Node JS API project</li> <li>Step-4: Add Dockerfiles to the MVC project</li> <li>Step-5: Docker build locally</li> <li>Step-6: Docker run locally</li> <li>Step-7: Push docker container to ACR</li> </ul> </li> <li>Chapter-6: Create Your First Website using .NET Core MVC Application<ul> <li>Step-1: Create a new ASP.NET Core Web App (MVC project)</li> <li>Step-2: Test the new ASP.NET core Web App project</li> <li>Step-3: Update home page contents[Optional]</li> <li>Step-4: Add Dockerfiles to the MVC project</li> <li>Step-5: Docker Build locally</li> <li>Step-6: Docker Run locally</li> <li>Step-7: Push docker container to ACR</li> </ul> </li> <li>Chapter-7: Create Your Second Website using React.js<ul> <li>Step-1: Install Node.js and NPM</li> <li>Step-2: Create a new React JS application</li> <li>Step-3: Add Dockerfiles to the MVC project</li> <li>Step-4: Docker Build locally</li> <li>Step-5: Docker Run locally</li> <li>Step-6: Push docker container to ACR</li> </ul> </li> <li>Chapter-8: Create your First Database with SQL Server<ul> <li>Benefits of SQL Server Container</li> <li>Step-1: Setup Git Repository for SQL Server database</li> <li>Step-2: Create Folder Structure for SQL Server database</li> <li>Step-3: Add Dockerfiles to the Database Project</li> <li>Step-4: Test the SQL Server database connection using SSMS</li> <li>Step-5: Test the SQL server database connection using Azure Data Studio</li> <li>Step-6: Push Docker Container to ACR</li> </ul> </li> <li>Chapter-9: Setting up PostgreSQL database in a Docker Container<ul> <li>Step-1: Setup Git Repository for PostgreSQL database</li> <li>Step-2: Create Folder Structure for PostgreSQL database</li> <li>Step-3: Add Dockerfiles to the Database Project</li> <li>Step-4: Create Docker Compose file</li> <li>Step-5: Test the PostgreSQL database connection from psql tool</li> <li>Step-6: Test the PostgreSQL database from pgadmin4 tool</li> <li>Step-7: Push Docker Container to ACR</li> </ul> </li> <li>Chapter-10: Setting up Keycloak in a Docker Container<ul> <li>Step-1: Setup repository for Keycloak in Azure DevOps</li> <li>Step-2: Create Keycloak project</li> <li>Step-3: Keycloak setup with docker compose</li> <li>Step-3.1: Setup Keycloak Service</li> <li>Step-3.2: Setup Keycloak Service with PostgreSQL database</li> <li>Step-4: Keycloak setup with Dockerfile</li> <li>Step-4.1: Create Dockerfile</li> <li>Step-4.2: Docker build locally</li> <li>Step-4.3: Docker run locally</li> <li>Step-5: Publish the Keycloak docker container to container registry</li> </ul> </li> <li>Chapter-11: Setting up Drupal in a Docker Container<ul> <li>Step-1: Setup Git Repository for Drupal</li> <li>Step-2: Create Drupal Project</li> <li>Step-3: Create Docker Compose file</li> <li>Step-4: Build Drupal locally</li> <li>Step-4.3: Run Drupal Container locally</li> </ul> </li> <li>Appendix:<ul> <li>Appendix-A: Git Cheat Sheet</li> <li>Appendix-B: Docker Cheat Sheet</li> <li>Appendix-C: Dockerfile Cheat Sheet</li> </ul> </li> </ul>"},{"location":"microservices/1.getting-started/","title":"Chapter-1: Getting Started with Microservices","text":""},{"location":"microservices/1.getting-started/#overview","title":"Overview","text":"<p>Welcome to the first chapter of our book. In this chapter, we will begin our journey by understanding microservices architectures and how they are different comparing with traditional monolithic architectures. We'll also learn the advantages of the microservices architectures, including scalability, flexibility, and easier maintenance. we will also learn challenges with microservices and considerations that need to be carefully addressed, key technologies and communication patterns. Finally we will perform four tasks such as identifying list of microservices, git repos needed, create org and project in azure devops to continue our journey in this book.</p>"},{"location":"microservices/1.getting-started/#objective","title":"Objective","text":"<p>In this exercise, our objective is to accomplish and learn the following tasks:</p> <ul> <li>What are Microservices?</li> <li>Microservices vs Monolithic Architectures</li> <li>Advantages of Microservices</li> <li>Challenges and Considerations</li> <li>Key Technologies and Tools</li> <li>Microservices Communication</li> <li>Domain-Driven Design (DDD)</li> <li>Task-1: Identify Microservices for the book</li> <li>Task-2: Identify the List of Git Repositories Needed</li> <li>Task-3: Create new Azure DevOps Organization</li> <li>Task-4: Create new Azure DevOps Project</li> </ul>"},{"location":"microservices/1.getting-started/#what-are-microservices","title":"What are Microservices?","text":"<p><code>Microservices</code> are architectural style that structures an application as a collection of small, independent, and loosely coupled services. These services, known as microservices  , are designed to be self-contained and focused on specific functions or features of the application. Unlike monolithic applications, where all components are tightly integrated into a single codebase, microservices allow for the decomposition of an application into smaller, manageable parts.</p> <p>Key Characteristics:</p> <ul> <li>Autonomous and independently deployable</li> <li>Organized around business capabilities</li> <li>Technology-agnostic (can be built using different languages/platforms)</li> <li>Decentralized data management</li> <li>Fault isolation</li> </ul>"},{"location":"microservices/1.getting-started/#microservices-vs-monolithic-architectures","title":"Microservices vs Monolithic Architectures","text":"<p>Monolithic Architectures:</p> <ul> <li>In a monolithic architecture, the entire application is built as a single, unified codebase.</li> <li>All components of the application, including user interfaces, business logic, and data access layers, are tightly coupled.</li> <li>Scaling a monolithic application typically involves replicating the entire application, even if only specific parts require additional resources.</li> <li>Maintenance and updates often require making changes to the entire codebase, making it challenging to isolate and fix issues.</li> </ul> <p>Microservices:</p> <ul> <li>Microservices architecture promotes breaking down the application into smaller, independent services.</li> <li>Each microservice is responsible for a specific application's functionality.</li> <li>Microservices can be developed, deployed, and scaled independently.</li> <li>Updates and maintenance are easier to manage, as changes to one microservice do not impact the entire system.</li> </ul>"},{"location":"microservices/1.getting-started/#advantages-of-microservices","title":"Advantages of Microservices","text":"<p>Microservices architecture offers several advantages, including:</p> <ul> <li> <p>Scalability: Microservices can be easily scaled horizontally to handle increased traffic, ensuring that the system remains responsive during high-demand periods.</p> </li> <li> <p>Flexibility: Developers can work on individual microservices without affecting the entire application. This makes it easier to introduce new features, fix bugs, or update a specific service without disrupting the entire system.</p> </li> <li> <p>Easy Maintenance: Smaller, self-contained services are typically easier to maintain and manage. Updates and changes can be isolated to specific microservices, reducing the risk of unintended consequences.</p> </li> <li> <p>Improved Fault Isolation: When a microservice fails, it usually doesn't bring down the entire system. Failures are contained within the affected service, minimizing the impact on the overall application.</p> </li> <li> <p>Technology Agnosticism: Microservices allow you to use different technologies and programming languages for different services, which can be chosen based on the specific requirements of each service.</p> </li> <li> <p>Rapid Development: Smaller teams can work independently on microservices, enabling faster development cycles and quicker time-to-market for new features or products.</p> </li> <li> <p>Enhanced Testing: Isolated microservices can be tested more thoroughly, leading to better quality assurance and reduced testing complexity compared to monolithic applications.</p> </li> <li> <p>Easier Deployment: Smaller, independent services are easier to deploy, reducing the risk of deployment failures and making it possible to implement continuous integration and continuous delivery (CI/CD) practices.</p> </li> </ul>"},{"location":"microservices/1.getting-started/#challenges-and-considerations","title":"Challenges and Considerations","text":"<p>While microservices offer numerous advantages, they also come with their set of challenges and considerations that need to be carefully addressed. Careful planning and architectural decisions are important for realizing the benefits of microservices while mitigating their challenges.</p> <p>Challenges of microservices</p> <ul> <li> <p>Complexity: Microservices introduce complexity, as an application is divided into multiple services, each with its own codebase, data store, and dependencies. Managing the interactions between microservices and ensuring the overall system's integrity can be challenging.</p> </li> <li> <p>Data Consistency: Maintaining data consistency in a distributed microservices architecture can be complex. With each microservice managing its data, ensuring data synchronization and integrity across services is important.</p> </li> <li> <p>Distributed Systems Issues: Microservices are inherently distributed, which introduces challenges such as network latency, message serialization, and handling communication failures. Implementing robust error handling and resilience mechanisms becomes essential.</p> </li> <li> <p>Operational Complexity: Managing and monitoring a large number of microservices in a production environment can be operationally complex.  Tools and practices for deployment, monitoring, and scaling need to be in place to ensure smooth operations.</p> </li> </ul> <p>Considerations for Microservices Adoption</p> <ul> <li> <p>Application Complexity: Microservices are well-suited for complex, large-scale applications with multiple modules or functionalities. For simpler applications, a monolithic architecture may be more appropriate.</p> </li> <li> <p>Team Structure: Consider your organization's team structure. Microservices often align with small, cross-functional teams that can own and manage individual microservices. Ensure your teams have the necessary skills for microservices development and operations.</p> </li> <li> <p>Scalability and Performance: Microservices can provide scalability benefits, particularly for applications with varying workloads. Evaluate whether your application requires the ability to scale individual components independently.</p> </li> <li> <p>Frequent Updates: If your application requires frequent updates and releases, microservices can support continuous integration and deployment practices. Ensure you have the necessary CI/CD pipelines and infrastructure.</p> </li> </ul> <p>Choosing the Right Architecture</p> <p>The choice between monolithic and microservices architecture depends on various factors, including the complexity of the application, team structure, scalability requirements, and development speed. Monolithic architectures excel in simplicity and are suitable for smaller applications with straightforward requirements. Microservices, on the other hand, offer flexibility and scalability for larger, more complex applications but introduce operational complexities.</p>"},{"location":"microservices/1.getting-started/#key-technologies-and-tools","title":"Key Technologies and Tools","text":"<p>Microservices development relies on a set of essential technologies and tools that facilitate the creation, deployment, and management of individual microservices. </p> <ul> <li> <p>Docker: Docker is a containerization platform that allows developers to package applications and their dependencies into lightweight containers.  Docker containers provide consistency in deployment across different environments, ensuring that microservices run reliably on any system.</p> </li> <li> <p>DevContainers: DevContainers streamline the development and testing of microservices locally by providing a controlled, isolated, and consistent environment that enhances collaboration among team members and simplifies the management of complex microservices ecosystems.</p> </li> <li> <p>Kubernetes: Kubernetes is a container orchestration platform that automates the deployment, scaling, and management of containerized applications, including microservices. Kubernetes simplifies the management of microservices at scale, enabling features like load balancing, auto-scaling, and rolling updates.</p> </li> </ul> <ul> <li> <p>API Gateways: API gateways act as a front-end for microservices, providing a unified entry point for clients and handling tasks such as authentication, rate limiting, and request routing. API gateways simplify client interactions with microservices, centralize security controls, and enable API versioning and documentation.</p> </li> <li> <p>Continuous Integration/Continuous Deployment (CI/CD) Tools: CI/CD tools such as Azure DevOps, Argocd, Helmcharts automate the building, testing, and deployment of microservices, supporting rapid development and delivery. CI/CD pipelines streamline the development process, allowing for frequent updates and reducing the risk of errors.</p> </li> <li> <p>Monitoring and Observability Tools (e.g., Prometheus, Grafana, Jaeger): Monitoring and observability tools provide insights into the performance, availability, and behavior of microservices, helping to detect and troubleshoot issues. These tools ensure the reliability of microservices in production by offering real-time monitoring, logging, and tracing capabilities.</p> </li> </ul>"},{"location":"microservices/1.getting-started/#microservices-communication","title":"Microservices Communication","text":"<p>Microservices can communicate with each other using different communication patterns, both synchronous and asynchronous.</p> <p>Synchronous:</p> <ul> <li> <p>HTTP/HTTPS: Microservices can communicate over standard HTTP/HTTPS protocols, making it easy to create RESTful APIs or web services.    Synchronous communication is suitable for scenarios where immediate responses are required.</p> </li> <li> <p>gRPC: gRPC is a high-performance, language-agnostic remote procedure call (RPC) framework that allows microservices to communicate efficiently. It is ideal for scenarios where low-latency, binary-encoded communication is needed.</p> </li> </ul> <p>Asynchronous:</p> <ul> <li> <p>Message Queues (e.g., RabbitMQ, Apache Kafka): Microservices can exchange messages through message queues or publish-subscribe systems. Asynchronous communication is useful for decoupling services and handling background tasks or event-driven scenarios.</p> </li> <li> <p>Event Sourcing and Event-driven Architecture: In event-driven architecture, microservices issue and consume events to communicate changes or trigger actions. This pattern is beneficial for building scalable, loosely coupled systems that respond to real-time events.</p> </li> </ul>"},{"location":"microservices/1.getting-started/#domain-driven-design-ddd","title":"Domain-Driven Design (DDD)","text":"<p>Domain-Driven Design (DDD) is a set of principles, patterns, and techniques for designing applicatio with a focus on the domain of the problem being solved. In the context of microservices architecture, DDD plays a importantent role in helping you define the boundaries of your microservices and ensure that they align with your business domain. Here's how DDD techniques can be applied in microservices architecture:</p> <ul> <li> <p>Bounded Contexts:In DDD, a bounded context is a specific boundary within which a domain model is defined and applicable. In microservices, each microservice typically corresponds to a bounded context. Bounded contexts ensure that each microservice has a well-defined scope and encapsulates a specific aspect of the business domain.</p> </li> <li> <p>Aggregates: Aggregates in DDD represent a cluster of domain objects treated as a single unit. In microservices, an aggregate can be considered a microservice that manages a set of related entities. Microservices encapsulate aggregates and provide APIs for manipulating them. This helps maintain data consistency and isolation.</p> </li> <li> <p>Entities and Value Objects: DDD distinguishes between entities (objects with a distinct identity) and value objects (objects with no distinct identity). In microservices, entities and value objects are used to model domain concepts within the microservice's scope, helping to define data structures and behavior.</p> </li> <li> <p>Context Mapping: Context mapping in DDD deals with defining relationships and interactions between bounded contexts. It helps manage the integration points between different parts of the system.  In microservices architecture, context mapping is essential for specifying how microservices interact and communicate with each other, either through APIs or messaging.</p> </li> </ul>"},{"location":"microservices/1.getting-started/#domain-driven-design-ddd-example","title":"Domain-Driven Design (DDD) Example","text":"<p>Let\u2019s take a <code>detailed real-world example</code> of a microservices-based application following <code>Domain-Driven Design (DDD)</code> principles. This example will helps you to understand how to identify bounded contexts, define microservices, map databases per service, and see how this all ties together into a cohesive system.</p> <p>Scenario: Online Retail Platform (E-Commerce System)</p> <p>You are building a modern online retail platform similar to Amazon or Flipkart. The platform needs to handle:</p> <ul> <li>Product management</li> <li>Customer management</li> <li>Orders and payments</li> <li>Inventory tracking</li> <li>Notifications</li> <li>Authentication and authorization</li> </ul> <p>Applying DDD: Identify Bounded Contexts</p> <p>In DDD, each bounded context becomes a candidate for a microservice. Here\u2019s how the domain breaks down:</p> Bounded Context Description Product Catalog Manages product details, categories, pricing Customer Management Handles user registration, profile, and address Order Management Creates and tracks customer orders Inventory Manages stock levels per product and location Payment Handles payment processing, refunds Notification Sends emails/SMS for order updates Authentication User login, token issuance, role-based access <p>Microservices List with Databases</p> Microservice Responsibility Database Technology Stack ProductService Add/update product catalog, categories, pricing SQL Server / PostgreSQL .NET Core Web API CustomerService Manage user profile, address, contact info PostgreSQL .NET Core Web API OrderService Place order, track order status, order history SQL Server .NET Core Web API InventoryService Check and update stock, warehouse mapping MongoDB / PostgreSQL Node.js / .NET PaymentService Handle payments, payment status, refunds PostgreSQL Node.js NotificationService Send order/shipping alerts via email/SMS No DB / Redis Queue Node.js AuthService Register/login users, token issuance, RBAC PostgreSQL (Keycloak DB) Keycloak (Docker) <p>Each microservice:</p> <ul> <li>Has its own isolated data store</li> <li>Manages its own business rules</li> <li>Communicates with others via REST APIs or message queues</li> </ul> <p>Microservice Interactions (Example Flow)</p> <p>User places an order:</p> <ol> <li>AuthService validates user token.</li> <li>OrderService creates order, validates customer and product.</li> <li>ProductService provides product pricing.</li> <li>InventoryService checks and reserves stock.</li> <li>PaymentService processes payment.</li> <li>NotificationService sends confirmation email/SMS.</li> <li>OrderService updates order status.</li> </ol> <p>These services can be chained using REST (synchronous) or Kafka/RabbitMQ (asynchronous).</p> <p>Databases per Microservice (DB-per-Service Pattern)</p> <p>Each microservice owns its own database schema and is responsible for reading/writing to it.</p> Microservice Database Type Reason ProductService PostgreSQL Relational data, joins for categories CustomerService PostgreSQL Structured customer records OrderService SQL Server Order lifecycle with transactional guarantees InventoryService MongoDB High write-read throughput, document model PaymentService PostgreSQL Transactional ACID compliance NotificationService Redis (Optional) Queueing and retry tracking AuthService PostgreSQL Used internally by Keycloak"},{"location":"microservices/1.getting-started/#task-1-identify-microservices-for-the-book","title":"Task-1: Identify Microservices for the book","text":"<p>To fully explore the microservices architecture in this book, we will create several containerized microservices and microfrontend applications and couple of databases. These applications will allow us to demonstrate real-world scenarios and provide a practical understanding of microservices implementation. In this case study, we will create the following microservices, which will be developed in the upcoming labs.  we have purposely selected diverse options to ensure a broader learning experience.</p> Microservice/Website/Database Technology Used Name First Microservice .NET Core Web API (C#) aspnet-api Second Microservice Node.js (Node) nodejs-api First Website ASP.NET Core MVC (C#) aspnet-app Second Website React.js (Node) react-app First Database SQL Server sqlserver-db Second Database PostgreSQL postgresql-db Keycloak Identity and Access Management keycloak-service Drupal Content Management System drupal-service <p>for example, here is how the folder structure of our Microservices and MicroFrontend Applications looks like    .</p> <pre><code>Microservices/\n\u251c\u2500\u2500 aspnet-api/\n\u2502   \u251c\u2500\u2500 Controllers/\n\u2502   \u251c\u2500\u2500 Models/\n\u2502   \u251c\u2500\u2500 appsettings.json\n\u2502   \u251c\u2500\u2500 Program.cs\n\u2502   \u251c\u2500\u2500 Startup.cs\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u2502   \u2514\u2500\u2500 aspnet-api.csproj\n\u2514\u2500\u2500 node-api/\n    \u251c\u2500\u2500 routes/\n    \u251c\u2500\u2500 models/\n    \u251c\u2500\u2500 package.json\n    \u251c\u2500\u2500 app.js\n    \u2514\u2500\u2500 Dockerfile\n\nWebsites/\n\u251c\u2500\u2500 aspnet-app/\n\u2502   \u251c\u2500\u2500 Controllers/\n\u2502   \u251c\u2500\u2500 Models/\n\u2502   \u251c\u2500\u2500 Views/\n\u2502   \u251c\u2500\u2500 appsettings.json\n\u2502   \u251c\u2500\u2500 Program.cs\n\u2502   \u251c\u2500\u2500 Startup.cs\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u2502   \u2514\u2500\u2500 aspnet-app.csproj\n\u251c\u2500\u2500 react-app/\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 package.json\n\u2502   \u251c\u2500\u2500 public/\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u2502   \u251c\u2500\u2500 node_modules/\n\u2502   \u2514\u2500\u2500 README.md\n\u2514\u2500\u2500 ...\nDatabases/\n\u251c\u2500\u2500 sqlserver-db/\n\u2502   \u251c\u2500\u2500 tables/\n\u2502   \u251c\u2500\u2500 procedures/\n\u2502   \u251c\u2500\u2500 views/\n\u2502   \u251c\u2500\u2500 functions/\n\u2502   \u2514\u2500\u2500 triggers/\n\u2502   \u2514\u2500\u2500 Dockerfile\n|\n\u2514\u2500\u2500 postgresql-db/\n    \u251c\u2500\u2500 tables/\n    \u251c\u2500\u2500 procedures/\n    \u251c\u2500\u2500 views/\n    \u251c\u2500\u2500 functions/\n    |\u2500\u2500 Dockerfile\n    \u2514\u2500\u2500 triggers/\n</code></pre> <p>Important</p> <p>If you noticed, each project has its own <code>Dockerfile</code>, indicating that all these applications will be containerized and ready for deployment to a Kubernetes cluster.</p> <p>The following diagram shows the conceptual view of the microservices environment</p> <p></p> <p>For example:</p> <p></p>"},{"location":"microservices/1.getting-started/#task-2-identify-the-list-of-git-repositories-needed","title":"Task-2: Identify the List of Git Repositories Needed","text":"<p>Once you have determined the list of domains or microservices required for your project, it's time to analyze how they will be organized within the source control system, such as Git repositories. One important consideration is determining the number of Git repositories you need.</p> <p>There are multiple ways to organize source code and pipelines in Azure DevOps Git, and the approach you choose depends on how you want to manage your source code and pipelines for your microservices architecture while ensuring ease of maintenance in the future.</p> <p>In my preference, I recommend creating a separate Git repository for each domain or microservice. Within each domain, you may have multiple microservices, MicroFrontends, and databases.</p> <p>For example, let's visualize how the Git structure may look:</p> <ul> <li>Organization1 (Name of your organization)<ul> <li>Project1 (Name of the project)<ul> <li>Repo-1 (for Domain1)<ul> <li>APIs - Create one or more APIs with separate folders</li> <li>Websites - Create one or more websites with separate folders</li> <li>Databases - Create one or more databases with separate folders</li> </ul> </li> <li>Repo-2 (for Domain2)<ul> <li>APIs - Create one or more APIs with separate folders</li> <li>Websites - Create one or more websites with separate folders</li> <li>Databases - Create one or more databases with separate folders</li> </ul> </li> <li>Repo-3 (for Domain3)<ul> <li>APIs - Create one or more APIs with separate folders</li> <li>Websites - Create one or more websites with separate folders</li> <li>Databases - Create one or more databases with separate folders</li> </ul> </li> </ul> </li> <li>Project2 (Project2)<ul> <li>Repo-1 (Name of the repository under Project2)<ul> <li>APIs - Create one or more APIs with separate folders</li> <li>Websites - Create one or more websites with separate folders</li> <li>Databases - Create one or more databases with separate folders</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Repeat this structure as the organization grows and new projects or domains are introduced.</p> <p>By following this approach, each domain or microservice will have its dedicated Git repository, providing a clear separation and organization of the source code and related artifacts. This structure facilitates easier maintenance, collaboration, and version control.</p> <p>Remember, this is just a sample structure, and you can adapt it based on your organization's specific needs and preferences.</p> <p>Visual representation of a sample DevOps Git structure: <pre><code>Organization1\n\u2514\u2500\u2500 Project1\n    \u251c\u2500\u2500 Repo-1 (Microservice-1)\n    \u2502   \u251c\u2500\u2500 APIs\n    \u2502   \u251c\u2500\u2500 Websites\n    \u2502   \u2514\u2500\u2500 Databases\n    \u251c\u2500\u2500 Repo-2 (Microservice-2)\n    \u2502   \u251c\u2500\u2500 APIs\n    \u2502   \u251c\u2500\u2500 Websites\n    \u2502   \u2514\u2500\u2500 Databases\n    \u251c\u2500\u2500 Repo-3 (Microservice-3)\n    \u2502   \u251c\u2500\u2500 APIs\n    \u2502   \u251c\u2500\u2500 Websites\n    \u2502   \u2514\u2500\u2500 Databases\n    Project2\n    \u2514\u2500\u2500 Repo-1\n        \u251c\u2500\u2500 APIs\n        \u251c\u2500\u2500 Websites\n        \u2514\u2500\u2500 Databases\n</code></pre></p> <p>By adopting this Git structure, you can effectively manage and scale your microservices projects while ensuring a clear and organized source control system.</p>"},{"location":"microservices/1.getting-started/#task-3-create-new-azure-devops-organization","title":"Task-3: Create new Azure DevOps Organization","text":"<p>With the planning and preparation of your Microservices application complete, the next step is to create a DevOps organization where you can manage the lifecycle of your projects.</p> <p>To create a new Azure DevOps organization, follow these steps:</p> <ol> <li>Sign in to Azure DevOps. - https://dev.azure.com</li> <li>Click on <code>New organization</code> in the left nav. </li> <li>Enter name of the Organization and create new organization. </li> </ol> <p>Once you have completed these steps, you will have a new Azure DevOps organization that is ready for use. You can then invite members to join your organization and start creating new projects.</p>"},{"location":"microservices/1.getting-started/#task-4-create-new-azure-devops-project","title":"Task-4: Create new Azure DevOps Project","text":"<p>You need a new project in Azure DevOps to manage your source code and other project related activities.</p> <p>Follow these steps to create a new project in Azure DevOps:</p> <ol> <li> <p>Sign in to the Azure DevOps website https://dev.azure.com/ with your Azure DevOps account.</p> </li> <li> <p>Click on the <code>Create a project</code> button.</p> </li> <li> <p>Enter a name for your project and select a process template. The process template determines the default work item types, source control repository, and other settings for your project.</p> </li> <li> <p>Click the <code>Create project</code> button to create your new project.</p> </li> <li> <p>Follow the screen to configure your project settings, including source control, work item types, and team members.</p> </li> <li> <p>When you are finished, click the <code>Create</code> button to complete the project creation process.</p> </li> </ol> <p>For example: </p> <p>Project Name - <code>Microservices</code></p> <p>Description - <code>Microservices project will be used to roll out sample microservices applications for demonstrating microservices architecture.</code></p> <p></p> <p>We have created new organization in azure DevOps and created new project so that we can start working on containerized microservices applications in the next labs.</p>"},{"location":"microservices/1.getting-started/#references","title":"References","text":"<ul> <li>Microsoft MSDN - Microservice architecture style</li> <li>Microsoft MSDN - Create an organization</li> <li>Microsoft MSDN - Create a project in Azure DevOps</li> <li>Microservice Architecture</li> </ul>"},{"location":"microservices/10.keycloak/","title":"Chapter-10: Setting up Keycloak in a Docker Container","text":""},{"location":"microservices/10.keycloak/#introduction","title":"Introduction","text":"<p>As part of this chapter, I will introduce Keycloak as one of the applications in the microservices landscape for Security, which is a common requirement across many organizations. Keycloak is a free, open-source, powerful, and flexible popular open-source identity and access management solution that enables you to secure your applications and services.</p> <p>If you are new to Keycloak and would like to learn more, you can refer to my article on Getting Started with Keycloak</p> <p>In this lab, I will guide you through the process of creating Docker container for Keycloak, and finally accessing the Keycloak application in the web browser.</p> <p>Running Keycloak in a Docker container provides greater control and flexibility over its configuration and deployment, allowing us to tailor authentication, authorization, and identity management features to meet specific organizational requirements. This approach enables seamless customization of realms, themes, user federation, and integration with external identity providers, all while maintaining consistency across environments through containerized infrastructure.</p> <p>The objective is to establish a local development environment for the Keycloak application, securing Microservices with Keycloak in a Microservices Architecture,  our goal is to implement authentication and authorization mechanisms across the microservices, ensuring that only authorized users and services can access specific resources. To accomplish this, you will create a Dockerfile or Docker Compose files, run them locally, and subsequently push the image to an Azure Container Registry (ACR). All of these tasks we are doing here will be useful in later chapters when deploying to the Azure Kubernetes Service (AKS).</p> <p>Here are some Keycloak requirements within microservices architecture:</p> <ul> <li> <p>Keycloak integration:    Integrate Keycloak into the microservices architecture to provide authentication and authorization capabilities.    Keycloak should act as the central identity provider for all microservices.</p> </li> <li> <p>User management:    Implement user management within Keycloak, allowing users to sign up, log in, and manage their profiles.    Define user roles and groups for fine-grained access control.</p> </li> <li> <p>Secure API endpoints:    Protect API endpoints to ensure that only authenticated users or services with the appropriate permissions can access them.    Implement OAuth 2.0 or OpenID Connect for securing APIs.</p> </li> <li> <p>Single Sign-On (SSO):    Keycloak can serve as a versatile solution for enabling SSO between companies by establishing federated trust relationships between IdPs and SPs. This approach simplifies user access across organizations, enhances security, and provides a seamless user experience when accessing services and applications from different companies.</p> </li> <li> <p>JWT Tokens:    Utilize JSON Web Tokens (JWT) for secure communication between microservices and Keycloak.    Configure token expiration, signing, and validation.</p> </li> </ul>"},{"location":"microservices/10.keycloak/#objective","title":"Objective","text":"<p>In this exercise, our objective is to accomplish and learn the following tasks:</p> <ul> <li>Step-1: Setup repository for Keycloak in Azure devops.</li> <li>Step-2: Create Keycloak Folder.</li> <li>Step-3: Add Dockerfiles to the Keycloak project.</li> <li>Step-4: Docker build locally.</li> <li>Step-5: Docker run locally.</li> <li>Step-6: Publish the Keycloak docker container to container registry.</li> </ul>"},{"location":"microservices/10.keycloak/#prerequisites","title":"Prerequisites","text":"<p>Before starting this lab, ensure you have the following prerequisites in place:</p> <ul> <li>Docker and the VS Code Docker extension :  - Docker Downloads.</li> <li>Git Client tool:  - Git Downloads.</li> <li>Azure devops and Git Repository: Initialize a Git repository for your Keycloak application.</li> <li>Azure Container Registry (ACR)</li> <li>Docker compose installed</li> </ul> <p>Verify the docker installation by running following commands: <pre><code>docker version\n# or\ndocker --version\n# or\ndocker -v\n</code></pre></p> <p>Verify the docker compose by running following commands:</p> <pre><code>docker-compose version\n</code></pre>"},{"location":"microservices/10.keycloak/#architecture-diagram","title":"Architecture Diagram","text":"<p>The following diagram shows the high level steps to create docker container for Keycloak application.</p> <p></p>"},{"location":"microservices/10.keycloak/#step-1-setup-repository-for-keycloak-in-azure-devops","title":"Step-1: Setup repository for Keycloak in Azure DevOps","text":"<p>Before you begin with the Keycloak setup, it's necessary to have a version control repository to manage your project. </p> <ul> <li>Create azure devops project</li> <li>Initialize repository</li> </ul> <p>For this Keycloak application, we can either use an existing git repository created in our first chapter or initiate a new one.</p> <p>To clone an existing repository, run the following command:</p> <pre><code>git clone https://keesari.visualstudio.com/Microservices/_git/microservices\n</code></pre>"},{"location":"microservices/10.keycloak/#step-2-create-keycloak-project","title":"Step-2: Create Keycloak project","text":"<p>In this step, we'll create a dedicated Folder for our Keycloak application</p> <p>Create a new Folder: Inside our Git repository, create a new directory or folder specifically for your Keycloak application. This folder will contain all the necessary files for Keycloak, including Dockerfiles and configurations.</p> <p></p>"},{"location":"microservices/10.keycloak/#step-3-keycloak-setup-with-docker-compose","title":"Step-3: Keycloak setup with docker compose","text":"<p>Setup Keycloak Service:</p> <p>To setup the Keycloak with docker compose you need to first create a docker compose file that defines the Keycloak service and any necessary dependencies, such as a PostgreSQL database. </p> <p>Here's a step-by-step explanation of how to set up Keycloak with docker compose:</p> <p>Create a file named <code>docker-compose.yml</code> in your project directory. This file will define the services and configurations for your Keycloak setup.</p> <p>In the docker-compose.yml file, define the Keycloak service. Use the official Keycloak Docker image and specify any necessary configurations. Here's an example of a Keycloak service definition:</p> docker-compose.yml<pre><code>services:\n  auth:\n    image: quay.io/keycloak/keycloak\n    ports:\n      - \"8080:8080\"\n    environment:\n      KEYCLOAK_ADMIN: admin \n      KEYCLOAK_ADMIN_PASSWORD: admin\n    command: \n      - start-dev \n      - --import-realm\n    volumes:\n      - /home/keycloak/realm.json:/opt/keycloak/data/import/realm.json\n</code></pre> <p>This definition:</p> <ul> <li>Uses the <code>quay.io/keycloak/keycloak</code> Docker image.</li> <li>Maps port 8080 on your host to port 8080 in the Keycloak container.</li> <li>Sets up an initial admin user and password for Keycloak.</li> </ul> <pre><code>docker-compose up\n# or\ndocker-compose up -d\n\n#output\n[+] Running 1/0\n \u2714 Container keycloak-auth-1  Created                                                                                                                                                                                   0.0s \nAttaching to keycloak-auth-1\n.\n.\n.\nRunning the server in development mode. DO NOT use this configuration in production.\n</code></pre> <p><pre><code>docker ps\n\n# output\n\nCONTAINER ID   IMAGE                                COMMAND                  CREATED              STATUS              PORTS                              NAMES\nd3ee7cef046e   quay.io/keycloak/keycloak            \"/opt/keycloak/bin/k\u2026\"   About a minute ago   Up About a minute   0.0.0.0:8080-&gt;8080/tcp, 8443/tcp   keycloak-auth-1\n</code></pre> <pre><code>docker image ls\n\n# output\nREPOSITORY                                TAG                                        IMAGE ID       CREATED         SIZE  \nquay.io/keycloak/keycloak                 latest                                     273d68e6fb8c   6 days ago      459MB \n</code></pre></p> <p><pre><code>docker container ls\n\n# output\nCONTAINER ID   IMAGE                                COMMAND                  CREATED          STATUS          PORTS                              NAMES\nd3ee7cef046e   quay.io/keycloak/keycloak            \"/opt/keycloak/bin/k\u2026\"   22 minutes ago   Up 22 minutes   0.0.0.0:8080-&gt;8080/tcp, 8443/tcp   keycloak-auth-1\n</code></pre> <pre><code>docker network ls\n\n# output\nNETWORK ID     NAME                           DRIVER    SCOPE\ne71f9c6bd718   bridge                         bridge    local\nd08c17ea4f0e   docker-nodejs-sample_default   bridge    local\ncfb02a162739   host                           host      local\nc8fb8d726406   keycloak_default               bridge    local\n8bba86e6ad07   none                           null      local\n</code></pre></p> <p>Access Keycloak: </p> <p>Once the Keycloak service is up and running, you can access the Keycloak admin console by opening a web browser and navigating to http://localhost:8080. You can log in using the admin user and password you defined in the Keycloak service configuration.</p> <p>Keycloal admin console</p> <p></p> <p>Keycloak Login page</p> <p></p> <p>Keycloak master relm</p> <p></p> <p>Setup Keycloak Service with PostgreSQL database:</p> <p>If you want to use a PostgreSQL database as Keycloak's backend, define a PostgreSQL service in the same <code>docker-compose.yml</code> file. </p> <p>Here's a complete <code>docker-compose.yml</code> file that sets up Keycloak with a PostgreSQL database:</p> docker-compose.yml<pre><code>version: '3'\nservices:\n  keycloak:\n    image: quay.io/keycloak/keycloak\n    container_name: keycloak\n    ports:\n      - \"8080:8080\"\n    environment:\n      - KEYCLOAK_ADMIN=admin\n      - KEYCLOAK_ADMIN_PASSWORD=admin\n    command: \n      - start-dev \n      - --import-realm\n    volumes:\n      - /home/keycloak/realm.json:/opt/keycloak/data/import/realm.json\n    depends_on:\n      - postgres\n    networks:\n      - keycloak_network\n\n  postgres:\n    image: postgres:latest\n    container_name: postgres\n    ports:\n      - \"5432:5432\"\n    environment:\n      - POSTGRES_DB=keycloak\n      - POSTGRES_USER=keycloak\n      - POSTGRES_PASSWORD=keycloak\n    networks:\n      - keycloak_network\n\nnetworks:\n  keycloak_network:\n    driver: bridge\n</code></pre> <p>In this <code>docker-compose.yml</code> file:</p> <ul> <li>The <code>keycloak</code> service uses the official Keycloak Docker image, maps port 8080 on your host to port 8080 in the Keycloak container, and sets up an initial admin user and password.</li> <li>The <code>postgres</code> service uses the official PostgreSQL Docker image, specifies the database name, username, and password for PostgreSQL, and maps port 5432 on your host to port 5432 in the PostgreSQL container.</li> <li><code>depends_on</code> ensures that the <code>keycloak</code> service starts only after the <code>postgres</code> service is up and running, as Keycloak relies on the PostgreSQL database.</li> <li>Both services are connected to a custom network called <code>keycloak_network</code> for communication between containers.</li> </ul> <p></p> <p>Once both services are up and running, you can access the Keycloak admin console by opening a web browser and navigating to <code>http://localhost:8080/auth</code>. Log in using the admin user and password you specified in the Keycloak service configuration.</p>"},{"location":"microservices/10.keycloak/#step-4-keycloak-setup-with-dockerfile","title":"Step-4: Keycloak setup with Dockerfile","text":"<p>Step-4.1: Create Dockerfile</p> <p>Let's create a Dockerfile in the root directory of our project and include the following code. We are going to use this Dockerfile to containerize our Keycloak application as per our need.</p> Dockerfile<pre><code>FROM quay.io/keycloak/keycloak:latest as builder\n\n# Enable health and metrics support\nENV KC_HEALTH_ENABLED=true\nENV KC_METRICS_ENABLED=true\n\n# Configure a database vendor\nENV KC_DB=postgres\n\nWORKDIR /opt/keycloak\n# for demonstration purposes only, please make sure to use proper certificates in production instead\nRUN keytool -genkeypair -storepass password -storetype PKCS12 -keyalg RSA -keysize 2048 -dname \"CN=server\" -alias server -ext \"SAN:c=DNS:localhost,IP:127.0.0.1\" -keystore conf/server.keystore\nRUN /opt/keycloak/bin/kc.sh build\n\nFROM quay.io/keycloak/keycloak:latest\nCOPY --from=builder /opt/keycloak/ /opt/keycloak/\n\n# change these values to point to a running postgres instance\nENV KC_DB=postgres\nENV KC_DB_URL=&lt;DBURL&gt;\nENV KC_DB_USERNAME=&lt;DBUSERNAME&gt;\nENV KC_DB_PASSWORD=&lt;DBPASSWORD&gt;\nENV KC_HOSTNAME=localhost\nENTRYPOINT [\"/opt/keycloak/bin/kc.sh\"]\n</code></pre> <p>Step-4.2: Docker build locally</p> <p>We will build the Docker container locally using the Dockerfiles and ensure that the containerized application working as expected.</p> <p>The <code>docker build</code> command is used to build Docker images from a Dockerfile.  </p> <pre><code>docker build -t sample/keycloak-app:20240101.1 .\n</code></pre> <p>output</p> <pre><code>Docker build output goes here\n</code></pre> <p>When you run the <code>docker build</code> command, Docker looks for a Dockerfile in the specified directory and reads the instructions in the file to build a new image. </p> <p>The Dockerfile contains a series of instructions that define how to build the image, such as copying files, running commands, and setting environment variables. </p> <p>Step-4.3: Docker run locally</p> <p>Run the Docker container locally to verify that the keycloak application working correctly within a containerized environment. This step ensures that the containerized keycloak application works as expected on your local machine.</p> <p>Run the <code>docker run</code> command to start a container based on the image:</p> <p><pre><code>docker run --rm -p 8080:8080 sample/keycloak-app:20240101.1 .\n</code></pre> output</p> <p><pre><code>Docker run output goes here\n</code></pre> if you open the docker desktop you will notice the new image &amp; container started running.</p>"},{"location":"microservices/10.keycloak/#step-5-publish-the-keycloak-docker-container-to-container-registry","title":"Step-5: Publish the Keycloak docker container to container registry","text":"<p>Now that we have Keycloak Docker container ready locally, it's time to push them to the Container Registry for future deployment on Azure Kubernetes Services (AKS). This step is important for preparing the container for deployment in a cloud environment.</p> <p>To publish a Keycloak Docker container to Azure Container Registry (ACR), you will need to have the following:</p> <p>Create an Azure Container Registry. If you don't have one, you can create one by following the instructions in the Azure Portal or using Azure CLI.</p> <p>Log in to your Azure Container Registry using the Docker command-line interface. You can do this by running the following command:</p> <pre><code># azure Login\naz login\n\n# set the azure subscription\naz account set -s \"anji.keesari\"\n\n# Log in to the container registry\naz acr login --name acr1dev\n# Login Succeeded\n# To get the login server address for verification\naz acr list --resource-group rg-acr-dev --query \"[].{acrLoginServer:loginServer}\" --output table\n\n# output should look similar to this.\n\n# AcrLoginServer    \n# ------------------\n# acr1dev.azurecr.io\n</code></pre> <p>list all the Docker images that are available on the local system</p> <pre><code>docker images\n\n# output\n\nREPOSITORY                                                TAG                                                                          IMAGE ID       CREATED         SIZE\nsample/keycloak-app                                         20230312.1                                                                   587f347206bc   8 minutes ago   216MB\n.\n.\n.\n</code></pre> <p><code>Tag</code> your Docker container image with the full name of your Azure Container Registry, including the repository name and the version tag. You can do this by running the following command:</p> <pre><code>docker tag sample/keycloak-app:20240101.1 acr1dev.azurecr.io/sample/keycloak-app:20240101.1\n</code></pre> <p>Push your Docker container image to your Azure Container Registry using the Docker command-line interface. You can do this by running the following command:</p> <pre><code>docker push acr1dev.azurecr.io/sample/keycloak-app:20240101.1\n\n#Output\nThe push refers to repository [acr1dev.azurecr.io/sample/keycloak-app]\n649a035a1734: Pushed\n4061bd2dd536: Pushed\nc0257b3030b0: Pushed\n912a3b0fc587: Pushed\na36186d93e25: Pushed\na3d997b065bc: Pushed\n65d358b7de11: Pushed\nf97384e8ccbc: Pushed\nd56e5e720148: Pushed\nbeee9f30bc1f: Pushed\n20240101.1: digest: sha256:73f0669d18c6cae79beb81edc8c523191710f9ec4781d590884b46326f9ad6f9 size: 2419\n</code></pre> <p>Wait for the push to complete. Depending on the size of your Docker container image and the speed of your internet connection, this may take a few minutes.</p> <p>Verify the newly pushed image to ACR.</p> <pre><code>az acr repository list --name acr1dev --output table\n\n# Output\n\nResult\n-------------------------------\nmcr.microsoft.com/dotnet/aspnet\nmcr.microsoft.com/dotnet/sdk\nsample/aspnet-api\nsample/aspnet-app\nsample/node-api\nsample/postgresql-db\nsample/keycloak-app\n</code></pre> <p>Show the new tags of a image in the acr</p> <pre><code>az acr repository show-tags --name acr1dev --repository sample/keycloak-app --output table\n</code></pre> <p>You've successfully pushed your Docker container image to Azure Container Registry. You can now use the Azure Portal or Azure CLI to manage your container images and deploy them to Azure services like Azure Kubernetes Service (AKS).</p>"},{"location":"microservices/10.keycloak/#conclusion","title":"Conclusion","text":"<p>You have successfully created a Docker container for keycloak application, container created as part of this task will be used in the future labs in AKS.</p>"},{"location":"microservices/10.keycloak/#references","title":"References","text":"<ul> <li>keycloak Docker image</li> <li>Keycloak Official Documentation </li> <li>GitHub repository</li> <li>Stack Overflow </li> </ul> <p>-</p>"},{"location":"microservices/11.drupal/","title":"Chapter-11: Setting up Drupal in a Docker Container","text":""},{"location":"microservices/11.drupal/#introduction","title":"Introduction","text":"<p>As part of this chapter, I will introduce Drupal as one of the applications in the microservices landscape for content management, which is a common requirement across many organizations. Drupal is a free, open-source, powerful, and flexible CMS written in PHP that enables you to create and manage websites with ease.</p> <p>If you are new to Drupal and would like to learn more, you can refer to my article on Getting Started with Drupal: A Beginner's Guide</p> <p>In this lab, I will guide you through the process of creating Docker container for Drupal and run PostgreSQL database in the backend, and finally accessing the drupal website in the web browser.</p> <p>The objective is to establish a local development environment for the drupal website. To accomplish this, you will create a docker Compose file, run them locally. All of these tasks we are doing here will be useful in later chapters when deploying to the Azure Kubernetes Service (AKS).</p>"},{"location":"microservices/11.drupal/#technical-scenario","title":"Technical Scenario","text":"<p>As an <code>Application Architect</code>, your responsibility is to design a content management system (CMS) that provides you with enhanced control and flexibility. By creating a custom Docker container with Drupal, you gain the ability to make modifications. You can adapt the Dockerfile to include additional packages, configurations, or custom modules/themes as per your project's specific requirements. This approach guarantees that your Drupal environment aligns with your project's needs while simultaneously utilizing Docker's advantages, including isolation, portability, and scalability.</p>"},{"location":"microservices/11.drupal/#objective","title":"Objective","text":"<p>In this exercise, our objective is to accomplish and learn the following tasks:</p> <ul> <li>Step-1: Setup Git Repository for Drupal.</li> <li>Step-2: Create Drupal Folder locally.</li> <li>Step-3: Create Docker Compose file</li> <li>Step-4: Build Drupal locally.</li> <li>Step-5: Run Drupal Container locally.</li> </ul>"},{"location":"microservices/11.drupal/#prerequisites","title":"Prerequisites","text":"<p>Before starting this lab, ensure you have the following prerequisites in place:</p> <ul> <li>Docker Desktop: - Docker Downloads.</li> <li>Git Client tool: - Git Downloads.</li> <li>Git Repository: Initialize a Git repository for your Drupal website.</li> <li>Docker installed</li> <li>Docker compose installed</li> <li>PostgreSQL installed - this will allow you to run <code>psql</code> command line tool</li> </ul> <p>Verify the docker installation by running following commands: <pre><code>docker version\n# or\ndocker --version\n# or\ndocker -v\n</code></pre></p> <p>Verify the docker compose by running following commands:</p> <pre><code>docker-compose version\n</code></pre>"},{"location":"microservices/11.drupal/#architecture-diagram","title":"Architecture Diagram","text":"<p>The following diagram shows the high level steps to create docker container for Drupal website.</p> <p></p>"},{"location":"microservices/11.drupal/#step-1-setup-git-repository-for-drupal","title":"Step-1: Setup Git Repository for Drupal","text":"<p>Setting up a Git repository for your Drupal project allows you to manage your code effectively, work in teams, and track the changes of your website's codebase.</p> <ul> <li>Create azure devops project</li> <li>Initialize repository</li> </ul> <p>For this Drupal website, we can either use an existing git repository created in our first chapter or initiate a new one.</p> <p>For example to clone an existing repository, run the following command:</p> <pre><code>git clone https://keesari.visualstudio.com/Microservices/_git/microservices\n</code></pre>"},{"location":"microservices/11.drupal/#step-2-create-drupal-project","title":"Step-2: Create Drupal Project","text":"<p>In this step, we'll create a dedicated project or folder for our Drupal Website</p> <p>Create a new project:</p> <p>Inside our Git repository, create a new directory or folder specifically for your Drupal website. This folder will contain all the necessary files for Drupal website, including docker compose &amp; Dockerfile and configurations.</p> <p></p>"},{"location":"microservices/11.drupal/#step-3-create-docker-compose-file","title":"Step-3:  Create Docker Compose file","text":"<p>To setup the Drupal with docker compose you need to first create a docker compose file that defines the drupal service and any necessary dependencies, such as a PostgreSQL database. </p> <p>Create a file named <code>docker-compose.yml</code> in your project directory. This file will define the services and configurations for your Drupal setup.</p> <p>In the docker-compose.yml file, define the Drupal service. Use the official Drupal Docker image and specify any necessary configurations. Here's an example of a Drupal service definition:</p> docker-compose.yml<pre><code># Drupal with PostgreSQL\n#\n# Access via \"http://localhost:8080\"\n#   (or \"http://$(docker-machine ip):8080\" if using docker-machine)\n#\n# During initial Drupal setup,\n# Database type: PostgreSQL\n# Database name: postgres\n# Database username: postgres\n# Database password: example\n# ADVANCED OPTIONS; Database host: postgres\n\nversion: '3.1'\n\nservices:\n\n  drupal:\n    image: drupal:10-apache\n    ports:\n      - 8080:80\n    volumes:\n      - /var/www/html/modules\n      - /var/www/html/profiles\n      - /var/www/html/themes\n      # this takes advantage of the feature in Docker that a new anonymous\n      # volume (which is what we're creating here) will be initialized with the\n      # existing content of the image at the same location\n      - /var/www/html/sites\n    restart: always\n\n  postgres:\n    image: postgres:16\n    environment:\n      POSTGRES_USER : postgres\n      POSTGRES_PASSWORD: example   \n    # ports:\n    #     - \"5432:5432\"\n    restart: always\n</code></pre> <ul> <li>Uses the <code>drupal:10-apache</code> Docker image.</li> <li>Maps port 8080 on your host to port 8080 in the drupal container.</li> <li>Sets up an initial admin user and password for drupal.</li> </ul>"},{"location":"microservices/11.drupal/#step-4-build-drupal-locally","title":"Step-4: Build Drupal locally","text":"<p>The <code>docker-compose up</code> command is used to start and initialize the services defined in a Docker Compose file. We will build the Docker container locally using the docker compose and ensure that the containerized application working as expected.</p> <pre><code>docker-compose up\n\n# or - -d flag, it tells Docker Compose to run the containers in detached mode\ndocker-compose up -d\n\n#output\n[+] Running 33/2\n \u2714 postgres 14 layers [\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff]      0B/0B      Pulled\n \u2714 drupal 17 layers [\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff]      0B/0B      Pulled\n[+] Running 3/3\n \u2714 Network drupal_default       Created\n \u2714 Container drupal-drupal-1    Started\n \u2714 Container drupal-postgres-1  Started\n</code></pre> <p>List running Docker containers on your system. </p> <pre><code>docker ps\n\n# output\nCONTAINER ID   IMAGE                       COMMAND                  CREATED          STATUS          PORTS                    NAMES\nb2701f4c0b44   postgres:16                 \"docker-entrypoint.s\u2026\"   24 minutes ago   Up 24 minutes   5432/tcp                 drupal-postgres-1\n5141598054d3   drupal:10-apache            \"docker-php-entrypoi\u2026\"   24 minutes ago   Up 24 minutes   0.0.0.0:8080-&gt;80/tcp     drupal-drupal-1\n</code></pre> <p>List Docker images that are currently available on your local system.</p> <pre><code>docker image ls\n\n# output\nREPOSITORY                                                TAG                                                                          IMAGE ID       CREATED         SIZE\ndrupal                                                    10-apache                                                                    48fb247e75d6   2 weeks ago     594MB\npostgres                                                  16                                                                           b0b90c1d9579   4 weeks ago     425MB\n</code></pre>"},{"location":"microservices/11.drupal/#step-43-run-drupal-container-locally","title":"Step-4.3: Run Drupal Container locally.","text":"<p>Run the Docker container locally to verify that the drupal website working correctly within a containerized environment. This step ensures that the containerized drupal website works as expected on your local machine.</p> <p>List the running Docker containers on your system</p> <pre><code>docker container ls\n\n# output\nCONTAINER ID   IMAGE                       COMMAND                  CREATED          STATUS          PORTS                    NAMES\nb2701f4c0b44   postgres:16                 \"docker-entrypoint.s\u2026\"   25 minutes ago   Up 25 minutes   5432/tcp                 drupal-postgres-1\n5141598054d3   drupal:10-apache            \"docker-php-entrypoi\u2026\"   25 minutes ago   Up 25 minutes   0.0.0.0:8080-&gt;80/tcp     drupal-drupal-1\n</code></pre> <p>List the Docker networks that are available on your local system</p> <pre><code>docker network ls\n\n# output\n026de34a62dc   bridge                         bridge    local\n0dcb9a6803a2   drupal_default                 bridge    local\n</code></pre> <p>if you open the docker desktop you will notice the new image &amp; container started running.</p> <p>Note</p> <p>Ensure that you test the PostgreSQL connection using either the pgAdmin tool or the <code>psql</code> command-line tool.</p> <p></p> <p>Access Drupal Webstie</p> <p>Once the Drupal service is up and running, you can access the Drupal website by opening a web browser and navigating to http://localhost:8080. You can log in using the admin user and password you defined in the Drupal service configuration.</p> <p>Drupal website &gt; language</p> <p></p> <p>Drupal &gt; Installation Profile</p> <p></p> <p>Drupal &gt; Database configuration</p> <p></p> <p>Drupal &gt; configure site</p> <p></p> <p>Drupal &gt; welcome page</p> <p></p> <p>Drupal &gt; Users page</p> <p></p>"},{"location":"microservices/11.drupal/#conclusion","title":"Conclusion","text":"<p>You have successfully created a Docker container for Drupal Website, container created as part of this task will be used in the future labs in AKS.</p>"},{"location":"microservices/11.drupal/#references","title":"References","text":"<p>For further information and resources related to setting up Drupal in a Docker container, refer to the following:</p> <ul> <li>Drupal Docker Official Repository</li> <li>Docker Documentation</li> <li>Docker Compose Documentation</li> <li>Drupal.org - Official Drupal Website</li> </ul>"},{"location":"microservices/2.docker-fundamentals/","title":"Chapter-2: Exploring Docker Fundamentals","text":""},{"location":"microservices/2.docker-fundamentals/#overview","title":"Overview","text":"<p>In this article, we'll explore the basics of Docker, which are like building blocks for understanding how containers work. Whether you're an experienced coder or just starting out, grasping these basics is essential for easily deploying applications in containers. These core concepts will come in handy as you continue your learning journey with docker.</p>"},{"location":"microservices/2.docker-fundamentals/#what-is-docker","title":"What is Docker?","text":"<p>Docker is a powerful platform that simplifies the process of developing, shipping, and running applications. Docker uses a technology known as containerization to encapsulate an application and its dependencies into a self-contained unit called a <code>container</code>. These containers are lightweight, portable, and consistent across different environments.</p>"},{"location":"microservices/2.docker-fundamentals/#why-use-docker","title":"Why use Docker?","text":"<p>Docker simplifies the development, deployment, and management of applications, offering an adaptable solution for modern software development practices. Its popularity comes from from its ability to address challenges related to consistency, scalability, and efficiency in the software development lifecycle.</p> <p>Docker has become increasingly popular in the software development and IT industry due to its numerous advantages. Here are some key benefits of using Docker:</p> <ol> <li> <p>Portability:    Docker containers encapsulate applications and their dependencies, ensuring consistency across different environments. This portability eliminates the common problem of \"it works on my machine\" and facilitates seamless deployment across various systems.</p> </li> <li> <p>Isolation:    Containers provide a lightweight and isolated environment for applications. Each container runs independently, preventing conflicts between dependencies and ensuring that changes made in one container do not affect others.</p> </li> <li> <p>Efficiency:    Docker's containerization technology enables efficient resource utilization. Containers share the host OS kernel, making them lightweight compared to traditional virtual machines. This results in faster startup times and improved performance.</p> </li> <li> <p>Scalability:    Docker makes it easy to scale applications horizontally by running multiple instances of containers. This scalability allows developers to change the workloads and ensures optimal resource utilization.</p> </li> <li> <p>Microservices architecture:    Docker is integral to the microservices architecture, where applications are composed of small, independently deployable services. Containers facilitate the development, deployment, and scaling of microservices, enabling agility and ease of management.</p> </li> <li> <p>DevOps integration:    Docker aligns well with DevOps practices by promoting collaboration between development and operations teams. Containers can be easily integrated into continuous integration and continuous deployment (CI/CD) pipelines, streamlining the software delivery process.</p> </li> <li> <p>Community support:    Docker's community offers lot of pre-made tools and solutions, helping developers work faster and learn from others.</p> </li> <li> <p>Security:     Docker provides built-in security features, such as isolation and resource constraints, to enhance application security. </p> </li> <li> <p>Cross-platform compatibility:     Docker containers can run on various operating systems, including Linux, Windows, and macOS. This cross-platform compatibility is beneficial for teams working in heterogeneous environments.</p> </li> </ol>"},{"location":"microservices/2.docker-fundamentals/#docker-concepts","title":"Docker concepts","text":"<p>Understanding these basic concepts is essential for effectively working with Docker and leveraging its advantages in terms of portability, scalability, and consistency across different environments.  Here are basic concepts of Docker:</p> <ul> <li> <p>Containerization Containerization is a technology that allows you to package an application and its dependencies, including libraries and configuration files, into a single container image.</p> </li> <li> <p>Images An image is a lightweight, standalone, and executable package that includes everything needed to run a piece of software, including the code, runtime, libraries, and system tools. Docker images are used to create containers. They are built from a set of instructions called a Dockerfile.</p> </li> <li> <p>Dockerfile A Dockerfile is a text file that contains a set of instructions for building a Docker image. It specifies the base image, adds dependencies, copies files, and defines other settings necessary for the application to run.</p> </li> <li> <p>Containers Containers are instances of Docker images. They run in isolated environments, ensuring that the application behaves consistently across different environments. Containers share the host OS kernel but have their own file system, process space, and network interfaces.</p> </li> <li> <p>Registries Docker images can be stored and shared through registries. The default registry is Docker Hub, but private registries can also be used. Registries allow versioning, distribution, and collaboration on Docker images.</p> </li> <li> <p>Docker compose Docker Compose is a tool for defining and running multi-container Docker applications. It allows you to define a multi-container application in a single file, specifying services, networks, and volumes.</p> </li> <li> <p>Docker engine Docker Engine is the core component that manages Docker containers. It includes a server, REST API, and a command-line interface (CLI). The Docker daemon runs on the host machine, and the Docker CLI communicates with it to build, run, and manage containers.</p> </li> <li> <p>Volumes Volumes provide a way for containers to persist data outside their lifecycle. They can be used to share data between containers or to persist data even if a container is stopped or removed.</p> </li> <li> <p>Networking Docker provides networking capabilities that allow containers to communicate with each other or with the external world. Containers can be connected to different networks, and ports can be mapped between the host and the containers.</p> </li> </ul>"},{"location":"microservices/2.docker-fundamentals/#container-orchestration","title":"Container orchestration","text":"<p>Whether managing a small cluster or a large-scale production environment, adopting container orchestration is crucial for containerized applications. Here are some container orchestrations:</p> <ul> <li> <p>Kubernetes: Kubernetes is the most widely adopted container orchestration platform. It automates the deployment, scaling, and management of containerized applications, providing a robust and extensible framework.</p> </li> <li> <p>Docker Swarm: Docker Swarm is a native clustering and orchestration solution provided by Docker. While it may not be as feature-rich as Kubernetes, it offers simplicity and seamless integration with Docker.</p> </li> <li> <p>Amazon ECS: Amazon Elastic Container Service (ECS) is a fully managed container orchestration service provided by AWS. It integrates with other AWS services and is suitable for users already utilizing the AWS ecosystem.</p> </li> <li> <p>Azure Kubernetes Service (AKS): AKS is a managed Kubernetes service offered by Microsoft Azure. It simplifies the deployment and management of Kubernetes clusters in the Azure cloud.</p> </li> </ul>"},{"location":"microservices/2.docker-fundamentals/#docker-desktop","title":"Docker Desktop","text":"<p>Docker Desktop is a powerful tool that provides a user-friendly interface and environment for developing, building, and testing applications using Docker containers on local machine. </p> <p>Docker Desktop provides a convenient environment for developers to work with containers on their personal machines.</p>"},{"location":"microservices/2.docker-fundamentals/#install-docker","title":"Install Docker","text":"<p>Here are the steps to install Docker on a different operating systems:</p> <p>Windows:</p> <p>Download Docker Desktop:</p> <ul> <li>Visit the Docker Desktop for Windows page.</li> <li>Click on the \"Download for Windows\" button.</li> <li>Follow the on-screen instructions to download the installer.</li> </ul> <p>Install Docker Desktop:</p> <ul> <li>Run the installer that you downloaded.</li> <li>Follow the installation wizard, accepting the default options.</li> <li>The installer may require you to restart your computer.</li> </ul> <p>Enable Hyper-V (Windows 10 Pro/Enterprise):</p> <ul> <li>If you're running Windows 10 Pro or Enterprise, Docker Desktop will use Hyper-V for virtualization. Ensure that Hyper-V is enabled in the Windows Features.</li> </ul> <p>Start Docker Desktop:</p> <ul> <li>Once installed, start Docker Desktop from the Start Menu.</li> <li>The Docker icon will appear in the system tray when Docker Desktop is running.</li> </ul> <p>macOS:</p> <p>Download Docker Desktop:</p> <ul> <li>Visit the Docker Desktop for Mac page.</li> <li>Click on the \"Download for Mac\" button.</li> <li>Follow the on-screen instructions to download the installer.</li> </ul> <p>Install Docker Desktop:</p> <ul> <li>Run the installer that you downloaded.</li> <li>Drag the Docker icon to the Applications folder.</li> <li>Launch Docker from Applications.</li> </ul> <p>Start Docker Desktop:</p> <ul> <li>Once installed, Docker Desktop should start automatically.</li> <li>The Docker icon will appear in the menu bar when Docker Desktop is running.</li> </ul> <p>Verify Docker install:</p> <p>To verify that Docker is installed correctly, open a terminal and run the following command:</p> <pre><code>docker --version\n\n# or\ndocker version\n</code></pre> <p>If you notice this, it indicates that your Docker is not in a running status.</p> <pre><code>error during connect: this error may indicate that the docker daemon is not running: Get \"http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/version\": open //./pipe/docker_engine: The system cannot find the file specified.\nClient:\n Cloud integration: v1.0.35\n Version:           24.0.2\n API version:       1.43\n Go version:        go1.20.4\n Git commit:        cb74dfc\n Built:             Thu May 25 21:53:15 2023\n OS/Arch:           windows/amd64\n Context:           default\n</code></pre> <p>After Docker desktop is started and if everything is set up correctly, you should see following message indicating that your Docker installation is working.</p> <pre><code>Client:\n Cloud integration: v1.0.35 \n Version:           24.0.2  \n API version:       1.43    \n Go version:        go1.20.4\n Git commit:        cb74dfc\n Built:             Thu May 25 21:53:15 2023\n OS/Arch:           windows/amd64\n Context:           default\n\nServer: Docker Desktop 4.21.1 (114176)\n Engine:\n  Version:          24.0.2\n  API version:      1.43 (minimum version 1.12)\n  Go version:       go1.20.4\n  Git commit:       659604f\n  Built:            Thu May 25 21:52:17 2023\n  OS/Arch:          linux/amd64\n  Experimental:     false\n containerd:\n  Version:          1.6.21\n  GitCommit:        3dce8eb055cbb6872793272b4f20ed16117344f8\n runc:\n  Version:          1.1.7\n  GitCommit:        v1.1.7-0-g860f061\n docker-init:\n  Version:          0.19.0\n  GitCommit:        de40ad0\n</code></pre> <p>Docker is now installed on your machine, and you can start using it to containerize your applications.</p>"},{"location":"microservices/2.docker-fundamentals/#docker-commands","title":"Docker Commands","text":"<p>For more comprehensive details on Docker commands, please refer to the Docker Commands Cheat Sheet on our website.</p>"},{"location":"microservices/2.docker-fundamentals/#conclusion","title":"Conclusion","text":"<p>Docker and containerization have changed the way we build and use application development. Now that you understand the basics of Docker, you're ready to dive deeper. Docker is straightforward and flexible, making it a great tool for developers. It ensures that your application works the same way in different situations, keeps things separate, and easily grows with your needs. So, go ahead and start your journey with containers.</p>"},{"location":"microservices/2.docker-fundamentals/#references","title":"References","text":"<ul> <li>Getting started guide</li> <li>Docker images</li> <li>Docker Documentation</li> <li>Docker Hub</li> </ul>"},{"location":"microservices/3-docker-getting-started/","title":"Chapter-3: Getting Started with Docker","text":"<p>Docker is a platform for developing, shipping, and running applications in containers. Containers allow you to package an application and its dependencies into a single unit, making it easy to deploy consistently across different environments.  </p> <p>In this lab, I will guide you through the process of creating Docker images, containers, and finally accessing the sample application in the web browser.</p> <p>If you are new to Docker and want to learn its fundamental concepts, please visit our website. - Exploring Docker Fundamentals </p>"},{"location":"microservices/3-docker-getting-started/#objective","title":"Objective","text":"<p>In this exercise, our objective is to accomplish and learn the following tasks:</p> <ol> <li>Step 1: Get the Sample Application</li> <li>Step 2: Create Docker Image</li> <li>Step 3: Create Docker Container</li> <li>Step 4: Port Binding</li> <li>Step 5: Browse the Frontend Application</li> <li>Step 6: View Docker Logs</li> <li>Step 7: Docker Commands</li> </ol>"},{"location":"microservices/3-docker-getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before starting this lab, ensure you have the following prerequisites in place:</p> <ul> <li>Visual Studio Code :  - Visual Studio Code Downloads.</li> <li>Docker desktop :  - Docker Downloads.</li> <li>Git Client tool:  - Git Downloads.</li> </ul> <p>Verify the docker installation by running following commands:</p> <pre><code>docker version\n# or\ndocker --version\n# or\ndocker -v\n</code></pre>"},{"location":"microservices/3-docker-getting-started/#step-1-get-the-sample-application","title":"Step 1: Get the Sample Application","text":"<p>To begin, you'll need a sample application to work with. You can either use an existing application or create a simple one. </p> <p>In this task, we'll start by searching for an image to run locally. For example, we'll use the <code>Nginx</code> image from Docker Hub using the following URL: Docker Hub Search</p>"},{"location":"microservices/3-docker-getting-started/#step-2-create-docker-image","title":"Step 2: Create Docker Image","text":"<p>Now that we've identified the image we want to use, let's pull it from Docker Hub into our local Docker Desktop and run it locally.</p> <p><pre><code>docker pull nginx\n\n# output\nUsing default tag: latest\nlatest: Pulling from library/nginx\na5573528b1f0: Pull complete \n8897d65c8417: Pull complete \nfbc138d1d206: Pull complete \n06f386eb9182: Pull complete \naeb2f3db77c3: Pull complete \n64fb762834ec: Pull complete \ne5a7e61f6ff4: Pull complete \nDigest: sha256:4c0fdaa8b6341bfdeca5f18f7837462c80cff90527ee35ef185571e1c327beac\nStatus: Downloaded newer image for nginx:latest\ndocker.io/library/nginx:latest\n</code></pre> </p> <p>List Docker images from Docker Desktop:</p> <pre><code>docker images\n\n# output\nREPOSITORY   TAG       IMAGE ID       CREATED        SIZE\nnginx        latest    6c7be49d2a11   2 months ago   192MB\n</code></pre>"},{"location":"microservices/3-docker-getting-started/#step-3-create-docker-container","title":"Step 3: Create Docker Container","text":"<p>In this step, we'll create a Docker container by running the <code>docker run</code> command for the image.</p> <pre><code>docker run nginx\n\n# output\n/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2024/01/15 04:27:56 [notice] 1#1: using the \"epoll\" event method\n2024/01/15 04:27:56 [notice] 1#1: nginx/1.25.3\n2024/01/15 04:27:56 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14) \n2024/01/15 04:27:56 [notice] 1#1: OS: Linux 6.3.13-linuxkit\n2024/01/15 04:27:56 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576\n2024/01/15 04:27:56 [notice] 1#1: start worker processes\n2024/01/15 04:27:56 [notice] 1#1: start worker process 29\n2024/01/15 04:27:56 [notice] 1#1: start worker process 30\n2024/01/15 04:27:56 [notice] 1#1: start worker process 31\n2024/01/15 04:27:56 [notice] 1#1: start worker process 32\n2024/01/15 04:27:56 [notice] 1#1: start worker process 33\n</code></pre> <p></p> <p>Open a new terminal and run the following command to list containers:</p> <pre><code>dockder ps\n\n# output\nCONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS     NAMES\n8d23e3ceb3da   nginx     \"/docker-entrypoint.\u2026\"   3 minutes ago   Up 2 minutes   80/tcp    lucid_edison\n</code></pre> <p>You can watch the <code>container logs</code> in the first terminal.</p> <p>To exit the container, press <code>Ctrl + C</code>.</p> <pre><code>2024/01/15 04:28:00 [notice] 1#1: signal 28 (SIGWINCH) received\n2024/01/15 04:28:00 [notice] 1#1: signal 28 (SIGWINCH) received\n2024/01/15 04:30:50 [notice] 1#1: signal 28 (SIGWINCH) received\n2024/01/15 04:30:50 [notice] 1#1: signal 28 (SIGWINCH) received\n</code></pre> <pre><code>docker run -d nginx \n\n# output \n6f5dbcae83bd3ac6a0ea8bdb45f753bf72a723179503d4b4ebce4ddeae2378e2\n\n# Now, you can run the following command to see the list of running containers:\ndocker ps\n</code></pre> <p>Alternatively, you can also run the image directly from Docker Hub. Here are the example commands:</p> <p><pre><code>docker run nginx:1.25.3-alpine\n\n# output\nUnable to find image 'nginx:1.25.3-alpine' locally\n1.25.3-alpine: Pulling from library/nginx\n2c03dbb20264: Pull complete \n0ed066aadd11: Pull complete \n4eeb1ddd7404: Pull complete \n9ba8827f116b: Pull complete \n2bc60ecca38f: Pull complete \n11d942ec6258: Pull complete \nfed1b403bb45: Pull complete \n392e92e0a8e8: Pull complete \nDigest: sha256:a59278fd22a9d411121e190b8cec8aa57b306aa3332459197777583beb728f59\nStatus: Downloaded newer image for nginx:1.25.3-alpine\n/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2024/01/15 04:39:23 [notice] 1#1: using the \"epoll\" event method\n2024/01/15 04:39:23 [notice] 1#1: nginx/1.25.3\n2024/01/15 04:39:23 [notice] 1#1: built by gcc 12.2.1 20220924 (Alpine 12.2.1_git20220924-r10) \n2024/01/15 04:39:23 [notice] 1#1: OS: Linux 6.3.13-linuxkit\n2024/01/15 04:39:23 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576\n2024/01/15 04:39:23 [notice] 1#1: start worker processes\n2024/01/15 04:39:23 [notice] 1#1: start worker process 29\n2024/01/15 04:39:23 [notice] 1#1: start worker process 30\n2024/01/15 04:39:23 [notice] 1#1: start worker process 31\n2024/01/15 04:39:23 [notice] 1#1: start worker process 32\n2024/01/15 04:39:23 [notice] 1#1: start worker process 33\n</code></pre> Now, you'll see two containers running, one from local Docker Desktop and the second one from the remote Docker Hub registry.</p> <pre><code>docker ps\n\n# output\nCONTAINER ID   IMAGE                 COMMAND                  CREATED              STATUS              PORTS     NAMES\n4df5f0ae77d9   nginx:1.25.3-alpine   \"/docker-entrypoint.\u2026\"   About a minute ago   Up About a minute   80/tcp    nostalgic_lamarr\n6f5dbcae83bd   nginx                 \"/docker-entrypoint.\u2026\"   6 minutes ago        Up 6 minutes        80/tcp    modest_hermann\n</code></pre> <p>docker images from docker desktop</p> <p></p> <p>docker containers from docker desktop</p> <p></p> <p>you can also run following commnds to see images and containers running locally.</p> <pre><code>docker image ls\n\n# output\nREPOSITORY   TAG             IMAGE ID       CREATED        SIZE\nnginx        latest          6c7be49d2a11   2 months ago   192MB\nnginx        1.25.3-alpine   74077e780ec7   2 months ago   43.5MB\n</code></pre> <pre><code>docker container ls\n\n# output\nCONTAINER ID   IMAGE                 COMMAND                  CREATED          STATUS          PORTS     NAMES\n4df5f0ae77d9   nginx:1.25.3-alpine   \"/docker-entrypoint.\u2026\"   5 minutes ago    Up 5 minutes    80/tcp    nostalgic_lamarr\n6f5dbcae83bd   nginx                 \"/docker-entrypoint.\u2026\"   10 minutes ago   Up 10 minutes   80/tcp    modest_hermann\n</code></pre>"},{"location":"microservices/3-docker-getting-started/#step-4-port-binding","title":"Step 4: Port Binding","text":"<p>Your application is now running inside the Docker container, and you've mapped port 8080 from the container to your host. This means you can access your application using <code>http://localhost:8080</code> in your web browser.</p> <pre><code># list the containers\ndocker ps\n\n# then stop the container \ndocker stop 6f5dbcae83bd\n</code></pre> <pre><code>docker run -d -p 8080:80 nginx:1.25.3-alpine\n\n# output\nf21ada11af57b799c9b834d0a6c8e6e1628c6289d64cf65fdc0968cbe94500fd\n</code></pre>"},{"location":"microservices/3-docker-getting-started/#step-5-browse-the-frontend-application","title":"Step 5: Browse the Frontend Application","text":"<p>Open your web browser and navigate to <code>http://localhost:8080</code> to access your Node.js application running in the Docker container.</p> <p></p>"},{"location":"microservices/3-docker-getting-started/#step-6-view-docker-logs","title":"Step 6: View Docker Logs","text":"<p>To view the logs of your running container, use the following command:</p> <p>This will display the logs generated by your application.</p> <p><pre><code>docker logs f21ada11af57\n</code></pre> </p> <pre><code>docker ps -a \n\n# output\nCONTAINER ID   IMAGE                 COMMAND                  CREATED          STATUS                      PORTS                  NAMES\nf21ada11af57   nginx:1.25.3-alpine   \"/docker-entrypoint.\u2026\"   7 minutes ago    Up 7 minutes                0.0.0.0:8080-&gt;80/tcp   nifty_goldberg\n4df5f0ae77d9   nginx:1.25.3-alpine   \"/docker-entrypoint.\u2026\"   19 minutes ago   Up 19 minutes               80/tcp                 nostalgic_lamarr\n6f5dbcae83bd   nginx                 \"/docker-entrypoint.\u2026\"   25 minutes ago   Exited (0) 10 minutes ago                          modest_hermann\n8d23e3ceb3da   nginx                 \"/docker-entrypoint.\u2026\"   31 minutes ago   Exited (0) 25 minutes ago                          lucid_edison\n</code></pre> <p>Naming the Container:</p> <p>You can also name the container using the <code>--name</code> flag:</p> <pre><code>docker run --name nginx-app -d -p 8080:80 nginx:1.25.3-alpine\n\n# output\n58e464680a8da16b717171732fb1b67b678b1c8efb115f9adad8d3257c6cc875\n\n# run following command to see the name\ndocker ps\ndocker logs nginx-app\n</code></pre>"},{"location":"microservices/3-docker-getting-started/#step-7-docker-commands","title":"Step 7: Docker Commands","text":"<p>For more comprehensive details on Docker commands, please refer to the Docker Commands Cheat Sheet on our website.</p>"},{"location":"microservices/3-docker-getting-started/#conclusion","title":"Conclusion","text":"<p>In summary, this guide introduced you to Docker, a tool that simplifies how we build, package, and run applications. We've covered essential steps, like getting an example application (nginx), creating Docker images and running containers. We've also learned how to manage ports, access apps in web browsers, and check what's happening behind the scenes with Docker logs. Plus, we touched on some common Docker commands.</p> <p>Docker is a powerful tool for containerization, enabling you to package and deploy applications with ease. By following these steps, you've created your first Docker application. </p>"},{"location":"microservices/3-docker-getting-started/#references","title":"References","text":"<ul> <li>Getting started guide</li> <li>Docker images</li> <li>Docker Documentation</li> <li>Docker Hub</li> <li>Nginx Docker Official Images</li> </ul>"},{"location":"microservices/4.aspnet-api/","title":"Chapter-4: Create Your First Microservice with .NET Core Web API","text":""},{"location":"microservices/4.aspnet-api/#introduction","title":"Introduction","text":"<p>Welcome to the first lab in our Microservices chapter. In this lab, we will look into creating a simple RESTful service using the ASP.NET Core Web API project template.</p> <p>This lab will demonstrate the process of building a RESTful service and generating a docker container using Dockerfile. By following this example, you will learn the fundamentals of creating RESTful APIs using the ASP.NET Core.</p>"},{"location":"microservices/4.aspnet-api/#technical-scenario","title":"Technical Scenario","text":"<p>As a <code>Backend (BE)</code> developer, you have been tasked with creating a RESTful service using .NET Core Web API, which is one of the services on our microservices list. This lab will serve as your introduction to the Microservices Architecture, starting with the basics of setting up a repository, creating a small project, and ultimately containerizing the microservice you build. The containerized microservice will then be pushed to the Azure Container Registry (ACR).</p> <p>The primary objective of this lab is to prepare an application for deployment on Kubernetes. The microservices you create in this lab will be utilized in subsequent labs, such as the creation of DevOps pipelines or the deployment to Azure Kubernetes Services (AKS). By completing this lab, you will gain a foundational understanding of how microservices can be developed, containerized, and integrated into a Kubernetes environment.</p>"},{"location":"microservices/4.aspnet-api/#objective","title":"Objective","text":"<p>In this exercise, our objective is to accomplish and learn the following tasks:</p> <ul> <li>Step-1: Create a new repo in azure DevOps</li> <li>Step-2: Clone the repository</li> <li>Step-3: Create a new Web API project</li> <li>Step-4: Test Web API project</li> <li>Step-5: Add Dockerfiles to the project</li> <li>Step-6: Build &amp; Test docker container locally</li> <li>Step-7: Publish docker container to ACR</li> </ul>"},{"location":"microservices/4.aspnet-api/#prerequisites","title":"Prerequisites","text":"<p>Before starting this lab, ensure you have the following prerequisites in place:</p> <ul> <li>An Organization in Azure DevOps</li> <li>A Project in Azure DevOps</li> <li>Create Repository permission</li> <li>Git client tool</li> <li>Download and install software for .NET development </li> <li>Docker and the VS Code Docker extension</li> <li>Azure Container Registry (ACR)</li> </ul>"},{"location":"microservices/4.aspnet-api/#architecture-diagram","title":"Architecture Diagram","text":"<p>The following diagram shows the high level steps to create the Restful service using .NET Core.</p> <p></p>"},{"location":"microservices/4.aspnet-api/#step-1-create-a-new-repo-in-azure-devops","title":"Step-1: Create a new repo in azure DevOps","text":"<p>We will create a new repository in Azure DevOps to store our project code and related files.</p> <p>To create a new repository in Azure DevOps, follow these steps:</p> <ol> <li>Login into azure DevOps -  Azure DevOps</li> <li>Select the project where we want to create the repo</li> <li>Click on <code>Repos</code> left nav link</li> <li>From the repo drop-down, select <code>New repository</code></li> <li>In the <code>Create a new repository</code> dialog, verify that Git is the repository type and enter a name for the new repository. </li> <li>You can also add a README and create a <code>.gitignore</code> for the type of code you plan to manage in the repo.</li> <li>I'd prefer to use lower case for all repos (one of the best practice)<ul> <li>Repo name - <code>aspnetapi</code> </li> </ul> </li> </ol> <p>Best-practice</p> <p>When creating repositories in Azure DevOps, it is recommended to use lower case for all repository names. Using lower case consistently throughout your repositories helps maintain consistency, readability, and ease of navigation within your projects.</p> <p>By adhering to this best practice, you ensure that your repository names are uniform and standardized, regardless of the specific domain or microservice they represent. This practice promotes clarity and reduces the chances of confusion or inconsistencies when working with multiple repositories within your organization.</p> <p>For example: </p> <p></p>"},{"location":"microservices/4.aspnet-api/#step-2-clone-the-repo-from-azure-devops","title":"Step-2: Clone the repo from azure DevOps","text":"<p>After creating the repository, we will clone it locally to establish a local working copy of the project.</p> <p>To clone a repository from Azure DevOps, you will need to have the Git client installed on your local machine. follow these steps to clone the source code locally:</p> <ol> <li> <p>Sign in to the Azure DevOps website Azure DevOps Login with your Azure DevOps account.</p> </li> <li> <p>Navigate to the project that contains the repository you want to clone.</p> </li> <li> <p>Click on the <code>Repos</code> tab in the navigation menu.</p> </li> <li> <p>Find the repository you want to clone and click on the <code>Clone</code> button.</p> </li> <li> <p>Copy the URL of the repository.</p> </li> <li> <p>Open a terminal window or command prompt on your local machine, and navigate to the directory where you want to clone the repository.</p> </li> <li> <p>Run the following command to clone the repository:</p> </li> </ol> <pre><code>git clone &lt;repository URL&gt;\n</code></pre> <p>When prompted, enter your Azure DevOps credentials.</p> <p>The repository will be cloned to your local machine, and you can start working with the code.</p> <p>Examples:</p> <pre><code>C:\\Users\\anji.keesari&gt;cd C:\\Source\\Repos\nC:\\Source\\Repos&gt;git clone https://keesari.visualstudio.com/Microservices/_git/aspnetapi\n\nor\n\n# cloning from main branch for the first time\ngit clone git clone https://keesari.visualstudio.com/Microservices/_git/aspnetapi  -b main C:\\Source\\Repos\\Microservices\\aspnetapi\n\n# cloning from feature branches\ngit clone https://keesari.visualstudio.com/Microservices/_git/aspnetapi  -b develop C:\\Source\\Repos\\Microservices\\aspnetapi\n</code></pre> <p>Please refer to our Git Cheat-Sheet, which provides a comprehensive list of Git commands and their usage. </p> <p>Anji Keesari - Git Commands</p>"},{"location":"microservices/4.aspnet-api/#step-3-create-a-new-net-core-web-api-project","title":"Step-3: Create a new .NET Core Web API project","text":"<p>Using the .NET Core Web API template, we will create a new project that serves as the foundation for our RESTful service.</p> <p>We will be using Visual Studio Code instead of Visual Studio to make things faster and easy and save time and money.</p> <p>Best-practice</p> <p>I recommend using Visual Studio Code (VS Code) as your preferred development environment instead of Visual Studio.</p> <p>Visual Studio Code is a lightweight, cross-platform code editor that offers powerful features and extensions tailored for modern development workflows. It provides a streamlined and customizable interface, allowing you to focus on coding without unnecessary overhead.</p> <p>To create a new .NET Core Web API project, you will need to have the .NET Core SDK installed on your machine. You can download the .NET Core SDK from the .NET website Download .NET.</p> <p>Once you have the .NET Core SDK installed, follow these steps to create a new .NET Core Web API project:</p> <ol> <li>Open a terminal window and navigate to the directory where you want to create your project.</li> <li>Run the <code>dotnet new</code> command to create a new .NET Core Web API project: Let's take a look some useful <code>dotnet</code> command before creating the project. Use this command to get the <code>dotnet</code> commands help so that your get idea on how use these commands better.  <pre><code>dotnet --help\n</code></pre> Use this command to get list of available <code>dotnet</code> project templates <pre><code>dotnet new --list\n\n# output\n\nThese templates matched your input: \n\nTemplate Name                                 Short Name           Language    Tags\n--------------------------------------------  -------------------  ----------  -------------------------------------\nASP.NET Core Empty                            web                  [C#],F#     Web/Empty\nASP.NET Core gRPC Service                     grpc                 [C#]        Web/gRPC\nASP.NET Core Web API                          webapi               [C#],F#     Web/WebAPI\nASP.NET Core Web App                          razor,webapp         [C#]        Web/MVC/Razor Pages\nASP.NET Core Web App (Model-View-Controller)  mvc                  [C#],F#     Web/MVC\nASP.NET Core with Angular                     angular              [C#]        Web/MVC/SPA\nASP.NET Core with React.js                    react                [C#]        Web/MVC/SPA\nASP.NET Core with React.js and Redux          reactredux           [C#]        Web/MVC/SPA\nBlazor Server App                             blazorserver         [C#]        Web/Blazor\nBlazor WebAssembly App                        blazorwasm           [C#]        Web/Blazor/WebAssembly/PWA\nClass Library                                 classlib             [C#],F#,VB  Common/Library\nConsole App                                   console              [C#],F#,VB  Common/Console\n.\n.\nand more....\n</code></pre> Use this command to actually create new project <pre><code>dotnet new webapi -o aspnetapi\n\nor \ndotnet new webapi -o aspnetapi --no-https -f net7.0\n\ncd aspnetapi\n\ncode . \n\nor \ncode -r ../aspnetapi\n</code></pre> Additional Notes: <pre><code>  `-o` parameter creates a directory\n  `--no-https` flag creates an app that will run without an HTTPS certificate\n  `-f` parameter indicates creation\n\n# Output\n\nC:\\WINDOWS\\system32&gt;cd C:\\Source\\Repos\n\nC:\\Source\\Repos&gt;dotnet new webapi -o aspnetapi\nThe template \"ASP.NET Core Web API\" was created successfully.\n\nProcessing post-creation actions...\nRunning 'dotnet restore' on C:\\Source\\Repos\\aspnetapi\\aspnetapi.csproj...\n  Determining projects to restore...\n  Restored C:\\Source\\Repos\\aspnetapi\\aspnetapi.csproj (in 247 ms).\nRestore succeeded.\n\nC:\\Source\\Repos&gt;cd aspnetapi\n\nC:\\Source\\Repos\\aspnetapi&gt;code .\n</code></pre></li> <li>Here is the example of adding packages to .net projects. <pre><code>dotnet add package Microsoft.EntityFrameworkCore.InMemory\n</code></pre></li> <li>Run the following command to restore the project's dependencies: <pre><code>dotnet restore\n</code></pre></li> </ol> <p>Mac</p> <p>If you're on a Mac with an Apple M1 chip, you need to install the Arm64 version of the SDK before following above commands.</p> <p>Download .NET 7.0.</p> <p>Check the install typing by running following in terminal</p> <pre><code>dotnet\n</code></pre> <p>You should see an output similar to the following if the installation is successful</p> <pre><code>anjikeesari@Anjis-MacBook-Pro-2 MyMicroservice % dotnet\n\nUsage: dotnet [options]\nUsage: dotnet [path-to-application]\n\nOptions:\n  -h|--help         Display help.\n  --info            Display .NET information.\n  --list-sdks       Display the installed SDKs.\n  --list-runtimes   Display the installed runtimes.\n\npath-to-application:\n  The path to an application .dll file to execute.\n</code></pre>"},{"location":"microservices/4.aspnet-api/#step-4-test-the-new-net-core-web-api-project","title":"Step-4: Test the new .NET core Web API project","text":"<p>dotnet build</p> <p>Run the following command to build the project:</p> <p><code>dotnet build</code> command will look for the project or solution file in the current directory and compile the code in it. It will also restore any dependencies required by the project and create the output files in the bin directory.</p> <pre><code>dotnet build\n\n# output\n\nMicrosoft (R) Build Engine version 17.0.1+b177f8fa7 for .NET\nCopyright (C) Microsoft Corporation. All rights reserved.\n\n  Determining projects to restore...\n  All projects are up-to-date for restore.\n  AspNetApi -&gt; C:\\Source\\Repos\\AspNetApi\\aspnet-api\\bin\\Debug\\net6.0\\AspNetApi.dll\n\nBuild succeeded.\n    0 Warning(s)\n    0 Error(s)\n\nTime Elapsed 00:00:01.51\n</code></pre> <p>dotnet run</p> <p>Run the following command to start the development server:</p> <p><code>dotnet run</code> command will look for the project or solution file in the current directory and compile the code in it. After compiling, it will run the application and any output will be displayed in the console. <pre><code>dotnet run\n\n# output\n\nBuilding...\ninfo: Microsoft.Hosting.Lifetime[14]\n      Now listening on: https://localhost:7136\ninfo: Microsoft.Hosting.Lifetime[14]\n      Now listening on: http://localhost:5136\ninfo: Microsoft.Hosting.Lifetime[0]\n      Application started. Press Ctrl+C to shut down.\ninfo: Microsoft.Hosting.Lifetime[0]\n      Hosting environment: Development\ninfo: Microsoft.Hosting.Lifetime[0]\n      Content root path: C:\\Source\\Repos\\AspNetApi\\aspnet-api\\\n</code></pre></p> <p>You will notice the URL in the output, copy the URL and paste it in your favorite browser. you will get a <code>404 error.</code> don\u2019t worry. Just type swagger at the end of the URL and press enter and you will get the following webpage.</p> <p></p> <ul> <li> <p>https://localhost:7136</p> </li> <li> <p>https://localhost:7136/swagger/index.html - Swagger URL</p> </li> <li> <p>https://localhost:7136/api/aspnetapi/v1/weatherforecast - API endpoint URL</p> </li> </ul> <p>If you are able to see this swagger URL in your browser then everything is created and setup as expected.</p> <p></p> <p>Use the following command to stop the application in VS Code</p> <p><pre><code>ctrl + c\n</code></pre> It is time to push your basic project template source into Azure DevOps Git repo.</p> <p>Best-practice</p> <p>To maintain good version control and ensure a reliable development process, it is strongly recommended to commit and push source code changes to your Git repository before proceeding to the next step.</p> <p>Use these git commands to push the source code.</p> <pre><code>git add .\ngit commit -am \"My fist commit - Create Web API project\"\ngit push\n</code></pre>"},{"location":"microservices/4.aspnet-api/#step-5-add-dockerfiles-to-the-api-project","title":"Step-5: Add Dockerfiles to the API project","text":"<p>Dockerfiles will be added to the project, which provide instructions for building a container image of our Web API application.</p> <p>There are multiple way to create <code>Dockerfile</code> depending on your code editor.  Here are the step-by-step instructions for creating a <code>Dockerfile</code> in a .NET Core Web API project:</p> <ol> <li>First, open your .NET Core Web API project in Visual Studio code or your favorite code editor.</li> <li>Next, create a new file in the root directory of your project and name it Dockerfile (with no file extension).</li> <li> <p>Open the Dockerfile and add the following code to the file: <pre><code>#See https://aka.ms/containerfastmode to understand how Visual Studio uses this Dockerfile to build your images for faster debugging.\n\nFROM mcr.microsoft.com/dotnet/aspnet:6.0 AS base\nWORKDIR /app\nEXPOSE 80\nEXPOSE 443\n\nFROM mcr.microsoft.com/dotnet/sdk:6.0 AS build\nWORKDIR /src\nCOPY [\"AspNetApi.csproj\", \".\"]\nRUN dotnet restore \"./AspNetApi.csproj\"\nCOPY . .\nWORKDIR \"/src/.\"\nRUN dotnet build \"AspNetApi.csproj\" -c Release -o /app/build\n\nFROM build AS publish\nRUN dotnet publish \"AspNetApi.csproj\" -c Release -o /app/publish\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"AspNetApi.dll\"]\n</code></pre> This code defines a Docker image that is based on the aspnet:6.0 image from Microsoft's container registry. The image is divided into four stages:</p> </li> <li> <p><code>base:</code> sets up the working directory and exposes port 80.</p> </li> <li><code>build:</code> restores the project dependencies, builds the project in Release mode, and copies the build output to the /app/build directory.</li> <li><code>publish:</code> publishes the project in Release mode and copies the published output to the /app/publish directory.</li> <li><code>final:</code> sets the working directory to <code>/app</code> and copies the published output from the <code>publish</code> stage to the current directory. It also specifies the entry point for the container, which is the <code>dotnet</code> command with the name of your project's DLL file.</li> </ol>"},{"location":"microservices/4.aspnet-api/#step-6-docker-build-run","title":"Step-6: Docker Build &amp; Run","text":"<p>We will build the Docker container locally using the Dockerfiles and ensure that the containerized application functions as expected.</p> <p><code>docker build</code> is a command that allows you to build a Docker image from a Dockerfile. The Dockerfile is a text file that contains instructions for Docker to build the image, including the base image to use, the files to include, the commands to run, and the ports to expose.</p> <p>To build and publish a container image for a .NET Core Web API project, you will need to have Docker installed on your machine. You can download Docker from the Docker website Get Started with Docker</p> <p>Once you have Docker installed, follow these steps to build and publish a container for your .NET Core Web API project:</p> <ol> <li>Open a terminal window and navigate to the root of the project.</li> <li>Run the <code>docker build</code> command to build the Docker image: <pre><code>docker build -t sample/aspnet-api:20230226.1 .\n</code></pre> output <pre><code>[+] Building 9.5s (19/19) FINISHED\n =&gt; [internal] load build definition from Dockerfile                                                                                                          0.0s \n =&gt; =&gt; transferring dockerfile: 878B                                                                                                                          0.0s \n =&gt; [internal] load .dockerignore                                                                                                                             0.0s \n =&gt; =&gt; transferring context: 374B  \n..            \n..\n..\n\n =&gt; =&gt; naming to docker.io/sample/aspnet-api:20230226.1                                                                                                             \n</code></pre> Verify the new image</li> </ol> <p>if you open the docker desktop you should be able to see the newly created image there.  3. Run the <code>docker run</code> command to start a container based on the image: <pre><code>docker run --rm -p 8080:80 sample/aspnet-api:20230226.1\n</code></pre> output <pre><code>info: Microsoft.Hosting.Lifetime[14]  \n      Now listening on: http://[::]:80\ninfo: Microsoft.Hosting.Lifetime[0]\n      Application started. Press Ctrl+C to shut down.\ninfo: Microsoft.Hosting.Lifetime[0]\n      Hosting environment: Production\ninfo: Microsoft.Hosting.Lifetime[0]\n      Content root path: /app/\n</code></pre> Wait for the container to start. You should see output in the terminal indicating that the container is listening on port 80. Open the docker desktop to see the newly created container in the docker desktop app </p> <p>Open a web browser and navigate to http://localhost:8080/api/values (or whatever URL corresponds to your Web API endpoint) to confirm that the Web API is running inside the Docker container.</p> <p>use these links for testing when you run docker command from vs code</p> <ul> <li>http://localhost:8080/swagger/index.html</li> <li>http://localhost:8080/api/aspnetapi/v1/heartbeat/ping</li> <li>http://localhost:8080/api/aspnetapi/v1/weatherforecast</li> </ul> <p></p> <p>Best-practice</p> <p>When working with Docker containers, it is recommended to follow a consistent naming convention to ensure clarity and organization. The following pattern is suggested for naming Docker containers:</p> <pre><code>docker build -t projectname/domainname/appname:yyyymmdd.sequence .\n\nexample:\ndocker build -t project1/sample/aspnet-api:20230226 .\n</code></pre> <p>You've successfully created a Dockerfile and built a Docker image for your .NET Core Web API project. You can now distribute the Docker image to other machines or deploy it to a cloud service like Azure or AWS.</p> <p>Tip</p> <p>If you need to clean up containers and images locally in Docker Desktop, you can use the following commands:</p> <pre><code># To delete all containers including its volumes use,\n#     docker rm -vf $(docker ps -aq)\n\n# To delete all the images,\n#     docker rmi -f $(docker images -aq)\n</code></pre>"},{"location":"microservices/4.aspnet-api/#step-7-push-docker-container-to-acr","title":"Step-7: Push docker container to ACR","text":"<p>Finally, we will publish the built Docker container to the Azure Container Registry (ACR), making it accessible for deployment and distribution.</p> <p>Now we've Docker Containers ready for push to Container Registry so that we can use them in future labs.</p> <p>To publish a Docker container image to Azure Container Registry (ACR), you will need to have the following:</p> <ol> <li>Create an Azure Container Registry. If you don't have one, you can create one by following the instructions in the Azure Portal or using Azure CLI. As part of the Chapter-2 we will create this azure resource, you can come back to this steps after ACR is created.</li> <li>Log in to your Azure Container Registry using the Docker command-line interface. You can do this by running the following command: <pre><code># azure Login\naz login\n\n# set the azure subscription\naz account set -s \"anji.keesari\"\n\n# Log in to the container registry\naz acr login --name acr1dev\n\n# To get the login server address for verification\naz acr list --resource-group rg-acr-dev --query \"[].{acrLoginServer:loginServer}\" --output table\n\n# output should look similar to this.\n\n# AcrLoginServer    \n# ------------------\n# acr1dev.azurecr.io\n</code></pre></li> <li><code>Tag</code> your Docker container with the full name of your Azure Container Registry, including the repository name and the version tag. You can do this by running the following command: <pre><code>docker tag sample/aspnet-api:20230226.1 acr1dev.azurecr.io/sample/aspnet-api:20230226.1\n</code></pre> Use this command to see a list of your current local images <pre><code>docker images\n\n# output\n\nREPOSITORY                             TAG          IMAGE ID       CREATED         SIZE\nacr1dev.azurecr.io/sample/aspnet-api   20230226.1   1bab8ba123ca   2 hours ago     213MB\n</code></pre></li> <li>Push your Docker container to your Azure Container Registry using the Docker command-line interface. You can do this by running the following command: <pre><code>docker push acr1dev.azurecr.io/sample/aspnet-api:20230226.1\n\n# output\n\nThe push refers to repository [acr1dev.azurecr.io/sample/aspnet-api]\na592c2e20b23: Pushed\n5f70bf18a086: Layer already exists\nd57ad0aaee3b: Layer already exists\naff5d88d936a: Layer already exists\nb3b2bd456a19: Layer already exists\n2540ef4bc011: Layer already exists\n94100d1041b6: Layer already exists\nbd2fe8b74db6: Layer already exists\n20230226.1: digest: sha256:026ec79d24fca0f30bcd90c7fa17e82a2347cf7bc5ac5d762a630277086ed0d1 size: 1995\n</code></pre></li> <li>Wait for the push to complete. Depending on the size of your Docker container and the speed of your internet connection, this may take a few minutes.</li> <li>Verify the newly pushed image to ACR. <pre><code># List images in registry\naz acr repository list --name acr1dev --output table\n\n# output\n\nResult\n-------------------------------\nmcr.microsoft.com/dotnet/aspnet\nmcr.microsoft.com/dotnet/sdk\nsample/aspnet-api\n</code></pre></li> <li>Show the new tags of a image in the acr <pre><code>az acr repository show-tags --name acr1dev --repository sample/aspnet-api --output table\n\n# output\n\nResult\n----------\n20230220.1\n20230226.1\n</code></pre></li> </ol> <p>You've successfully pushed your Docker container to Azure Container Registry. You can now use the Azure Portal or Azure CLI to manage your container and deploy them to Azure services like Azure Kubernetes Service (AKS).</p>"},{"location":"microservices/4.aspnet-api/#step-8-pull-docker-container-from-acr","title":"Step-8: Pull docker container from ACR","text":"<p>Pull docker container from ACR is something may be helpful during container troubleshooting.</p> <p>To pull a Docker container from Azure Container Registry (ACR), you need to perform the following steps:</p> <ol> <li>Log in to your Azure Container Registry using the Docker command-line interface. You can do this by running the following command: <pre><code># Log in to the container registry\naz acr login --name acr1dev\n</code></pre></li> <li>Pull your Docker container from your Azure Container Registry using the Docker command-line interface. You can do this by running the following command: <pre><code>docker pull acr1dev.azurecr.io/sample/aspnet-api:20230226.1\n\n# output\n\n20230226.1: Pulling from sample/aspnet-api\n01b5b2efb836: Already exists\nc4c81489d24d: Already exists\n95b82a084bc9: Already exists\nbb369c4b0f26: Already exists \nc888ac593815: Already exists\n14ce87409b2e: Already exists\n4f4fb700ef54: Already exists\nd15d1be868b7: Already exists\nDigest: sha256:026ec79d24fca0f30bcd90c7fa17e82a2347cf7bc5ac5d762a630277086ed0d1\nStatus: Downloaded newer image for acr1dev.azurecr.io/sample/aspnet-api:20230226.1\nacr1dev.azurecr.io/sample/aspnet-api:20230226.1\n</code></pre></li> <li>Wait for the pull to complete. Depending on the size of your Docker container and the speed of your internet connection, this may take a few minutes. </li> <li>Verify the recently pulled container from ACR to make sure it running as expected <pre><code>docker run --rm -p 8080:80 acr1dev.azurecr.io/sample/aspnet-api:20230226.1\n</code></pre> Test the container running following URL</li> </ol> <p></p> <p>http://localhost:8080/swagger/index.html</p> <p>You've successfully pulled your Docker container from Azure Container Registry. You can now use the Docker command-line interface to manage your container and run them locally or deploy them to other environments.</p>"},{"location":"microservices/4.aspnet-api/#reference","title":"Reference","text":"<ul> <li>Microsoft MSDN - Tutorial: Create a web API with ASP.NET Core</li> <li>Microsoft MSDN - Create and deploy a cloud-native ASP.NET Core microservice</li> <li>Microsoft MSDN - .NET Tutorial - Your First Microservice</li> <li>Visual Studio Core - ASP.NET Core in a container</li> <li>Visual Studio Core - Docker in Visual Studio Code</li> <li>Visual Studio Core - Node.js in a container</li> <li>github - ASP.NET Core Docker Sample</li> <li>Containerize a .NET application</li> </ul>"},{"location":"microservices/5.node-api/","title":"Chapter-5: Create Your Second Microservice with Node.js","text":""},{"location":"microservices/5.node-api/#introduction","title":"Introduction","text":"<p>Welcome to the second lab in our Microservices chapter. In this session, I will guide you through the creation of a simple RESTful service using the Node.js <code>npx express-generator</code> project template.</p> <p>This lab aims to illustrate the process of building a RESTful service and generating a Docker container using a Dockerfile. By following this example, you will gain a solid understanding of the fundamentals involved in creating RESTful APIs with Node.js.</p>"},{"location":"microservices/5.node-api/#technical-scenario","title":"Technical Scenario","text":"<p>As a <code>Backend (BE)</code> developer, you have been tasked with creating a RESTful service using Node JS, which is one of the services on our microservices list. This lab will serve as your introduction to the Microservices Architecture, starting with the basics of setting up a repository, creating a small API project, and ultimately containerizing the microservice you build. The containerized microservice will then be pushed to the Azure Container Registry (ACR).</p> <p>The primary objective of this lab is to prepare an application for deployment on Kubernetes. The microservices you create in this lab will be utilized in subsequent labs, such as the creation of DevOps pipelines or the deployment to Azure Kubernetes Services (AKS). By completing this lab, you will gain a foundational understanding of how microservices can be developed, containerized, and integrated into a Kubernetes environment.</p>"},{"location":"microservices/5.node-api/#objective","title":"Objective","text":"<p>In this exercise, our objective is to accomplish and learn the following tasks:</p> <ul> <li>Step-1: Setup repository in Azure DevOps.</li> <li>Step-2: Create a new Node.js API project.</li> <li>Step-3: Test Node.js API project.</li> <li>Step-4: Add Dockerfiles to the project.</li> <li>Step-5: Docker build locally.</li> <li>Step-6: Docker run locally.</li> <li>Step-7: Publish the Docker container to ACR.</li> </ul>"},{"location":"microservices/5.node-api/#prerequisites","title":"Prerequisites","text":"<p>Before starting this lab, ensure you have the following prerequisites in place:</p> <ul> <li>Node.js and npm:  - Node.js Downloads.</li> <li>Docker and the VS Code Docker extension :  - Docker Downloads.</li> <li>Git Client tool:  - Git Downloads.</li> <li>A project in Azure DevOps and Git Repository: Initialize a Git repository for your Node.js application.</li> <li>Azure Container Registry (ACR)</li> </ul>"},{"location":"microservices/5.node-api/#architecture-diagram","title":"Architecture Diagram","text":"<p>The following diagram shows the high level steps to create the Rest API using Node JS.</p> <p></p>"},{"location":"microservices/5.node-api/#step-1-setup-repository-in-azure-devops","title":"Step-1: Setup repository in Azure DevOps.","text":"<p>For this project, you can either leverage an existing Git repository created in our first chapter or initiate a new one.</p> <p>To clone an existing repository, execute the following command:</p> <pre><code>git clone https://keesari.visualstudio.com/Microservices/_git/microservices\n</code></pre>"},{"location":"microservices/5.node-api/#step-2-create-a-new-node-js-api-project","title":"Step-2: Create a new <code>Node JS</code> API project","text":"<p>In this step, we will set up a new Node.js API project using a basic Express application as our example. To expedite the process, we'll utilize Express's scaffolding tool to generate the necessary directory structure and essential files.</p> <p>Open your terminal and execute the following commands:</p> <pre><code>$ npx express-generator --no-view src\n$ cd src\n$ npm install\n</code></pre> <p>npx express-generator:</p> <p>The npx express-generator command initializes the project, creating a structure that includes directories like 'bin' and 'routes'.</p> <p></p> <p>npm install:</p> <p>Ensure you run npm install to set up and configure all required Node.js modules.</p> <p>This step ensures that your project is equipped with the necessary dependencies, allowing seamless integration with Docker and efficient containerization of your Node.js application.</p> <p></p> <p>folder structure</p> <p>you've established the foundation for your Node.js API project, complete with a standardized directory structure and essential files.</p> <p></p> <p>This should have created a number of files in your directory, including bin and routes directories. Make sure to run npm install so that npm can get all of your Node.js modules set up and ready to use.</p>"},{"location":"microservices/5.node-api/#step-3-test-the-node-js-api-project","title":"Step-3: Test the Node JS API project","text":"<p>Now, let's verify that our Node.js API project is functioning correctly. We'll initiate the application for the first time, utilizing the default routes defined in <code>app.js</code>.</p> <p>Ensure you are in the project directory, and in your terminal, execute the following command to start the application: <pre><code>npm start\n</code></pre></p> <p>This command launches the Node.js application, making it accessible locally.</p> <p>Open your web browser and navigate to http://localhost:3000</p> <p></p> <p>You confirm that your Node.js API project is up and running on your local environment. This preliminary test ensures the initial functionality of your application before proceeding with additional configurations or containerization.</p>"},{"location":"microservices/5.node-api/#step-4-add-dockerfiles-to-the-mvc-project","title":"Step-4: Add Dockerfiles to the MVC project","text":"<p>To seamlessly containerize our Node.js API project, let's create a Dockerfile in the root directory of your project and incorporate the following code. The Dockerfile provides instructions for building a container image of our Node.js API.</p> <pre><code># Use the official Node.js image from Docker Hub with a specific version\nFROM node:18.16.0-alpine3.17\n\n# Create a directory for the application in the container\nRUN mkdir -p /opt/app\n\n# Set the working directory inside the container to /opt/app\nWORKDIR /opt/app\n\n# Copy package.json and package-lock.json to the container's working directory\nCOPY src/package.json src/package-lock.json .\n\n# Install Node.js dependencies based on the package.json and package-lock.json\nRUN npm install\n\n# Copy the entire contents of the 'src' directory to the container's working directory\nCOPY src/ .\n\n# Expose port 3000 to allow external access to the application\nEXPOSE 3000\n\n# Specify the command to run when the container starts (start the application)\nCMD [\"npm\", \"start\"]\n</code></pre> <p>Note</p> <p>Read inline comments of the Dockerfile for understanding the Dockerfile instructions</p> <p></p>"},{"location":"microservices/5.node-api/#step-5-docker-build-locally","title":"Step-5: Docker build locally","text":"<p>We will build the Docker container locally using the Dockerfiles and ensure that the containerized application functions as expected.</p> <p>The <code>docker build</code> command is used to build Docker images from a Dockerfile.  </p> <pre><code>docker build -t sample/node-api:20240101.1 .\n</code></pre> <p>output</p> <p></p> <p>When you run the <code>docker build</code> command, Docker looks for a Dockerfile in the specified directory (PATH) and reads the instructions in the file to build a new image. </p> <p>The Dockerfile contains a series of instructions that define how to build the image, such as copying files, running commands, and setting environment variables. </p>"},{"location":"microservices/5.node-api/#step-6-docker-run-locally","title":"Step-6: Docker run locally","text":"<p>Run the Docker container locally to verify that the application functions correctly within a containerized environment. This step ensures that the containerized application operates as expected on your local machine.</p> <p>Run the <code>docker run</code> command to start a container based on the image:</p> <p><pre><code>docker run --rm -p 3000:3000 sample/node-api:20240101.1 .\n</code></pre> output</p> <p><pre><code>Compiled successfully!\n\nYou can now view node-api in the browser.\n\n  Local:            http://localhost:3000\n  On Your Network:  http://172.17.0.2:3000\n\nNote that the development build is not optimized.\nTo create a production build, use npm run build.\n\nwebpack compiled successfully\nCompiling...\nCompiled successfully!\nwebpack compiled successfully\n</code></pre> if you open the docker desktop you will notice the new image &amp; container started running.</p> <p>Image</p> <p></p> <p>Container</p> <p></p> <p>This will start the Node.js application in the Docker container and map the container's port 3000 to your local machine's port 3000. </p> <p>Your Node.js application is now running inside a Docker container.</p> <p>Open your favorite browser and enter the following URL to see the running application in port 3000</p> <p>http://localhost:3000/</p> <p></p> <p>You now have a basic Node.js application up and running. From here, you can continue building out your application by adding more and more code as per your requirements.</p>"},{"location":"microservices/5.node-api/#step-7-push-docker-container-to-acr","title":"Step-7: Push docker container to ACR","text":"<p>Now that we have Docker containers ready locally, it's time to push them to the Container Registry for future deployment on Azure Kubernetes Services (AKS). This step is crucial for preparing the container for deployment in a cloud environment.</p> <p>To publish a Docker container to Azure Container Registry (ACR), you will need to have the following:</p> <p>Create an Azure Container Registry. If you don't have one, you can create one by following the instructions in the Azure Portal or using Azure CLI.</p> <p>Log in to your Azure Container Registry using the Docker command-line interface. You can do this by running the following command:</p> <pre><code># azure Login\naz login\n\n# set the azure subscription\naz account set -s \"anji.keesari\"\n\n# Log in to the container registry\naz acr login --name acr1dev\n# Login Succeeded\n# To get the login server address for verification\naz acr list --resource-group rg-acr-dev --query \"[].{acrLoginServer:loginServer}\" --output table\n\n# output should look similar to this.\n\n# AcrLoginServer    \n# ------------------\n# acr1dev.azurecr.io\n</code></pre> <p>list all the Docker images that are available on the local system</p> <pre><code>docker images\n\n# output\n\nREPOSITORY                                                TAG                                                                          IMAGE ID       CREATED         SIZE\nsample/aspnet-app                                         20230312.1                                                                   587f347206bc   8 minutes ago   216MB\n.\n.\n.\n</code></pre> <p><code>Tag</code> your Docker container image with the full name of your Azure Container Registry, including the repository name and the version tag. You can do this by running the following command:</p> <pre><code>docker tag sample/node-api:20240101.1 acr1dev.azurecr.io/sample/node-api:20240101.1\n</code></pre> <p>Push your Docker container image to your Azure Container Registry using the Docker command-line interface. You can do this by running the following command:</p> <pre><code>docker push acr1dev.azurecr.io/sample/node-api:20240101.1\n\n# Output\nThe push refers to repository [acr1dev.azurecr.io/sample/node-api]\n649a035a1734: Pushed\n4061bd2dd536: Pushed\nc0257b3030b0: Pushed\n912a3b0fc587: Pushed\na36186d93e25: Pushed\na3d997b065bc: Pushed\n65d358b7de11: Pushed\nf97384e8ccbc: Pushed\nd56e5e720148: Pushed\nbeee9f30bc1f: Pushed\n20240101.1: digest: sha256:73f0669d18c6cae79beb81edc8c523191710f9ec4781d590884b46326f9ad6f9 size: 2419\n</code></pre> <p>Wait for the push to complete. Depending on the size of your Docker container image and the speed of your internet connection, this may take a few minutes.</p> <p>Verify the newly pushed image to ACR.</p> <pre><code>az acr repository list --name acr1dev --output table\n\n# Output\nResult\n-------------------------------\nmcr.microsoft.com/dotnet/aspnet\nmcr.microsoft.com/dotnet/sdk\nsample/aspnet-api\nsample/aspnet-app\nsample/node-api\n</code></pre> <p>Show the new tags of a image in the acr</p> <pre><code>az acr repository show-tags --name acr1dev --repository sample/node-api --output table\n\n# output\n\nResult\n----------\n20240101.1\n</code></pre> <p>You've successfully pushed your Docker container image to Azure Container Registry. You can now use the Azure Portal or Azure CLI to manage your container images and deploy them to Azure services like Azure Kubernetes Service (AKS).</p>"},{"location":"microservices/5.node-api/#conclusion","title":"Conclusion","text":"<p>So, we've covered Docker and learned how to run a basic Node.js application inside a container. Now, you should feel confident and ready to create your own Dockerfile, tapping into the cool features that Docker brings to your development experience.</p>"},{"location":"microservices/5.node-api/#reference","title":"Reference","text":"<ul> <li>Containerize a Node.js application</li> <li>Dockerizing a Node.js Web Application</li> </ul>"},{"location":"microservices/6.aspnet-app/","title":"Chapter-6: Create Your First Website using .NET Core MVC Application","text":""},{"location":"microservices/6.aspnet-app/#introduction","title":"Introduction","text":"<p>In our previous labs, we have explored the creation of Microservices to demonstrate the Microservices architecture pattern. In this lab and the next, we will shift our focus to the MicroFrontend architecture pattern by creating a couple of MicroFrontend UI applications.</p>"},{"location":"microservices/6.aspnet-app/#technical-scenario","title":"Technical Scenario","text":"<p>As a Frontend (FE) developer, your task is to develop a website or UI application using ASP.NET Core MVC technology. This application represents one of the small Website (UI) components in our MicroFrontend applications list.</p> <p>This lab will guide you through the process of building an ASP.NET Core MVC application. We will begin by creating a new Git repository or utilizing an existing one. Next, we will generate an MVC project template and proceed to containerize the UI application. Finally, we will push the containerized UI application to the Azure Container Registry (ACR) in preparation for deployment to Azure Kubernetes Services (AKS).</p> <p>The objective is to prepare a UI application for deployment on Kubernetes. The UI applications developed in this lab will be utilized in subsequent labs, such as the creation of DevOps pipelines or the deployment to Azure Kubernetes Services.</p>"},{"location":"microservices/6.aspnet-app/#objective","title":"Objective","text":"<p>In this exercise, our objective is to accomplish and learn the following tasks:</p> <ul> <li>Step-1: Create a new ASP.NET Core Web App (MVC project)</li> <li>Step-2: Test ASP.NET MVC project</li> <li>Step-3: Update home page contents [optional]</li> <li>Step-4: Add Dockerfiles to MVC project</li> <li>Step-5: Docker Build locally</li> <li>Step-6: Docker Run locally</li> <li>Step-7: Publish docker container to ACR</li> </ul>"},{"location":"microservices/6.aspnet-app/#prerequisites","title":"Prerequisites","text":"<p>Before starting this lab, make sure you have the following prerequisites in place:</p> <ul> <li>Clone existing Microservices repo</li> <li>Download and install software for .NET development </li> <li>Docker desktop</li> <li>VS Code Docker extension</li> <li>Azure Container Registry (ACR)</li> </ul>"},{"location":"microservices/6.aspnet-app/#architecture-diagram","title":"Architecture Diagram","text":"<p>The following diagram shows the high level steps to create the website using ASP.NET Core MVC.</p> <p></p>"},{"location":"microservices/6.aspnet-app/#step-1-create-a-new-aspnet-core-web-app-mvc-project","title":"Step-1: Create a new ASP.NET Core Web App (MVC project)","text":"<p>Create a new ASP.NET Core Web App using the MVC project template. This will serve as the foundation for our UI application.</p> <p>To create new ASP.NET Core Web App (Model-View-Controller) project you can use either Visual Studio Code or Visual Studio 2022 (latest version).</p> <p>Using Visual Studio Code</p> <p>Assuming you already have the .NET Core SDK installed in your system, follow these steps to create a new .NET Core MVC project:</p> <p>Open Visual Studio Code and open the terminal and use following command to see list of templates.</p> <pre><code>dotnet new --list\n</code></pre> <p>output</p> <pre><code>These templates matched your input: \n\nTemplate Name                                 Short Name           Language    Tags\n--------------------------------------------  -------------------  ----------  -------------------------------------\nASP.NET Core Empty                            web                  [C#],F#     Web/Empty\nASP.NET Core gRPC Service                     grpc                 [C#]        Web/gRPC\nASP.NET Core Web API                          webapi               [C#],F#     Web/WebAPI\nASP.NET Core Web App                          razor,webapp         [C#]        Web/MVC/Razor Pages\nASP.NET Core Web App (Model-View-Controller)  mvc                  [C#],F#     Web/MVC\nASP.NET Core with Angular                     angular              [C#]        Web/MVC/SPA\nASP.NET Core with React.js                    react                [C#]        Web/MVC/SPA\nASP.NET Core with React.js and Redux          reactredux           [C#]        Web/MVC/SPA\nBlazor Server App                             blazorserver         [C#]        Web/Blazor\nBlazor WebAssembly App                        blazorwasm           [C#]        Web/Blazor/WebAssembly/PWA\nClass Library                                 classlib             [C#],F#,VB  Common/Library\nConsole App                                   console              [C#],F#,VB  Common/Console\n.\n.\nand more....\n</code></pre> <p>Pick the following template for our MVC project from the list.</p> <p><pre><code>ASP.NET Core Web App (Model-View-Controller)  mvc                  [C#],F#     Web/MVC\n</code></pre> Use <code>dotnet new</code> command to create new MVC project</p> <pre><code>dotnet new mvc -o aspnet-app\n</code></pre> <p>output</p> <pre><code>The template \"ASP.NET Core Web App (Model-View-Controller)\" was created successfully.\nThis template contains technologies from parties other than Microsoft, see https://aka.ms/aspnetcore/6.0-third-party-notices for details.\n\nProcessing post-creation actions...\nRunning 'dotnet restore' on C:\\Source\\Repos\\microservices\\aspnet-app\\aspnet-app.csproj...\n  Determining projects to restore...\n  Restored C:\\Source\\Repos\\microservices\\aspnet-app\\aspnet-app.csproj (in 95 ms).\nRestore succeeded.\n</code></pre> <p>Using Visual Studio 2022</p> <p>In case if you want to use Visual Studio only then, here are the steps to create a new ASP.NET Core Web App using the Model-View-Controller (MVC) architectural pattern:</p> <ul> <li>Open Visual Studio and select \"Create a new project\".</li> <li>In the \"Create a new project\" window, select \"ASP.NET Core Web Application\" and click \"Next\".</li> <li>Choose a name and location for your project and click \"Create\".</li> <li>In the \"Create a new ASP.NET Core Web Application\" window, select \"Web Application (Model-View-Controller)\" and click \"Create\".</li> </ul> <p>Visual Studio will create a new project for you with the necessary files and folders to get started.</p> <p>Once the MVC project is created successfully you will see the project folder structure like below:</p> <p></p> <p>cd to the new folder here <code>aspnet-app</code></p> <pre><code>cd .\\aspnet-app\\\n</code></pre>"},{"location":"microservices/6.aspnet-app/#step-2-test-the-new-aspnet-core-web-app-project","title":"Step-2: Test the new ASP.NET core Web App project","text":"<p>Perform testing of the ASP.NET MVC project to ensure its functionality and identify any issues or bugs that may need to be addressed.</p> <p>Run the following command to build the project:</p> <p><code>dotnet build</code> command will look for the project or solution file in the current directory and compile the code in it. It will also restore any dependencies required by the project and create the output files in the bin directory. </p> <pre><code>dotnet build\n</code></pre> <p>output</p> <p><pre><code>Microsoft (R) Build Engine version 17.0.1+b177f8fa7 for .NET\nCopyright (C) Microsoft Corporation. All rights reserved.\n\n  Determining projects to restore...\n  All projects are up-to-date for restore.\n  aspnet-app -&gt; C:\\Source\\Repos\\microservices\\aspnet-app\\bin\\Debug\\net6.0\\aspnet-app.dll\n\nBuild succeeded.\n    0 Warning(s)\n    0 Error(s)\n\nTime Elapsed 00:00:05.07\n</code></pre> Run the following command to start the development server:</p> <p><code>dotnet run</code> command will look for the project or solution file in the current directory and compile the code in it. After compiling, it will run the application and any output will be displayed in the console.</p> <pre><code>dotnet run\n</code></pre> <p>output</p> <pre><code>Building...\ninfo: Microsoft.Hosting.Lifetime[14]\n      Now listening on: https://localhost:7289\ninfo: Microsoft.Hosting.Lifetime[14]\n      Now listening on: http://localhost:5023\ninfo: Microsoft.Hosting.Lifetime[0]\n      Application started. Press Ctrl+C to shut down.\ninfo: Microsoft.Hosting.Lifetime[0]\n      Hosting environment: Development\ninfo: Microsoft.Hosting.Lifetime[0]\n      Content root path: C:\\Source\\Repos\\microservices\\aspnet-app\\\n</code></pre> <p>You will notice the URL in the output, copy the URL and paste it in your favorite browser. https://localhost:7289/</p> <p></p> <p>For the first time if you are able to see this page in your browser that means ASP.NET MVC project is created as expected.</p> <p>Use these git commands to push the source code to remote git.</p> <pre><code>git add .\ngit commit -a -m \"My fist mvc app commit.\"\ngit push --set-upstream origin main\ngit status\n</code></pre> <p>Note</p> <p>For the simplicity I am creating all the applications in the same repo called <code>microservices</code> but in reality you may need to follow your organization standards for creating git repos</p> <p>New folder structure will look like below in the microservices git repo. you will notice the new <code>aspnet-app</code> folder with MVC project source code. </p> <p></p>"},{"location":"microservices/6.aspnet-app/#step-3-update-home-page-contentsoptional","title":"Step-3: Update home page contents[Optional]","text":"<p>Let's update our landing page to show .NET version, Operating System, processor, CPU core etc.. this information will provide us some technical details of the application when we deploy it in our AKS in the upcoming labs.  </p> <p>We are going to update the <code>Index.html</code> file with following code.</p> <p>Index.html<pre><code>@page\n@using System.Runtime.InteropServices\n@using System.IO\n@using System.Diagnostics\n@{\n    //ViewData[\"Title\"] = \"Home page\";\n    var hostName = System.Net.Dns.GetHostName();\n    var ipList = await System.Net.Dns.GetHostAddressesAsync(hostName);\n\n    const long Mebi = 1024 * 1024;\n    const long Gibi = Mebi * 1024;\n    GCMemoryInfo gcInfo = GC.GetGCMemoryInfo();\n    string totalAvailableMemory = GetInBestUnit(gcInfo.TotalAvailableMemoryBytes);\n\n    bool cgroup = RuntimeInformation.OSDescription.StartsWith(\"Linux\") &amp;&amp; Directory.Exists(\"/sys/fs/cgroup/memory\");\n    string memoryUsage = string.Empty;\n    string memoryLimit = string.Empty;\n\n    if (cgroup)\n    {\n        string usage = System.IO.File.ReadAllLines(\"/sys/fs/cgroup/memory/memory.usage_in_bytes\")[0];\n        string limit = System.IO.File.ReadAllLines(\"/sys/fs/cgroup/memory/memory.limit_in_bytes\")[0];\n        memoryUsage = GetInBestUnit(long.Parse(usage));\n        memoryLimit = GetInBestUnit(long.Parse(limit));\n    }\n}\n&lt;div align=\"center\"&gt;\n    &lt;table class=\"table table-striped table-hover\"&gt;\n        &lt;tr&gt;\n            &lt;td&gt;.NET version&lt;/td&gt;\n            &lt;td&gt;@RuntimeInformation.FrameworkDescription&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n            &lt;td&gt;Operating system&lt;/td&gt;\n            &lt;td&gt;@RuntimeInformation.OSDescription&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n            &lt;td&gt;Processor architecture&lt;/td&gt;\n            &lt;td&gt;@RuntimeInformation.OSArchitecture&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n            &lt;td&gt;CPU cores&lt;/td&gt;\n            &lt;td&gt;@Environment.ProcessorCount&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n            &lt;td&gt;Containerized&lt;/td&gt;\n            &lt;td&gt;@(Environment.GetEnvironmentVariable(\"DOTNET_RUNNING_IN_CONTAINER\") is null ? \"false\" : \"true\")&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n            &lt;td&gt;Memory, total available GC memory&lt;/td&gt;\n            &lt;td&gt;@totalAvailableMemory&lt;/td&gt;\n        &lt;/tr&gt;\n        @if (cgroup)\n        {\n            &lt;tr&gt;\n                &lt;td&gt;cgroup memory usage&lt;/td&gt;\n                &lt;td&gt;@memoryUsage&lt;/td&gt;\n            &lt;/tr&gt;\n            &lt;tr&gt;\n                &lt;td&gt;cgroup memory limit&lt;/td&gt;\n                &lt;td&gt;@memoryLimit&lt;/td&gt;\n            &lt;/tr&gt;\n        }\n        &lt;tr&gt;\n            &lt;td&gt;Host name&lt;/td&gt;\n            &lt;td&gt;@hostName&lt;/td&gt;\n        &lt;/tr&gt;\n        &lt;tr&gt;\n            &lt;td style=\"vertical-align: top\"&gt;Server IP address&lt;/td&gt;\n            &lt;td&gt;\n                @{\n                    foreach (var ip in ipList)\n                    {\n                        @ip\n                        &lt;br /&gt;\n                    }\n                }\n            &lt;/td&gt;\n        &lt;/tr&gt;\n    &lt;/table&gt;\n&lt;/div&gt;\n\n@{\n    string GetInBestUnit(long size)\n    {\n        if (size &lt; Mebi)\n        {\n            return $\"{size} bytes\";\n        }\n        else if (size &lt; Gibi)\n        {\n            decimal mebibytes = Decimal.Divide(size, Mebi);\n            return $\"{mebibytes:F} MiB\";\n        }\n        else\n        {\n            decimal gibibytes = Decimal.Divide(size, Gibi);\n            return $\"{gibibytes:F} GiB\";\n        }\n    }\n}\n</code></pre> Here is the home page with new details:</p> <p></p> <p>Now it is time to commit our source code </p> <pre><code>git add .\ngit commit -am \"updated landing page\"\ngit push \n</code></pre>"},{"location":"microservices/6.aspnet-app/#step-4-add-dockerfiles-to-the-mvc-project","title":"Step-4: Add Dockerfiles to the MVC project","text":"<p>This file define the necessary instructions to build Docker images for the application.</p> <p>Create a Dockerfile in the root directory of the MVC project and copy following code.</p> <pre><code>#See https://aka.ms/containerfastmode to understand how Visual Studio uses this Dockerfile to build your images for faster debugging.\n# Use the official Microsoft ASP.NET Core runtime image as a parent image\nFROM mcr.microsoft.com/dotnet/aspnet:6.0 AS base\nWORKDIR /app\nEXPOSE 80\nEXPOSE 443\n\n# Copy the project files and restore dependencies\nFROM mcr.microsoft.com/dotnet/sdk:6.0 AS build\nWORKDIR /src\nCOPY [\"aspnet-app.csproj\", \".\"]\nRUN dotnet restore \"./aspnet-app.csproj\"\n\n# Copy the remaining files and build the application\nCOPY . .\nWORKDIR \"/src/.\"\nRUN dotnet build \"aspnet-app.csproj\" -c Release -o /app/build\n\n# Publish the application\nFROM build AS publish\nRUN dotnet publish \"aspnet-app.csproj\" -c Release -o /app/publish\n\n# Final image\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\n# Start the application\nENTRYPOINT [\"dotnet\", \"aspnet-app.dll\"]\n</code></pre> <p>Note</p> <p>Read inline comments of the Dockerfile for understanding the Dockerfile instructions</p>"},{"location":"microservices/6.aspnet-app/#step-5-docker-build-locally","title":"Step-5: Docker Build locally","text":"<p>Build Docker images locally using the Dockerfiles added to the MVC project. This process will generate container images ready for deployment.</p> <p>The <code>docker build</code> command is used to build Docker images from a Dockerfile. The Dockerfile contains a set of instructions that Docker uses to create a new image. </p> <p><pre><code>docker build -t sample/aspnet-app:20230312.1 .\n</code></pre> <code>-t</code> to specify a name and optionally a tag for the image,</p> <p>output</p> <pre><code>[+] Building 49.9s (18/18) FINISHED\n =&gt; [internal] load build definition from Dockerfile\n =&gt; =&gt; transferring dockerfile: 696B                \n =&gt; [internal] load .dockerignore                   \n =&gt; =&gt; transferring context: 2B                     \n =&gt; [internal] load metadata for mcr.microsoft.com/dotnet/sdk:6.0        \n =&gt; [internal] load metadata for mcr.microsoft.com/dotnet/aspnet:6.0 \n .\n .\n .\n =&gt; exporting to image \n =&gt; =&gt; exporting layers\n =&gt; =&gt; writing image sha256:587f347206bcc67dafe3c0b53047862f11b6e52b1b61bce15b8432cc3a488e24\n =&gt; =&gt; naming to docker.io/sample/aspnet-app:20230312.1  \n</code></pre> <p>When you run the <code>docker build</code> command, Docker looks for a Dockerfile in the specified directory (PATH) and reads the instructions in the file to build a new image. The Dockerfile contains a series of instructions that define how to build the image, such as copying files, running commands, and setting environment variales. </p> <p>Error &amp; troubleshooting</p> <p>In case if you are getting following error while running <code>docker build</code> command, that means the docker desktop is not running locally. make sure that run the docker desktop locally to fix this issue.</p> <pre><code>error during connect: This error may indicate that the docker daemon is not running.: Post \"http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/build?buildargs=%7B%7D&amp;cachefrom=%5B%5D&amp;cgroupparent=&amp;cpuperiod=0&amp;cpuquota=0&amp;cpusetcpus=&amp;cpusetmems=&amp;cpushares=0&amp;dockerfile=Dockerfile&amp;labels=%7B%7D&amp;memory=0&amp;memswap=0&amp;networkmode=default&amp;rm=1&amp;shmsize=0&amp;t=sample%2Faspnet-app%3A20230312.1&amp;target=&amp;ulimits=null&amp;version=1\": open //./pipe/docker_engine: The system cannot find the file specified.\n</code></pre>"},{"location":"microservices/6.aspnet-app/#step-6-docker-run-locally","title":"Step-6: Docker Run locally","text":"<p>Run the Docker container locally to verify that the application functions correctly within a containerized environment. This step ensures that the containerized application operates as expected on your local machine.</p> <p>Run the <code>docker run</code> command to start a container based on the image:</p> <pre><code>docker run --rm -p 8080:80 sample/aspnet-app:20230312.1\n</code></pre> <p>output <pre><code>warn: Microsoft.AspNetCore.DataProtection.Repositories.FileSystemXmlRepository[60]\n      Storing keys in a directory '/root/.aspnet/DataProtection-Keys' that may not be persisted outside of the container. Protected data will be unavailable when container is destroyed.\nwarn: Microsoft.AspNetCore.DataProtection.KeyManagement.XmlKeyManager[35]\n      No XML encryptor configured. Key {90c41ec3-18a3-434a-8d4b-1d0cc5f140af} may be persisted to storage in unencrypted form.\ninfo: Microsoft.Hosting.Lifetime[14]  \n      Now listening on: http://[::]:80\ninfo: Microsoft.Hosting.Lifetime[0]\n      Application started. Press Ctrl+C to shut down.\ninfo: Microsoft.Hosting.Lifetime[0]\n      Hosting environment: Production\ninfo: Microsoft.Hosting.Lifetime[0]\n      Content root path: /app/\nwarn: Microsoft.AspNetCore.HttpsPolicy.HttpsRedirectionMiddleware[3]\n      Failed to determine the https port for redirect.\n</code></pre> if you open the docker desktop you will notice the new container started running.</p> <p></p> <p>http://localhost:8080/</p> <p></p> <p>You now have a basic ASP.NET Core Web App using the MVC pattern up and running. From here, you can continue building out your application by adding more controllers, views, and models as needed.</p>"},{"location":"microservices/6.aspnet-app/#step-7-push-docker-container-to-acr","title":"Step-7: Push docker container to ACR","text":"<p>Publish the Docker container to the Azure Container Registry (ACR) for future deployment to Azure Kubernetes Services (AKS). This step prepares the container for deployment to the cloud environment.</p> <p>Now we've Docker Containers ready locally for push to Container Registry so that we can use them in future labs.</p> <p>To publish a Docker container to Azure Container Registry (ACR), you will need to have the following:</p> <p>Create an Azure Container Registry. If you don't have one, you can create one by following the instructions in the Azure Portal or using Azure CLI.</p> <p>Log in to your Azure Container Registry using the Docker command-line interface. You can do this by running the following command:</p> <pre><code># azure Login\naz login\n\n# set the azure subscription\naz account set -s \"anji.keesari\"\n\n# Log in to the container registry\naz acr login --name acr1dev\n\n# To get the login server address for verification\naz acr list --resource-group rg-acr-dev --query \"[].{acrLoginServer:loginServer}\" --output table\n\n# output should look similar to this.\n\n# AcrLoginServer    \n# ------------------\n# acr1dev.azurecr.io\n</code></pre> <p>list all the Docker images that are available on the local system</p> <pre><code>docker images\n</code></pre> <p>output</p> <p><pre><code>REPOSITORY                                                TAG                                                                          IMAGE ID       CREATED         SIZE\nsample/aspnet-app                                         20230312.1                                                                   587f347206bc   8 minutes ago   216MB\n.\n.\n.\n</code></pre> <code>Tag</code> your Docker container with the full name of your Azure Container Registry, including the repository name and the version tag. You can do this by running the following command:</p> <p><pre><code>docker tag sample/aspnet-app:20230312.1 acr1dev.azurecr.io/sample/aspnet-app:20230312.1\n</code></pre> Push your Docker container to your Azure Container Registry using the Docker command-line interface. You can do this by running the following command:</p> <pre><code>docker push acr1dev.azurecr.io/sample/aspnet-app:20230312.1\n</code></pre> <p>Output</p> <p><pre><code>The push refers to repository [acr1dev.azurecr.io/sample/aspnet-app]\nf9c45e227c3a: Pushed\n5f70bf18a086: Mounted from sample/aspnet-api\n478d6dc381e4: Pushed\n355b7bb8c23e: Pushed\nff13768cb51e: Pushed\nfe674e2b138c: Pushed\nf30d150c0152: Pushed\n4695cdfb426a: Pushed\n20230312.1: digest: sha256:049b736aa29e9574010dfe1fc2ef5bb44ed76d54757a8f190b967fa0f854567e size: 1995\n</code></pre> 1. Wait for the push to complete. Depending on the size of your Docker containers and the speed of your internet connection, this may take a few minutes. 1. Verify the newly pushed image to ACR. <pre><code>az acr repository list --name acr1dev --output table\n</code></pre></p> <p>Output</p> <pre><code>Result\n-------------------------------\nmcr.microsoft.com/dotnet/aspnet\nmcr.microsoft.com/dotnet/sdk\nsample/aspnet-api\nsample/aspnet-app\n</code></pre> <p>Show the new tags of a image in the acr</p> <pre><code>az acr repository show-tags --name acr1dev --repository sample/aspnet-api --output table\n</code></pre> <p>output</p> <pre><code>Result\n----------\n20230312.1\n</code></pre> <p>You've successfully pushed your Docker container to Azure Container Registry. You can now use the Azure Portal or Azure CLI to manage your container and deploy them to Azure services like Azure Kubernetes Service (AKS).</p>"},{"location":"microservices/7.react-app/","title":"Chapter-7: Create Your Second Website using React.js","text":""},{"location":"microservices/7.react-app/#introduction","title":"Introduction","text":"<p>In this lab, we will create our second website using React JS, which serves as another MicroFrontend application in our Microservices architecture.</p> <p>Our goal is to prepare a React JS application for deployment on Kubernetes. The UI applications developed in this lab will be utilized in subsequent labs, including the creation of DevOps pipelines and the deployment to Azure Kubernetes Services.</p> <p>Let's look into the lab and begin our journey by creating a React JS application as part of the Microservices Architecture!</p>"},{"location":"microservices/7.react-app/#technical-scenario","title":"Technical Scenario","text":"<p>As a <code>Frontend (FE)</code> developer, you have been assigned the task of developing a website or UI application using React JS technology. This website will be one of the small Website (UI) components in our MicroFrontend applications list.</p> <p>This lab aims to provide you with hands-on experience in creating a React JS application as part of the Microservices Architecture. We will begin by utilizing an existing Git repository and proceed to create a new React JS project within it. Finally, we will containerize this website and push it to the Azure Container Registry (ACR) in preparation for deployment to Azure Kubernetes Services (AKS).</p>"},{"location":"microservices/7.react-app/#objective","title":"Objective","text":"<p>In this exercise, our objective is to accomplish and learn the following tasks:</p> <ul> <li>Step 1: Install Node.js and NPM</li> <li>Step-2: Create new React JS application</li> <li>Step-3: Add Dockerfiles to the React JS project</li> <li>Step-4: Docker Build locally</li> <li>Step-5: Docker Run locally</li> <li>Step-6: Publish docker container to ACR</li> </ul>"},{"location":"microservices/7.react-app/#prerequisites","title":"Prerequisites","text":"<ul> <li>Git Repository</li> <li>Clone existing Microservices repo</li> <li>Download and install software for React Development </li> <li>Docker desktop</li> <li>VS Code with Docker extension</li> <li>Azure Container Registry (ACR)</li> </ul>"},{"location":"microservices/7.react-app/#architecture-diagram","title":"Architecture Diagram","text":"<p>The following diagram shows the high level steps to create the website using React JS.</p> <p></p>"},{"location":"microservices/7.react-app/#step-1-install-nodejs-and-npm","title":"Step-1: Install Node.js and NPM","text":"<p>Before you can create a React app, you'll need to install Node.js and NPM (Node Package Manager) on your system. You can download the latest version of Node.js and NPM from the official website: https://nodejs.org/en/download/</p> <p>Manual install</p> <p>Click on the Installer as per your Operating system preference to install Node.js &amp; NPM both in your system.</p> <p>install using commands</p> <ul> <li>Windows OS</li> </ul> <p>Install Node.js &amp; NPM using Chocolatey (choco) for windows users, assuming you already installed choco in your system, run these commands as administrator from command prompt</p> <pre><code># This command will download and install the latest version of Node.js. \nchoco install nodejs\n\n# install a specific version\nchoco install nodejs --version=14.17.6\n</code></pre> <ul> <li>Mac OS</li> </ul> <p>Install Node.js &amp; NPM using Homebrew for Mac users, assuming you already installed Homebrew in your system:</p> <pre><code># install latest version\nbrew install node\n# install a specific version\nbrew install node@14\n</code></pre> <p>verify that Node.js is installed correctly</p> <p><pre><code>node --version\nnpm version\n</code></pre> output</p> <p><pre><code>v19.8.1\n</code></pre> verify that npm version is installed correctly</p> <p><pre><code>npm version\n</code></pre> output <pre><code>{\n  npm: '9.5.1',\n  node: '19.8.1',\n  acorn: '8.8.2',\n  ada: '1.0.4',\n  ares: '1.19.0',\n  brotli: '1.0.9',\n  cldr: '42.0',\n  icu: '72.1',\n  llhttp: '8.1.0',\n  modules: '111',\n  napi: '8',\n  nghttp2: '1.52.0',\n  nghttp3: '0.7.0',\n  ngtcp2: '0.8.1',\n  openssl: '3.0.8+quic',\n  simdutf: '3.2.2',\n  tz: '2022g',\n  undici: '5.21.0',\n  unicode: '15.0',\n  uv: '1.44.2',\n  uvwasi: '0.0.16',\n  v8: '10.8.168.25-node.12',\n  zlib: '1.2.13'\n}\n</code></pre></p>"},{"location":"microservices/7.react-app/#step-2-create-a-new-react-js-application","title":"Step-2: Create a new React JS application","text":"<p>Once you have Node.js installed, you can create a new React JS application using the <code>create-react-app</code> command. Open a terminal window and run the following command:</p> <p><pre><code>npx create-react-app react-app\n</code></pre> Wait for few mins for completing the installation.</p> <p></p> <p>This command will create a new React JS application with all the necessary files and directories in a folder named <code>react-app</code> in your current directory.</p> <p>output</p> <pre><code>Need to install the following packages:\n  create-react-app@5.0.1\nOk to proceed? (y) Y\nnpm WARN deprecated tar@2.2.2: This version of tar is no longer supported, and will not receive security updates. Please upgrade asap.\n\nCreating a new React app in C:\\Source\\Repos\\Microservices\\react-app.\nInstalling packages. This might take a couple of minutes.\nInstalling react, react-dom, and react-scripts with cra-template...\n\nadded 1419 packages in 2m\n.\n.\n.\n</code></pre> <p>If you closely look at the output produced by installer, it has some details to get start by React JS application.</p> <p>Run the Application</p> <pre><code>cd react-app\nnpm start\n</code></pre> <p>output</p> <pre><code>Compiled successfully!\n\nYou can now view react-app in the browser.\n\n  Local:            http://localhost:3000\n  On Your Network:  http://172.21.128.1:3000\n\nNote that the development build is not optimized.\nTo create a production build, use npm run build.\n\nwebpack compiled successfully\n</code></pre> <p></p>"},{"location":"microservices/7.react-app/#step-3-add-dockerfiles-to-the-mvc-project","title":"Step-3: Add Dockerfiles to the MVC project","text":"<p>Create a Dockerfile in the root directory of your project and copy following code. Dockerfile will provide instructions for building a container image of our React JS Website.</p> <pre><code># pull official base image\nFROM node:13.12.0-alpine\n\n# set working directory\nWORKDIR /app\n\n# add `/app/node_modules/.bin` to $PATH\nENV PATH /app/node_modules/.bin:$PATH\n\n# install app dependencies\nCOPY package.json ./\nCOPY package-lock.json ./\nRUN npm install --silent\nRUN npm install react-scripts@3.4.1 -g --silent\n\n# add app\nCOPY . ./\n\n# start app\nCMD [\"npm\", \"start\"]\n</code></pre> <p>Note</p> <p>Read inline comments of the Dockerfile for understanding the Dockerfile instructions</p>"},{"location":"microservices/7.react-app/#step-4-docker-build-locally","title":"Step-4: Docker Build locally","text":"<p>We will build the Docker container locally using the Dockerfiles and ensure that the containerized application functions as expected.</p> <p>The <code>docker build</code> command is used to build Docker images from a Dockerfile.  </p> <pre><code>docker build -t sample/react-app:20230322.1 .\n</code></pre> <p>output</p> <pre><code>=&gt; [6/7] RUN npm install react-scripts@3.4.1 -g\n=&gt; [7/7] COPY .\n=&gt; exporting to image\n=&gt; =&gt; exporting layers\n=&gt; =&gt; writing image sha256:552d7e73a9fbecf6f51397becc9af1b69df05429b3731513f53f6e89dd8a7cab \n=&gt; =&gt; naming to docker.io/sample/react-app:20230322.\n\nUse 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n</code></pre> <p>When you run the <code>docker build</code> command, Docker looks for a Dockerfile in the specified directory (PATH) and reads the instructions in the file to build a new image. </p> <p>The Dockerfile contains a series of instructions that define how to build the image, such as copying files, running commands, and setting environment variables. </p>"},{"location":"microservices/7.react-app/#step-5-docker-run-locally","title":"Step-5: Docker Run locally","text":"<p>Run the Docker container locally to verify that the application functions correctly within a containerized environment. This step ensures that the containerized application operates as expected on your local machine.</p> <p>Run the <code>docker run</code> command to start a container based on the image:</p> <p><pre><code>docker run --rm -p 3000:3000 sample/react-app:20230322.1\n</code></pre> output</p> <p><pre><code>Compiled successfully!\n\nYou can now view react-app in the browser.\n\n  Local:            http://localhost:3000\n  On Your Network:  http://172.17.0.2:3000\n\nNote that the development build is not optimized.\nTo create a production build, use npm run build.\n\nwebpack compiled successfully\nCompiling...\nCompiled successfully!\nwebpack compiled successfully\n</code></pre> if you open the docker desktop you will notice the new image &amp; container started running.</p> <p>Image</p> <p></p> <p>Container</p> <p></p> <p>This will start the ReactJS application in the Docker container and map the container's port 3000 to your local machine's port 3000. </p> <p>Your ReactJS application is now running inside a Docker container.</p> <p>Open your favorite browser and enter the following URL to see the running application in port 3000</p> <p>http://localhost:3000/</p> <p></p> <p>You now have a basic React JS application up and running. From here, you can continue building out your application by adding more and more code as per your requirements.</p>"},{"location":"microservices/7.react-app/#step-6-push-docker-container-to-acr","title":"Step-6: Push docker container to ACR","text":"<p>Now we've Docker Containers ready locally for push to Container Registry so that we can use them in future deployment to Azure Kubernetes Services (AKS). This step prepares the container for deployment to the cloud environment.</p> <p>To publish a Docker container to Azure Container Registry (ACR), you will need to have the following:</p> <ol> <li>Create an Azure Container Registry. If you don't have one, you can create one by following the instructions in the Azure Portal or using Azure CLI.</li> <li>Log in to your Azure Container Registry using the Docker command-line interface. You can do this by running the following command: <pre><code># azure Login\naz login\n\n# set the azure subscription\naz account set -s \"anji.keesari\"\n\n# Log in to the container registry\naz acr login --name acr1dev\n# Login Succeeded\n# To get the login server address for verification\naz acr list --resource-group rg-acr-dev --query \"[].{acrLoginServer:loginServer}\" --output table\n\n# output should look similar to this.\n\n# AcrLoginServer    \n# ------------------\n# acr1dev.azurecr.io\n</code></pre> list all the Docker images that are available on the local system <pre><code>docker images\n</code></pre> output <pre><code>REPOSITORY                                                TAG                                                                          IMAGE ID       CREATED         SIZE\nsample/aspnet-app                                         20230312.1                                                                   587f347206bc   8 minutes ago   216MB\n.\n.\n.\n</code></pre></li> <li><code>Tag</code> your Docker container image with the full name of your Azure Container Registry, including the repository name and the version tag. You can do this by running the following command: <pre><code>docker tag sample/react-app:20230322.1 acr1dev.azurecr.io/sample/react-app:20230322.1\n</code></pre></li> <li>Push your Docker container image to your Azure Container Registry using the Docker command-line interface. You can do this by running the following command: <pre><code>docker push acr1dev.azurecr.io/sample/react-app:20230322.1\n</code></pre> Output <pre><code>The push refers to repository [acr1dev.azurecr.io/sample/react-app]\n649a035a1734: Pushed\n4061bd2dd536: Pushed\nc0257b3030b0: Pushed\n912a3b0fc587: Pushed\na36186d93e25: Pushed\na3d997b065bc: Pushed\n65d358b7de11: Pushed\nf97384e8ccbc: Pushed\nd56e5e720148: Pushed\nbeee9f30bc1f: Pushed\n20230322.1: digest: sha256:73f0669d18c6cae79beb81edc8c523191710f9ec4781d590884b46326f9ad6f9 size: 2419\n</code></pre></li> <li>Wait for the push to complete. Depending on the size of your Docker container image and the speed of your internet connection, this may take a few minutes.</li> <li>Verify the newly pushed image to ACR. <pre><code>az acr repository list --name acr1dev --output table\n</code></pre> Output <pre><code>Result\n-------------------------------\nmcr.microsoft.com/dotnet/aspnet\nmcr.microsoft.com/dotnet/sdk\nsample/aspnet-api\nsample/aspnet-app\nsample/react-app\n</code></pre></li> <li>Show the new tags of a image in the acr <pre><code>az acr repository show-tags --name acr1dev --repository sample/react-app --output table\n</code></pre> output <pre><code>Result\n----------\n20230322.1\n</code></pre></li> </ol> <p>You've successfully pushed your Docker container image to Azure Container Registry. You can now use the Azure Portal or Azure CLI to manage your container images and deploy them to Azure services like Azure Kubernetes Service (AKS).</p>"},{"location":"microservices/8.sqlserver-db/","title":"Chapter-8: Setting up SQL Server database in a Docker Container","text":""},{"location":"microservices/8.sqlserver-db/#introduction","title":"Introduction","text":"<p>Running <code>SQL Server</code> in a Docker container is best suited for development, testing, learning, or quick experimentation scenarios where you need a lightweight, isolated environment that can be spun up or torn down easily. It works well offline, and your can run it without any cost, and is perfect for local development workflows. However, it's not ideal for production use. for production environments you can use Azure SQL Database which is a fully managed platform-as-a-service (PaaS) offering that's optimized for production workloads. It provides built-in high availability, automated backups, scalability, and security, making it ideal for applications that need global reach, minimal maintenance, and enterprise-grade reliability.</p> <p>In this lab, I will guide you through the process of creating Docker container for SQL Server database and run SQL Server database in the docker, and finally accessing the SQL Server database using SQL Server Management Studio (<code>SSMS</code>) and <code>Azure Data Studio</code> tools.</p>"},{"location":"microservices/8.sqlserver-db/#objective","title":"Objective","text":"<p>The objective is to establish a local development environment for the SQL Server database. To accomplish this, you will create a Dockerfile file, run them locally. All of these tasks we are doing here will be useful in later chapters when deploying to the Azure Kubernetes Service (AKS).</p> <p>In this exercise, our objective is to accomplish and learn the following tasks:</p> <ul> <li>Step-1: Setup Git Repository for SQL Server database.</li> <li>Step-2: Create Folder Structure for SQL Server database.</li> <li>Step-3: Add Dockerfiles to the Database Project</li> <li>Step-3.1: Docker Build Locally</li> <li>Step-3.2: Docker Run Locally</li> </ul> <ul> <li>Step-4: Test the SQL Server database connection using SSMS</li> <li>Step-5: Test the SQL Server database connection using Azure Data Studio</li> <li>Step-6: Push Docker Container to ACR</li> </ul> <p>By the end of this lab, you will have a SQL Server database running in a Docker container, managed through Azure DevOps, and ready for use in your development and production environments.</p>"},{"location":"microservices/8.sqlserver-db/#prerequisites","title":"Prerequisites","text":"<p>Before starting this lab, ensure you have the following prerequisites in place:</p> <ul> <li>Docker Desktop: - Docker Downloads.</li> <li>Docker compose installed</li> <li>SQL Server Management Studio installed - this will allow you to manage the SQL Server databases</li> <li>Azure Data Studio installed - this will allow you to connect to SQL server databases</li> <li>Basic understanding of Docker and SQL Server.</li> <li>Access to an Azure Container Registry (ACR).</li> </ul> <p>Verify the docker installation by running following commands:</p> <pre><code>docker version\n# or\ndocker --version\n# or\ndocker -v\n</code></pre> <p>Verify the docker compose by running following commands:</p> <pre><code>docker-compose version\n</code></pre>"},{"location":"microservices/8.sqlserver-db/#architecture-diagram","title":"Architecture Diagram","text":"<p>The following diagram shows the high level steps to create docker container for SQL Server database.</p> <p></p>"},{"location":"microservices/8.sqlserver-db/#step-1-setup-git-repository-for-sql-server-database","title":"Step-1: Setup Git Repository for SQL Server database","text":"<p>Setting up a Git repository for your SQL Server database project allows you to manage your code effectively, work in teams, and track the changes of your database codebase.</p> <ul> <li>Create a new project in Azure DevOps for your database-related work.</li> <li>Create a repository within the project to store your database scripts and Dockerfiles.</li> </ul> <p>For example to clone an existing repository, run the following command:</p> <pre><code>git clone https://keesari.visualstudio.com/Microservices/_git/microservices\n</code></pre>"},{"location":"microservices/8.sqlserver-db/#step-2-create-folder-structure-for-sql-server-database","title":"Step-2: Create Folder Structure for SQL Server database","text":"<p>In this step, we'll create a dedicated project or folder for our SQL Server database</p> <p>Create a new database project:</p> <p>Inside our Git repository, create a new directory or folder specifically for your SQL Server database. This folder will contain all the necessary files for SQL Server database, including databaseschema scripts, sample data scripts, docker compose &amp; Dockerfile and other sql files.</p> <p>Here's a suggestion for a folder structure for a SQL Server database project:</p> <pre><code>your-project-name/\n\u2502\n\u251c\u2500\u2500 sql/\n\u2502   \u251c\u2500\u2500 scripts/\n\u2502   \u2502   \u251c\u2500\u2500 schema/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 tables/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 table1.sql\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 table2.sql\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 views/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 view1.sql\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 view2.sql\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 functions/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 function1.sql\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 function2.sql\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 procedures/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 procedure1.sql\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 procedure2.sql\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 ...\n\u2502   \u2502   \u2514\u2500\u2500 data/\n\u2502   \u2502       \u251c\u2500\u2500 seed_data.sql\n\u2502   \u2502       \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 migrations/\n\u2502       \u251c\u2500\u2500 version1/\n\u2502       \u2502   \u251c\u2500\u2500 up.sql\n\u2502       \u2502   \u2514\u2500\u2500 down.sql\n\u2502       \u251c\u2500\u2500 version2/\n\u2502       \u2502   \u251c\u2500\u2500 up.sql\n\u2502       \u2502   \u2514\u2500\u2500 down.sql\n\u2502       \u2514\u2500\u2500 ...\n\u2502\n\u251c\u2500\u2500 Dockerfile\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Explanation:</p> <ul> <li><code>sql/</code>: This folder contains all SQL-related files for your project.</li> <li><code>scripts/</code>: Contains scripts for creating database objects like tables, views, functions, and stored procedures.<ul> <li><code>schema/</code>: Contains subfolders for different types of database objects.</li> <li><code>tables/</code>, <code>views/</code>, <code>functions/</code>, <code>procedures/</code>: Each of these folders contains SQL scripts for the respective database objects.</li> </ul> </li> <li><code>data/</code>: Contains data scripts such as seed data.</li> <li><code>migrations/</code>: Contains SQL migration scripts for managing database schema changes over time. Each migration version should have an <code>up.sql</code> script for applying the migration and a <code>down.sql</code> script for reverting it.</li> <li><code>Dockerfile</code>: The Dockerfile for building a Docker image for your SQL Server database.</li> <li><code>README.md</code>: Documentation for your project.</li> </ul> <p>You can adjust this structure based on the specific needs of your project. For instance, if you have additional folders or files, you can add them accordingly.</p> <p></p>"},{"location":"microservices/8.sqlserver-db/#step-3-add-dockerfiles-to-the-database-project","title":"Step-3: Add Dockerfiles to the Database Project","text":"<p>To build a Docker image for SQL Server, create a Dockerfile in your project's root directory:</p> <pre><code># Use the official SQL Server 2019 image from Microsoft\nFROM mcr.microsoft.com/mssql/server:2019-latest\n\n# Set the environment variables for SQL Server\nENV ACCEPT_EULA=Y\nENV SA_PASSWORD=Strong@Passw0rd\n# ENV MSSQL_PID=Developer\n# ENV MSSQL_TCP_PORT=1433\n\n# Create a directory inside the container to copy your SQL scripts\nWORKDIR /src\n\n# Copy your SQL scripts into the container [optional]\nCOPY scripts.sql ./scripts.sql\n\n# Set permissions for the SQL scripts\n# RUN chmod +x ./scripts.sql\n\n# RUN SQL SERVER and Access SQL CLI on localhost with given credentials\n# Then run SQL Script - scripts.sql\nRUN (/opt/mssql/bin/sqlservr --accept-eula &amp; ) | grep -q \"Service Broker manager has started\" &amp;&amp;  /opt/mssql-tools/bin/sqlcmd -S127.0.0.1 -Usa -PStrong@Passw0rd -i scripts.sql\n</code></pre> <p>In this Dockerfile:</p> <ul> <li>We start with the official SQL Server 2019 image provided by Microsoft.</li> <li>Set environment variables <code>ACCEPT_EULA</code> to 'Y' and <code>SA_PASSWORD</code> to the desired strong password for the 'sa' account.</li> <li>Create a directory inside the container to copy your SQL scripts (<code>/src</code> in this case).</li> <li>Copy your SQL scripts into the container (assuming you have them in the same directory as your Dockerfile).</li> <li>Set permissions for the SQL scripts (if needed).</li> <li>Finally, specify the command to start SQL Server when the container starts.</li> </ul> <p>You would replace <code>\"./scripts.sql\"</code> with the path to your actual SQL script file.</p> <pre><code>USE master;\nGO\n\n-- Create SampleDB\nCREATE DATABASE SampleDB;\nGO\n\nUSE SampleDB;\nGO\n\n-- Create Users table\nCREATE TABLE Users (\n    UserID INT PRIMARY KEY,\n    Username NVARCHAR(50),\n    Email NVARCHAR(100)\n);\nGO\n\n-- Insert some sample data into Users table\nINSERT INTO Users (UserID, Username, Email) VALUES (1, 'user1', 'user1@example.com');\nINSERT INTO Users (UserID, Username, Email) VALUES (2, 'user2', 'user2@example.com');\nINSERT INTO Users (UserID, Username, Email) VALUES (3, 'user3', 'user3@example.com');\nGO\n</code></pre> <p>Step-3.1: Docker Build Locally</p> <p>To build the Docker image, navigate to the directory containing the Dockerfile and your SQL script, then run:</p> <pre><code>docker build -t my-sqlserver-image .\n</code></pre> <p>Docker desktop &gt; Image</p> <p></p> <p>Step-3.2: Docker Run Locally</p> <p>To run your SQL Server container locally for testing and development, use the following command:</p> <pre><code>docker run -d --name my-sqlserver-container -p 5432:5432 my-sqlserver-image\n</code></pre> <p>This command creates a container named <code>my-sqlserver-container</code> and maps port 5432 from the container to the host.</p> <p>Docker desktop &gt; Container</p> <p></p>"},{"location":"microservices/8.sqlserver-db/#step-4-test-the-sql-server-database-connection-using-ssms","title":"Step-4: Test the SQL Server database connection using SSMS","text":"<p>Testing the SQL Server database connection using SQL Server Management Studio (SSMS) ensures that the database server is accessible and that users can connect to it successfully.</p> <p>Launch SQL Server Management Studio (SSMS) and provide the necessary credentials to connect to the SQL Server instance.</p> <p>SSMS &gt; Login Page</p> <p></p> <p>SSMS &gt; After Login</p> <p></p>"},{"location":"microservices/8.sqlserver-db/#step-5-test-the-sql-server-database-connection-using-azure-data-studio","title":"Step-5: Test the SQL server database connection using Azure Data Studio","text":"<p>Azure Data Studio is a cross-platform database tool that offers features similar to SQL Server Management Studio (SSMS) but with additional support for Azure services and extensions.</p> <p>Launch Azure Data Studio and provide the necessary credentials to connect to the SQL Server instance.</p> <p>SSMS &gt; Login Page</p> <p></p> <p>SSMS &gt; After Login</p> <p></p>"},{"location":"microservices/8.sqlserver-db/#step-6-push-docker-container-to-acr","title":"Step-6: Push Docker Container to ACR","text":"<p>Push your SQL Server container image to Azure Container Registry (ACR) for use in AKS. Follow these steps:</p> <p>Log in to your Azure account using the Azure CLI:</p> <pre><code>az login\n</code></pre> <p>Authenticate to your ACR:</p> <pre><code>az acr login --name myacr\n</code></pre> <p>Replace <code>myacr</code> with your ACR name.</p> <p>Tag your local Docker image with the ACR login server:</p> <pre><code>docker tag my-sqlserver-image myacr.azurecr.io/my-sqlserver-image:v1\n</code></pre> <p>Push the Docker image to ACR:</p> <pre><code>docker push myacr.azurecr.io/my-sqlserver-image:v1\n</code></pre> <p>Replace <code>myacr</code> and <code>v1</code> with your ACR name and desired image version.</p> <p>Now, your SQL Server container image is stored in Azure Container Registry and can be easily pulled and deployed from AKS to Azure Database for SQL Server - Flexible Server.</p>"},{"location":"microservices/8.sqlserver-db/#conclusion","title":"Conclusion","text":"<p>You have successfully created a Docker container for SQL Server database, container created as part of this task will be used in the future labs in AKS.</p>"},{"location":"microservices/8.sqlserver-db/#references","title":"References","text":"<ul> <li>Docker Hub</li> <li>Docker Hub - Microsoft SQL Server image</li> <li>Microsoft MSDN- Install SQL Server</li> <li>Microsoft Github- mssql-docker</li> </ul>"},{"location":"microservices/9.postgresql-db/","title":"Chapter-9: Setting up PostgreSQL database in a Docker Container","text":""},{"location":"microservices/9.postgresql-db/#introduction","title":"Introduction","text":"<p>PostgreSQL, also known as <code>Postgres</code> is a powerful, open-source relational database management system (RDBMS). PostgreSQL has gained popularity due to its advanced features and capabilities. PostgreSQL is a reliable choice for a wide range of applications, from small projects to large-scale enterprise systems. Its open-source nature, strong adherence to standards, and extensive feature set making it a popular database solution in the application development.</p> <p>Running <code>PostgresSQL</code> in a Docker container is best suited for development, testing, learning, or quick experimentation scenarios where you need a lightweight, isolated environment that can be spun up or torn down easily,  it's not ideal for production use. For production environments you can use <code>azure database for postgresql flexible server</code> which is a fully managed platform-as-a-service (PaaS).</p> <p>In this lab, I will guide you through the process of creating Docker container for PostgreSQL database and run PostgreSQL database in the docker, and finally accessing the PostgreSQL database from <code>pgadmin</code> and <code>psql</code> command line tools.</p>"},{"location":"microservices/9.postgresql-db/#objective","title":"Objective","text":"<p>The objective is to establish a local development environment for the PostgreSQL database. To accomplish this, you will create a docker compose file, run them locally. All of these tasks we are doing here will be useful in later chapters when deploying to the Azure Kubernetes Service (AKS).</p> <p>In this exercise, our objective is to accomplish and learn the following tasks:</p> <ul> <li>Step-1: Setup Git Repository for PostgreSQL database.</li> <li>Step-2: Create Folder Structure for PostgreSQL database.</li> <li>Step-3: Add Dockerfiles to the Database Project</li> <li>Step-3.1: Docker Build Locally</li> <li>Step-3.2: Docker Run Locally</li> <li>Step-4: Create Docker Compose file</li> <li>Step-4.1: Build PostgreSQL database locally.</li> <li>Step-4.2: Run PostgreSQL database Container locally.</li> <li>Step-5: Test the PostgreSQL database connection from <code>psql</code> tool</li> <li>Step-6: Test the PostgreSQL database from <code>pgadmin4</code> tool</li> <li>Step-7: Push Docker Container to ACR</li> </ul> <p>By the end of this lab, you will have a PostgreSQL database running in a Docker container, managed through Azure DevOps, and ready for use in your development and production environments.</p>"},{"location":"microservices/9.postgresql-db/#prerequisites","title":"Prerequisites","text":"<p>Before starting this lab, ensure you have the following prerequisites in place:</p> <ul> <li>Docker Desktop: - Docker Downloads.</li> <li>Docker compose installed</li> <li>Git Client tool: - Git Downloads.</li> <li>PostgreSQL installed - this will allow you to run <code>psql</code> command line tool</li> <li>Basic understanding of Docker and PostgreSQL.</li> <li>Access to an Azure Container Registry (ACR).</li> </ul> <p>Verify the docker installation by running following commands:</p> <pre><code>docker version\n# or\ndocker --version\n# or\ndocker -v\n</code></pre> <p>Verify the docker compose by running following commands:</p> <pre><code>docker-compose version\n</code></pre>"},{"location":"microservices/9.postgresql-db/#step-1-setup-git-repository-for-postgresql-database","title":"Step-1: Setup Git Repository for PostgreSQL database","text":"<p>Setting up a Git repository for your PostgreSQL database project allows you to manage your code effectively, work in teams, and track the changes of your database codebase.</p> <ul> <li>Create a new project in Azure DevOps for your database-related work.</li> <li>Create a repository within the project to store your database scripts and Dockerfiles.</li> </ul> <p>For example to clone an existing repository, run the following command:</p> <pre><code>git clone https://keesari.visualstudio.com/Microservices/_git/microservices\n</code></pre>"},{"location":"microservices/9.postgresql-db/#step-2-create-folder-structure-for-postgresql-database","title":"Step-2: Create Folder Structure for PostgreSQL database","text":"<p>In this step, we'll create a dedicated project or folder for our PostgreSQL database</p> <p>Create a new project:</p> <p>Inside our Git repository, create a new directory or folder specifically for your PostgreSQL database. This folder will contain all the necessary files for PostgreSQL database, including database scripts, docker compose &amp; Dockerfile and other psql files.</p> <p>Here's a suggested folder structure for a PostgreSQL database project:</p> <pre><code>your-project-name/\n\u2502\n\u251c\u2500\u2500 psql/\n\u2502   \u251c\u2500\u2500 scripts/\n\u2502   \u2502   \u251c\u2500\u2500 schema/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 tables/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 table1.sql\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 table2.sql\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 views/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 view1.sql\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 view2.sql\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 functions/\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 function1.sql\n\u2502   \u2502   \u2502   \u2502   \u251c\u2500\u2500 function2.sql\n\u2502   \u2502   \u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 procedures/\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 procedure1.sql\n\u2502   \u2502   \u2502       \u251c\u2500\u2500 procedure2.sql\n\u2502   \u2502   \u2502       \u2514\u2500\u2500 ...\n\u2502   \u2502   \u2514\u2500\u2500 data/\n\u2502   \u2502       \u251c\u2500\u2500 seed_data.sql\n\u2502   \u2502       \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 migrations/\n\u2502       \u251c\u2500\u2500 version1/\n\u2502       \u2502   \u251c\u2500\u2500 up.sql\n\u2502       \u2502   \u2514\u2500\u2500 down.sql\n\u2502       \u251c\u2500\u2500 version2/\n\u2502       \u2502   \u251c\u2500\u2500 up.sql\n\u2502       \u2502   \u2514\u2500\u2500 down.sql\n\u2502       \u2514\u2500\u2500 ...\n\u2502\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 docker-compose.yml\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Explanation:</p> <ul> <li><code>sql/</code>: This folder contains all SQL-related files for your project.</li> <li><code>scripts/</code>: Contains scripts for creating database objects like tables, views, functions, and stored procedures.<ul> <li><code>schema/</code>: Contains subfolders for different types of database objects.</li> <li><code>tables/</code>, <code>views/</code>, <code>functions/</code>, <code>procedures/</code>: Each of these folders contains SQL scripts for the respective database objects.</li> </ul> </li> <li><code>data/</code>: Contains data scripts such as seed data.</li> <li><code>migrations/</code>: Contains SQL migration scripts for managing database schema changes over time. Each migration version should have an <code>up.sql</code> script for applying the migration and a <code>down.sql</code> script for reverting it.</li> <li><code>Dockerfile</code>: The Dockerfile for building a Docker image for your PostgreSQL database.</li> <li><code>docker-compose.yml</code>: A Docker Compose file that defines the services, networks, and volumes for your PostgreSQL container.</li> <li><code>README.md</code>: Include documentation or instructions for using the repository, such as setup steps, environment variables, or specific details about the database scripts.</li> </ul> <p>Feel free to customize this structure according to your project's needs. You can add additional folders or files as required.</p> <p>Dockerfile vs Docker Compose</p> <p>A <code>Dockerfile</code> contains a set of instructions and commands used by Docker to automatically build a new container image.</p> <p>The <code>docker-compose.yaml</code> file is a configuration file used by Docker Compose, a tool for defining and running multi-container Docker applications. With a single command, Docker Compose uses the docker-compose.yaml file to create and start all the services defined in the file. </p> <p>In this lab I'll show you both approaches for creating PostgreSQL database.</p>"},{"location":"microservices/9.postgresql-db/#step-3-add-dockerfiles-to-the-database-project","title":"Step-3: Add Dockerfiles to the Database Project","text":"<p>To build a Docker image for PostgreSQL, create a Dockerfile in your project's root directory:</p> <pre><code># Use the official PostgreSQL image as the base image\nFROM postgres:latest\n\n# Set environment variables for PostgreSQL\nENV POSTGRES_USER=myuser\nENV POSTGRES_PASSWORD=mypassword\nENV POSTGRES_DB=mydatabase\n</code></pre> <p>In this Dockerfile:</p> <ul> <li>We use the official PostgreSQL image as our base image.</li> <li>Set environment variables to configure the PostgreSQL instance.</li> </ul> <p>Step-3.1: Docker Build Locally</p> <p>Navigate to your project's root directory and build the Docker image locally using the following command:</p> <pre><code>docker build -t my-postgresql-image .\n</code></pre> <p>Replace <code>my-postgresql-image</code> with a meaningful name for your image.</p> <p>Docker desktop &gt; Image</p> <p></p> <p>Step-3.2: Docker Run Locally</p> <p>To run your PostgreSQL container locally for testing and development, use the following command:</p> <pre><code>docker run -d --name my-postgresql-container -p 5432:5432 my-postgresql-image\n</code></pre> <p>This command creates a container named <code>my-postgresql-container</code> and maps port 5432 from the container to the host.</p> <p>Docker desktop &gt; Container</p> <p></p>"},{"location":"microservices/9.postgresql-db/#step-4-create-docker-compose-file","title":"Step-4:  Create Docker Compose file","text":"<p>To setup the PostgreSQL database with docker compose you need to first create a docker compose file that defines the PostgreSQL database service and any necessary dependencies.</p> <p>Create a file named <code>docker-compose.yml</code> in your project directory. This file will define the services and configurations for your PostgreSQL database setup.</p> <p>In the docker-compose.yml file, define the PostgreSQL database service. Use the official PostgreSQL database Docker image and specify any necessary configurations. Here's an example of a PostgreSQL database service definition:</p> docker-compose.yml<pre><code># Database type: PostgreSQL\n# Database name: postgres\n# Database username: postgres\n# Database password: example\n# ADVANCED OPTIONS; Database host: postgres\n\nversion: '3'\n\nservices:\n  postgres:\n    image: postgres:16\n    environment:\n      POSTGRES_USER : postgres\n      POSTGRES_PASSWORD: example\n    # ports:\n    #     - \"5432:5432\"\n    restart: always\n</code></pre> <ul> <li>Uses the <code>postgres:16</code> Docker image.</li> <li>Maps port 5432 on your host to port 5432 in the PostgreSQL database container.</li> <li>Sets up an initial user and password for PostgreSQL database.</li> </ul> <p>Step-4.1: Build PostgreSQL database locally</p> <p>The <code>docker-compose up</code> command is used to start and initialize the services defined in a Docker Compose file. We will build the Docker container locally using the docker compose and ensure that the containerized application working as expected.</p> <pre><code>docker-compose up\n\n# or - -d flag, it tells Docker Compose to run the containers in detached mode\ndocker-compose up -d\n\n#output\n[+] Running 33/2\n \u2714 postgres 14 layers [\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff]      0B/0B      Pulled\n[+] Running 3/3\n \u2714 Network Postgresql_default       Created\n \u2714 Container Postgresql-postgres-1  Started\n</code></pre> <p>List running Docker containers on your system.</p> <pre><code>docker ps\n\n# output\nCONTAINER ID   IMAGE         COMMAND                  CREATED          STATUS          PORTS                    NAMES\na433ad35d0a1   postgres:16   \"docker-entrypoint.s\u2026\"   20 seconds ago   Up 19 seconds   0.0.0.0:5432-&gt;5432/tcp   postgresql-postgres-1\n</code></pre> <p>List Docker images that are currently available on your local system.</p> <pre><code>docker image ls\n\n# output\nREPOSITORY   TAG       IMAGE ID       CREATED       SIZE\npostgres     16        488c2842403b   4 weeks ago   448MB\n</code></pre> <p>Step-4.2: Run PostgreSQL database Container locally</p> <p>Run the Docker container locally to verify that the PostgreSQL database  working correctly within a containerized environment. This step ensures that the containerized PostgreSQL database  works as expected on your local machine.</p> <p>List the running Docker containers on your system</p> <pre><code>docker container ls\n\n# output\nCONTAINER ID   IMAGE         COMMAND                  CREATED          STATUS          PORTS                    NAMES\na433ad35d0a1   postgres:16   \"docker-entrypoint.s\u2026\"   42 seconds ago   Up 41 seconds   0.0.0.0:5432-&gt;5432/tcp   postgresql-postgres-1\n</code></pre> <p>List the Docker networks that are available on your local system</p> <pre><code>docker network ls\n\n# output\nNETWORK ID     NAME      DRIVER    SCOPE\na63fce88f432   bridge    bridge    local\n3a43b39f60b0   host      host      local\n21fbef3d5c78   none      null      local\n</code></pre> <p>if you open the docker desktop you will notice the new image &amp; container started running.</p> <p>Note</p> <p>Ensure that you test the PostgreSQL connection using either the pgAdmin tool or the <code>psql</code> command-line tool.</p>"},{"location":"microservices/9.postgresql-db/#step-5-test-the-postgresql-database-connection-from-psql-tool","title":"Step-5: Test the PostgreSQL database connection from psql tool","text":"<p>The psql tool is a command-line interface (CLI) provided by PostgreSQL that allows users to interact with PostgreSQL databases directly from the terminal or command prompt.</p> <p>To test a PostgreSQL database connection using the <code>psql</code> command-line tool, follow these steps:</p> <p>Opening a terminal or command prompt on your computer.</p> <p>Use the <code>psql</code> utility to connect to your PostgreSQL database. </p> <pre><code>psql -h &lt;hostname&gt; -U &lt;username&gt; -d &lt;database_name&gt;\n</code></pre> <p>Replace the placeholders with your specific information:</p> <ul> <li><code>&lt;hostname&gt;</code>: The hostname  of the PostgreSQL server.</li> <li><code>&lt;username&gt;</code>: Your PostgreSQL username.</li> <li><code>&lt;database_name&gt;</code>: The name of the PostgreSQL database you want to connect to.</li> </ul> <p>For example, to connect to a PostgreSQL database running on the local machine with the username \"myuser\" and the database \"mydatabase,\" you would use the following command:</p> <pre><code>psql -h localhost -U myuser -d mydatabase\n</code></pre> <p>If the PostgreSQL server is running on the default port (5432), you don't need to specify the port. However, if it's running on a different port, you can use the <code>-p</code> option to specify the port number.</p> <p>Provide Password(if required):</p> <p>If your PostgreSQL database is configured to require a password for the specified username, you will be prompted to enter the password. Type the password and press Enter.</p> <p>Successful Connection:</p> <p>If the connection is successful, you should see the <code>psql</code> command prompt, which indicates that you are connected to the PostgreSQL database. It will look something like this:</p> <pre><code>psql (12.7)\nType \"help\" for help.\n\nmydatabase=#\n</code></pre> <p>You are now in an interactive session with the PostgreSQL database, and you can run SQL commands and queries.</p> <p>Test SQL Commands:</p> <p>To further test the database connection, you can execute SQL commands to retrieve or manipulate data. For example, you can run a simple SQL query like:</p> <pre><code>SELECT version();\n</code></pre> <p>This query will return the PostgreSQL version, confirming that you can interact with the database.</p> <p>Exit <code>psql</code>:</p> <p>To exit the <code>psql</code> session and return to your command prompt, you can type:</p> <pre><code>\\q\n</code></pre> <p>or press <code>Ctrl + D</code> (on Unix-based systems) or <code>Ctrl + Z</code> (on Windows).</p> <p></p> <p>By following these steps, you can connect to a PostgreSQL database using the psql tool and start interacting with the database using SQL commands directly from the command line.</p> <p>Create a Database</p> <p>Creating a database is really simple. Execute the command below, and the database should be created.</p> <pre><code># command\npostgres=# CREATE DATABASE [databasename];\n\n# example\nCREATE DATABASE mydatabase2;\n</code></pre>"},{"location":"microservices/9.postgresql-db/#step-6-test-the-postgresql-database-from-pgadmin4-tool","title":"Step-6: Test the PostgreSQL database from pgadmin4 tool","text":"<p>pgAdmin is a popular open-source graphical user interface (GUI) administration tool for PostgreSQL. It provides a comprehensive set of features for managing PostgreSQL databases, including creating and managing databases, schemas, tables, indexes, users, and permissions. pgAdmin allows users to interact with PostgreSQL databases visually, making database administration tasks more intuitive and efficient.</p> <p>To connect to a PostgreSQL database using the pgAdmin tool, follow these steps:</p> <p>Install and Launch pgAdmin 4:</p> <p>Download and install pgAdmin 4 on your computer. Once installed, launch the pgAdmin 4 application.</p> <p>Log in to pgAdmin</p> <p>When you launch pgAdmin for the first time, you'll be prompted to set the master password. Enter the password you want to use to log in to pgAdmin. You can also choose to save the login information for future use.</p> <p>Add a Server:</p> <p>After logging in, you'll see the pgAdmin interface. To connect to a PostgreSQL server, you need to add a server to pgAdmin. Follow these steps:</p> <ul> <li>In the left sidebar, expand \"Servers\" to reveal the \"PostgreSQL\" group.</li> <li>Right-click on \"PostgreSQL\" and select \"Register &gt; Server...\"</li> <li> <p>Configure Server Connection: you'll need to provide the following information:</p> </li> <li> <p>Name: Give your server a descriptive name to identify it within pgAdmin.</p> </li> <li>Host name/address: Specify the hostname or IP address of the PostgreSQL server you want to connect to.</li> <li>Port: Enter the port number where PostgreSQL is running (default is 5432).</li> <li>Maintenance database: Specify the name of a database to connect to initially (e.g., \"postgres\" or \"mydatabase\").</li> <li>Username: Enter the PostgreSQL username you want to use for this connection.</li> <li>Password: Provide the password for the specified username.</li> </ul> <p>for example:</p> <pre><code>hostname - `localhost`\ndefault database - `postgres`\nport - `5432` - default postgresql port #\ndefault user - `user` - this is the owner of default database postgres\npassword - `example` - this is what we've setup in our container\n</code></pre> <p></p> <p>Once you've entered the connection details, click the \"Save\" button to add the server.</p>"},{"location":"microservices/9.postgresql-db/#step-7-push-docker-container-to-acr","title":"Step-7: Push Docker Container to ACR","text":"<p>Push your PostgreSQL container image to Azure Container Registry (ACR) for use in AKS. Follow these steps:</p> <p>Log in to your Azure account using the Azure CLI:</p> <pre><code>az login\n</code></pre> <p>Authenticate to your ACR:</p> <pre><code>az acr login --name myacr\n</code></pre> <p>Replace <code>myacr</code> with your ACR name.</p> <p>Tag your local Docker image with the ACR login server:</p> <pre><code>docker tag my-postgresql-image myacr.azurecr.io/my-postgresql-image:v1\n</code></pre> <p>Push the Docker image to ACR:</p> <pre><code>docker push myacr.azurecr.io/my-postgresql-image:v1\n</code></pre> <p>Replace <code>myacr</code> and <code>v1</code> with your ACR name and desired image version.</p> <p>Now, your PostgreSQL container image is stored in Azure Container Registry and can be easily pulled and deployed from AKS to Azure Database for PostgreSQL - Flexible Server.</p>"},{"location":"microservices/9.postgresql-db/#conclusion","title":"Conclusion","text":"<p>You have successfully created a Docker container for PostgreSQL database, container created as part of this task will be used in the future labs in AKS.</p>"},{"location":"microservices/9.postgresql-db/#references","title":"References","text":"<ul> <li>Postgres Docker Official Image</li> </ul>"}]}